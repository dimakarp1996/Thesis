\chapter{Исследование переноса знаний в многоязычных моделях на новом тематическом наборе данных}\label{ch:rutopics}
\section{Введение}
В предыдущей главе \ref{ch:tr-ag} был исследован перенос знаний в многозадачных многоязычных моделях. Тем не менее, в этой главе остался не исследован перенос знаний с русского языка на другие языки. Также, в этой главе осталось не раскрыто то, от чего зависит качество переноса знаний в многоязычных моделях на разные языки.

Помимо этого, прикладные задачи диалоговой платформы DREAM требовали создания русскоязычного набора данных для тематической классификации, которые подходят к применению в реальных диалоговых системах. Существующие наборы данных для тематической классификации, поддерживающие русский язык, имеют следующие проблемы:
\begin{itemize}
    \item[*] Часть таких наборов данных состоит из длинных обучающих примеров(как правило - новостей). Опыт применения моделей, обученных на наборе данных \texttt{DeepPavlov Topics} в диалоговой платформе DREAM, показывает(см. главу \ref{ch:mtldream}), что модели, обученные на таких данных, могут переобучаться на них и плохо себя показывать на реальных диалоговых задачах. Примерами таких наборов данных являются \texttt{MLSUM}~\cite{mlsum} и \texttt{XGLUE-nc}~\cite{xglue}.
    \item[*] Часть таких наборов данных является слишком специфичными и хорошо подходят для классификации узкоспециализированных вопросов, но не подходят для классификации широкого спектра тем из-за специфичной номенклатуры классов.  Примерами таких наборов данных являются~\cite{healthcare_facilities_reviews} и  ~\cite{pstu}
    \item[*] Некоторые наборы данных для тематической классификации лишены этих проблем, но либо имеют слишком маленькое число примеров~\cite{chatbotru}, либо имеют номенклатуру классов, далекую от покрытия всех потребностей диалоговой системы~\cite{massive}.
\end{itemize}
Данные вопросы были подробно освещены в статье \cite{rutopics}, по материалам которой написана данная глава. 

В этой главе представляется новый тематический набор данных - \texttt{YAQTopics}. Приводятся метрики базовых моделей на этом наборе данных, доказывается пригодность набора данных \texttt{YAQTopics} для разговорной тематической классификации и исследуется перенос знаний с этого набора данных на 50 разных языков для многоязычной нейросетевой модели типа Трансформер. %TODO - везде 50?

\section{Набор данных \texttt{YAQTopics}} 

В работе предлагается новый русскоязычный набор данных для тематической классификацииt - \texttt{YAQTopics}. Этот набор данных с сервиса "Яндекс.Кью"~\cite{yandex_q} был получен по данной ссылке:\url{https://huggingface.co/datasets/its5Q/yandex-q/blob/main/full.jsonl.gz}.

В данный датасет были спарсены примеры из 76 разных тем. Выбор тем осуществлялся, основываясь на наборе данных \texttt{DeepPavlov Topics} и потребностях диалоговой платформы \textbf{DREAM}. Тема каждого вопроса соответствовала теме этого вопроса из "Яндекс.Кью". Некоторые из выбранных тем могут быть похожими друг на друга, как и реальные темы из "Яндекс.Кью" - следовательно, прикладное использование набора данных \texttt{YAQTopics} может требовать объединения некоторых тем. 

 Для каждого вопроса, выбирался также ответ наилучшего качества (или первый из таких ответов, если их было несколько). Для части вопросов ответ был пустым. 
 

% TODO ВЫБОРКА ТЕСТОВАЯ ВАЛИДАЦИОННАЯ ИЛИ РАЗБИЕНИЕ? singlelabel multilabel перевод) однометочная? многометочная? Формат чисел. DREAM - жирным

% TODO. CHECK THE TOPIC NUMBER. PROVIDE a LINK TO EVERY QUESTION in the final dataset version. 
Полученные пары вопрос-ответ были разбиты на две части. В часть 1 (однометочную) попали только те пары, в которых вопрос принадлежит только к одной теме, и при этом ответ на этот вопрос либо не существует, либо после суммаризации алгоритмом TextRank~\cite{summarizer} может быть найден только в этой же теме. Все остальные примеры принадлежат части 2 (многометочной). Все эксперименты, описанные в данной главе, проводились только с примерами из однометочной части \texttt{YAQTopics}.

Для всех тем, было выбрано 532,550 уникальных вопросов, из которых 403,904 было отвечено. При этом однометочная часть набора данных содержит 360,572 вопросов, из которых 265,516 было отвечено. Многометочная часть, в свою очередь, содержит 172,008 вопросов, из которых 138,388 было отвечено.
%todo - YAQTOPICS одними и теми же буквами как в статтк

Помимо этого, из однометочной части \texttt{YAQTopics} была дополнительно выделена равноразмерная часть данного набора данных. Если вопрос отвечен и суммаризованная версия вопроса при этом встречается только в одной теме (той же, что и тема ответа), то данный вопрос вместе с ответом и суммаризованным ответом включается не только в однометочную часть \texttt{YAQTopics}, но и в равноразмерную часть этого набора данных. 
 
Размеры всех частей \texttt{YAQTopics} как для всего набора данных, так и для каждого из классов, с которыми проводились описанные в данной главе эксперименты, включены в Таблицу~\ref{tab:rutopics:sizes}. 

%TODO
\begin{table}[t]
\centering
\scalebox{0.8}{
\begin{tabular}{|c||c|c|c|c|c|} \hline
\textbf{тип данных}  & \multicolumn{2}{c|}{\textbf{однометочные}} & \multicolumn{2}{c|}{\textbf{многометочные}} & \multirow{2}{*}{\textbf{равноразмерные}} \\
\cline{1-5}
\textbf{класс}  & \multicolumn{1}{c|}{все} & \multicolumn{1}{c|}{отвеченные} & \multicolumn{1}{c|}{все} & \multicolumn{1}{c|}{отвеченные} & \\\hline \hline
\textbf{Размер набора данных} & 360,572 & 265,516 & 172,008 & 138,388 & 139,751\\ \hline
\textbf{Размер шестиклассового поднабора данных} & 23,992 & 16,857 & 22,238 & 20,610 & 7,335\\ \hline
\textit{Новости} & 945 & 605 & 912 & 718 & 354\\ \hline
\textit{Музыка} & 9,504 & 5,793 & 4,466 & 3,296 & 2,412\\ \hline
\textit{Еда, напитки и кулинария} & 5,729 & 4,734 & 14,117 & 11,101 & 2,503\\ \hline
\textit{Погода} & 889 & 480 & 218 & 143 & 179\\ \hline
\textit{Транспорт} & 2,432 & 1,622 & 1,936 & 1,391 & 655\\ \hline
\textit{Медиа и коммуникации} & 4,493 & 2,628 & 5,589 & 3,961 & 1,232\\ \hline
\end{tabular}
}
\caption{Размеры набора данных \texttt{YAQTopics} по классу и разбиению}
%\centering
\label{tab:rutopics:sizes}
\end{table}


\section{Выбор представления набора данных \texttt{YAQTopics}}\label{rutopics:prepr} 

После получения набора данных \texttt{YAQTopics}, было необходимо выбрать метод предобработки данного набора данных, показывающий наилучшие результаты на разговорных задачах. Проводилось сравнение следующих пяти методов предобработки:

\begin{itemize}
    \item \textbf{Q} означает использование только вопросов.
    \item \textbf{A} означает использование только ответов.
    \item \textbf{As} означает использоватние только \textbf{суммаризованных} ответов.
    \item \textbf{Q [SEP] A} означает, что если ответ на вопрос существует, используется конкатенация вопроса с ответом на этот вопрос при помощи токена [SEP]. Иначе используется просто вопрос. 
    \item \textbf{Q [SEP] As} означает, что если ответ на вопрос существует, используется конкатенация вопроса с \textbf{суммаризованным} ответом на этот вопрос при помощи токена [SEP]. Иначе используется просто вопрос. 
\end{itemize}

Для всех методов предобработки, обучение проводилось на равноразмерной версии \texttt{YAQTopics}(колонка "равноразмерные" из Таблицы~\ref{tab:rutopics:sizes}).
Такой режим обучения позволяет проводить честное сравнение между признаками, полученными разными методами предобработки, так как количество тренировочных примеров при данном режиме то же самое безотносительно способа предобработки данных. Результаты сравнения вышеупомянутых методов предобработки приводятся в Таблице~\ref{tab:rutopics:matched}. В этой таблице и всех таблицах этого раздела макро-усредненное f1 обозначается как f1.
 
Для оценки любого из упомянутых выше методов предобработки набора данных, модель для сравнения обучалась на тренировочных примерах из \texttt{YAQTopics}, принадлежащих любому из соответствующих набору данных \texttt{MASSIVE} шести классов и полученных в соответствии с этим методом. Валидация производилась на примерах из валидационной части MASSIVE, принадлежащих вышеупомянутым шести классам. После завершения обучения, данная модель оценивалась на поднаборе тренировочных+тестовых примеров из русского \texttt{MASSIVE}, принадлежащих соответствующим шести классам из этого набора данных. Этот поднабор обозначается как "объединенные тестовые данные". 

При сравнении набора данных \texttt{YAQTopics} с набором данных \texttt{MASSIVE}, можно видеть, что только шесть классов из \texttt{MASSIVE} можно поставить в соответствие классам из  \texttt{YAQTopics}. Следовательно, нейросетевая модель в данных экспериментах обучалась только для шести соответствующих классов \texttt{YAQTopics}: \textit{Еда, напитки и кулинария} (соответствует классу \textit{cooking} из \texttt{MASSIVE}), \textit{Новости} (соответствует классу \textit{news} из \texttt{MASSIVE} ), \textit{Транспорт} (соответствует классу \textit{transport} из \texttt{MASSIVE}), \textit{Музыка} (соответствует классу \textit{music} из \texttt{MASSIVE}),\textit{Медиа и коммуникации} (соответствует классу \textit{social} из \texttt{MASSIVE}) и \textit{Погода} (соответствует классу \textit{weather} из \texttt{MASSIVE} class). Классы из набора данных \texttt{YAQTopics} никак не объединялись, хотя это предположительно могло бы дополнительно улучшить результаты на классах \textit{cooking} и \textit{transport} из набора данных \texttt{MASSIVE}. 

Этот метод позволяет проверить пригодность набора данных \texttt{YAQTopics} для разговорной тематической классификации - по крайней мере, на выбранных шести классах. Впрочем, так как примеры для всех шести классов были получены похожим образом, можно ожидать, что другие классы из \texttt{YAQTopics} настолько же хорошо подходят для разговорной тематической классификации. 


Эксперименты, описанные в Таблице~\ref{tab:rutopics:matched}, проводились на различных базовых моделях из библиотеки \texttt{Transformers}~\cite{huggingface_transformers} от HuggingFace : \textit{bert-base-multilingual-cased}~\cite{multilingual_bert}, \textit{DeepPavlov/distilrubert-tiny-cased-conversational}~\cite{distilrubert}, \textit{sberbank-ai/ruBert-base}~\cite{sbert_base}  \textit{DeepPavlov/rubert-base-conversational-cased}~\cite{rubert}. Все эти модели имеют архитектуру типа BERT. Последние 2 модели очень похожи, но имеют несколько отличающееся число параметров, так как в них применяются разные методы токенизации. 

Данные всех экспериментов, описанных в этой главе, приведены в Таблице~\ref{appendix:rutopics:allruns}. 

Подробное сравнение всех базовых моделей приведено в Таблице~\ref{tab:rutopics:backbones}.

\begin{table*}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{1}{*}{\textbf{Модель}} & \multirow{1}{*}{\textbf{Сокращение}}  & \textbf{Многоязычность} &  \multicolumn{1}{c|}{\textbf{Число слоев}} & \textbf{Parameters}\\ \hline
\textit{DeepPavlov/distilrubert-tiny-cased-conversational}~\cite{distilrubert} & \textit{rubert-tiny} & нет & 2 & 107M\\ \hline
\textit{DeepPavlov/rubert-base-cased-conversational}~\cite{rubert} & \textit{rubert} & нет & 12 & 177.9M\\ \hline
\textit{bert-base-multilingual-cased}~\cite{multilingual_bert} & \textit{multbert} & да & 12 & 177.9M \\ \hline
\textit{sberbank-ai/ruBert-base}~\cite{sbert_base} & \textit{ru-sbert} & да & 12 & 178.3M\\ \hline
\end{tabular}
}
\caption{Параметры различных базовых моделей, рассмотренных в этой главе}
\label{tab:rutopics:backbones}
\end{table*}

\begin{table*}
\centering
\scalebox{0.9}{
\begin{tabular}{|c|c||c|c|}
\hline
\multirow{2}{*}{\textbf{Модель}} & \multirow{2}{*}{\textbf{Режим}}  &  \multicolumn{2}{c|}{\textbf{Метрики}} \\ 
\cline{3-4}
& & Точность & Макро-F1   \\ \hline \hline
\textit{rubert} & \textbf{Q} & 83.8 & 83.0 \\ \hline% & 85.2 & 84.6 \\ \hline
\textit{rubert} &  \textbf{A} & 80.1 & 79.1\\ \hline% & 79.7 & 78.1\\ \hline
\textit{rubert} &  \textbf{Q [SEP] A} & 83.8 & 83.8\\ \hline% & 85.3 & 84.5\\ \hline
\textit{rubert} &  \textbf{As} & 75.0 & 74.3\\ \hline% & 75.5 & 74.5 \\ \hline
\textit{rubert} &  \textbf{Q [SEP] As} & \textbf{84.9} & \textbf{84.6}\\ \hline \hline% & 85.2 & 84.5 \\ \hline
\textit{ru-sbert} &  \textbf{Q} & \textbf{84.0} & \textbf{83.0}\\ \hline% & 85.8 & 85.4 \\ \hline
\textit{ru-sbert} &  \textbf{A} & 81.6 & 81.0\\ \hline% & 81.4 & 80.0 \\ \hline
\textit{ru-sbert} &  \textbf{Q [SEP] A} & 82.9 & 82.8\\ \hline% & 85.1 & 84.1  \\ \hline
\textit{ru-sbert} &  \textbf{As} & 78.8 & 77.9\\ \hline% & 78.1 & 77.2 \\ \hline
\textit{ru-sbert} &  \textbf{Q [SEP] As} & 83.5 & \textbf{83.0}\\ \hline \hline% & 85.8 & 85.2\\ \hline
\textit{rubert-tiny} &  \textbf{Q} & 83.6 & 82.7 \\ \hline%& 85.7 & 85.2\\ \hline
\textit{rubert-tiny} &  \textbf{A} & 78.3 & 77.1\\ \hline% & 82.6 & 81.3\\ \hline
\textit{rubert-tiny} &  \textbf{Q [SEP] A} & 81.5 & 80.7\\ \hline% & 85.3 & 84.6 \\ \hline
\textit{rubert-tiny} &  \textbf{As} & 78.2 & 77.0\\ \hline% & 76.2 & 74.6\\ \hline
\textit{rubert-tiny} &  \textbf{Q [SEP] As} & \textbf{84.5} & \textbf{84.0}\\ \hline \hline% & 85.4 & 84.8 \\ \hline
\textit{multbert} &  \textbf{Q} & \textbf{78.8} & \textbf{77.5}\\ \hline% & 79.8 & 78.8\\ \hline \hline
\textit{multbert} &  \textbf{A} & 71.8 & 71.2\\ \hline% & 76.0 & 74.7 \\ \hline \hline
\textit{multbert} &  \textbf{Q [SEP] A} & 76.9 & 76.1\\ \hline% & 79.9 & 79.4 \\ \hline \hline
\textit{multbert} &  \textbf{As} & 66.8 & 63.9\\ \hline%  & 67.4 & 64.6 \\ \hline \hline
\textit{multbert} &  \textbf{Q [SEP] As} & 77.2 & 76.1\\ \hline% & 79.7 & 78.9\\ \hline \hline
\end{tabular}
}
\caption{
 Точность (макро-F1) различных типов базовых моделей на объединенных тестовых данных \texttt{MASSIVE} для русского языка.
Модели были обучены на шестиклассовой \textbf{равноразмерной} подвыборке \texttt{YAQTopics}, предобработанной при помощи одного из нескольких режимов, описанных в Разделе~\ref{rutopics:prepr}. Условные обозначения моделей - как в  Таблице~\ref{tab:rutopics:backbones}. Усреднено по трем запускам.}
\label{tab:rutopics:matched}
\end{table*}

Как можно видеть из Таблицы~\ref{tab:rutopics:matched}, модели, учиышиеся только на ответах, показывают лучшие результаты, чем учившиеся только на вопросах, а учившиеся только на ответах или только на суммаризованных ответах. Это верно для всех рассмотренных базовых моделях, что доказывает: вопросы - самый информативный элемент набора данных {YAQTopics}. 

Конкатенация вопросов к ответам или суммаризованным ответам не дает стойкого улучшения по сравнению с использованием только лишь вопросов. 

В общем и целом, все русскоязычные модели показывают похожие результаты, а многоязычная модель ожидаемо показывает результаты хуже, чем любая из русскоязычных. 

Все эти выводы также справедливы для экспериментов, в которых использовались все данные из части 1 набора данных \texttt{YAQTopics}, принадлежащие вышеупомянутым шести классам. Для данных настроек обучения, базовая модель \textit{rubert} с режимом предобработки данных \textbf{Q} показывает точность 85.2\% и макро-F1 84.6\%.

Для экспериментов в следующей секции, был выбран режим предобработки \textbf{Q}, так как остальные режимы либо сложнее и при этом дают результаты не лучше, чем у \textbf{Q} (\textbf{Q [SEP] A}, \textbf{Q [SEP] As}), либо показывают результаты хуже, чем у \textbf{Q} (\textbf{A}, \textbf{As}).





\section{Перенос знаний между языками}
После выбора наилучшего метода использования набора данных \texttt{YAQTopics}, необходимо было ответить на следующие вопросы:
\begin{itemize}
\item[*]Как эффективно знания из \texttt{YAQTopics} переносятся между несколькими языками?
\item[*]Что влияет на эффективность этого переноса?
\end{itemize}
Чтобы ответить на эти вопросы, были получены предсказания модели \textit{bert-base-multilingual-cased} не только для руссского языка, но и для всех языков из набора данных \texttt{MASSIVE}. Данная модель обучалась в режиме \textbf{Q} из Таблицы \ref{tab:rutopics:matched}, на всех данных из шести выбранных в предыдущем разделе классов \texttt{YAQTopics}, имеющих только одну метку. 

Для данных экспериментов использовалась версия 1.1 \texttt{MASSIVE}, содержащая каталанский язык. Так как \texttt{MASSIVE} и содержит как современную, так и традиционную версию китайской письменности, учитывались обе. Как и в Таблице \ref{tab:rutopics:matched}, полученные результаты были усреднены по трем запускам.
%To article - точно work claims?
Полученные результаты представлены в Таблице \ref{tab:rutopics:crosslingual}. Исходя из данной таблицы, можно сделать вывод о корреляции качества многоязычной модели BERT для разных языков с размером обучающей выборки для этих языков. Авторы модели \textit{bert-base-multilingual-cased} утверждают\footnote{\url{https://github.com/google-research/bert/blob/master/multilingual.md}}, что тренировочной выборкой модели \textit{bert-base-multilingual-cased} для каждого языка являлся размер Википедии для этого языка, при этом для обучающей выборки было применено экспоненциальное сглаживание со степенью 0.7 для балансировки языков.
%TO ARTICLE - pretraining sample size. %Smoothing of training sample - expressions as in the url.
Соответственно, в качестве приближения размера Википедии для каждого языка, был выбрано число статей Википедии для этого языка на 11 октября 2018 года(дату выпуска модели BERT), возведенное в степень 0.7.  Число статей Википедии для каждого языка на эту дату также представлено в Таблице~\ref{tab:rutopics:crosslingual}. Помимо этого, в Таблице~\ref{tab:rutopics:crosslingual} также представлена генеалогическая близость каждого языка к русскому, вычисленная в соответствии с работой~\cite{lang_sim}. 

% TODO UPDATE ALL RUNS
\begin{table*}
\caption{Точность(f1) модели \textit{bert-base-multilingual-cased} на объединенном тестовом наборе данных \texttt{MASSIVE} для всех языков. Модель обучалась на версии \textbf{Q} набора данных \texttt{YAQTopics}.\textbf{Код} означает код языка(ISO 639-1), \textbf{N} означает число статей в Википедии на этом языке на 11 октября 2018 года, \textbf{Дистанция} означает лингвистическую дистанцию между этим языком и русским, посчитанную в соответствии с работой~\cite{lang_sim}. Усреднено по трем запускам.}
\label{tab:rutopics:crosslingual}
\centering
    \scalebox{0.5}{
\begin{tabular}{|c|c|c||c|c|c|} \hline
\multirow{2}{*}{\textbf{Язык}}  & \multirow{2}{*}{\textbf{Код}} & \multirow{2}{*}{\textbf{Дистанция}} & \multirow{2}{*}{\textbf{Число статей}}  &  \multicolumn{2}{c|}{\textbf{Метрики}} \\ %\hline
\cline{5-6}
& & & & Точность & Макро-F1 \\ \hline \hline
русский & ru & 0 & 1,501,878 & 79.9 & 78.9\\ \hline
китайский (Тайвань) & zh-TW & 92.2 & 1,025,366 & 74.7 & 73.7\\ \hline
китайский & zh & 92.2 & 1,025,366 & 73.6 & 72.6\\ \hline
английский & en & 60.3 & 5,731,625 & 70.7 & 70.2\\ \hline
японский & ja & 93.3 & 1,124,097 & 67.5 & 64.8\\ \hline
словенский & sl & 4.2 & 162,453 & 64.9 & 63.1\\ \hline
индонезийский & id & 91.2 & 440,952 & 64.3 & 62.1\\ \hline
итальянский & it & 45.8 & 1,466,064 & 64.2 & 62.5\\ \hline
малайский & ms & n/c & 320,631 & 63.9 & 61.7\\ \hline
шведский & sv & 59.5 & 3,763,579 & 63.9 & 63.4\\ \hline
нидерландский & nl & 64.6 & 1,944,129 & 63.5 & 63.0\\ \hline
испанский & es & 51.7 & 1,480,965 & 62.0 & 61.3\\ \hline
датский & da & 66.2 & 240,436 & 61.9 & 60.8\\ \hline
португальский & pt & 61.6 & 1,007,323 & 61.7 & 61.3\\ \hline
турецкий & tr & 86.2 & 316,969 & 61.1 & 58.3\\ \hline
персидский & fa & 72.4 & 643,750 & 60.8 & 58.9\\ \hline
вьетнамский & vi & 95.0 & 1,190,187 & 60.7 & 60.2\\ \hline
азербайджанский & az & 87.7 & 138,538 & 60.6 & 59.7\\ \hline
французский & fr & 61.0 & 2,046,793 & 60.4 & 58.9\\ \hline
норвежский букмол & nb & 67.2 & 495,395 & 59.7 & 59.1\\ \hline
хинди & hi & 69.8 & 127,044 & 59.4 & 57.1\\ \hline
венгерский & hu & 87.2 & 437,984 & 58.2 & 56.8\\ \hline
польский & pl & 5.1 & 1,303,297 & 57.4 & 54.6\\ \hline
корейский & ko & 89.5 & 429,369 & 57.1 & 55.6\\ \hline
каталанский & ca & 60.3 & 591,783 & 56.6 & 54.2\\ \hline
иврит & he & 88.9 & 231,868 & 55.5 & 53.8\\ \hline
румынский & ro & 55.0 & 388,896 & 55.0 & 51.5\\ \hline
филиппинский & tl & 91.9 & 80,992 & 55.0 & 51.1\\ \hline
каннада & kn & 90.8 & 23,844 & 54.1 & 50.9\\ \hline
урду & ur & 66.7 & 140,939 & 53.6 & 52.9\\ \hline
арабский & ar & 86.5 & 619,692 & 52.6 & 51.8\\ \hline
телугу & te & 96.7 & 69,354 & 51.5 & 47.2\\ \hline
албанский & sq & 69.4 & 74,871 & 51.4 & 46.6\\ \hline
финский & fi & 88.9 & 445,606 & 50.8 & 47.9\\ \hline
африкаанс & af & 64.8 & 62,963 & 50.7 & 48.3\\ \hline
бирманский & my & 86.0 & 39,823 & 49.9 & 47.1\\ \hline
немецкий & de & 64.5 & 2,227,483 & 48.9 & 47.4\\ \hline
тамильский & ta & 94.7 & 118,119 & 47.4 & 44.1\\ \hline
латышский & lv & 49.1 & 88,189 & 47.2 & 45.6\\ \hline
малаялам & ml & 96.7 & 59,305 & 45.4 & 43.0\\ \hline
бенгальский & bn & 66.3 & 61,294 & 45.2 & 43.2\\ \hline
армянский & hy & 77.8 & 246,571 & 45.0 & 44.8\\ \hline
греческий & el & 75.3 & 153,855 & 43.9 & 42.4\\ \hline
тайский & th & 89.5 & 127,010 & 42.6 & 40.0\\ \hline
яванский & jv & 95.4 & 54,964 & 37.7 & 34.9\\ \hline
монгольский & mn & 86.2 & 18,353 & 35.2 & 31.7\\ \hline
грузинский & ka & 96.0 & 124,694 & 34.4 & 32.4\\ \hline
суахили & sw & 95.1 & 45,806 & 32.0 & 29.0\\ \hline
исландский & is & 68.9 & 45,873 & 31.5 & 29.0\\ \hline
валлийский & cy & 75.5 & 101,472 & 27.6 & 24.0\\ \hline
амхарский & am & 86.6 & 14,375 & 13.6 & 5.7\\ \hline
кхмерский & km & 97.1 & 6,741 & 13.5 & 5.3\\ \hline
\end{tabular}
}
\end{table*}
%TODO p-value p-значение
Корреляция Спирмена точности для каждого языка с экспоненциально сглаженным размером Википедии равняется 0.741 (p-значение 5.02e-10). При этом корреляция точности с генеалогической дистанцией до русского равна -0.299 (p-значение 0.035). Если же принять в расчёт при подсчете этой корреляции экспоненциально сглаженный размер Википедии как третью переменную, то частичная корреляция точности с генеалогической дистанцией до русского языка становится равной 0.032 с пи-значением 0.387, что не является статистически значимым.


\section{Обсуждение и анализ результатов} 

В данной главе предлагается новый русскоязычный набор данных для разговорной тематической классификации - \texttt{YAQTopics}. Этот тематический датасет объединяет большое количество примеров (360,572 - принадлежащих одному классу, 172,008 - 2 классам и более) с обширным охватом классов (76 классов). Этот набор данных сгруппирован по темам из «Яндекс.Кью»; для каждого вопроса приводится суммаризованный вариант ответа, ссылка на полный ответ и темы вопросов и ответов в «Яндекс.Кью».

Как можно видеть, набор данных \texttt{YAQTopics} подходит достаточно хорошо для разговорной тематической классификации. Так, для классификации вопросов, русскоязычные модели типа BERT, обученные на шестиклассовой подвыборке \texttt{YAQTopics}, показывают точность свыше 85.0\% на подвыборке соответствующих 6 классов из русскоязычного \texttt{MASSIVE}(Таблица \ref{tab:rutopics:matched}). 

Русскоязычные модели показывают данные результаты, только если вопросы из  \texttt{YAQTopics} используются в тренировочных примера (сами по себе или в конкатенации с ответами/суммаризованными ответами). Это доказывает, что вопросы - самая информативная часть данного набора данных. 

В общем случае, данные результаты показывают важность размеченных коротких примеров в тематических датасетах. Эти результаты также доказываются тем, что конкатенация вопросов и суммаризованных ответов практически всегда лучше чяем конкатенация вопросов и ответов. 

На удивление, результаты на наборе данных \texttt{MASSIVE} практически не меняются для различных русскоязычных базовых моделей. Это показывает, что дистиллированные модели хорошо подходят для разговорных задач, особенно в условиях ограниченных вычислительных ресурсов. 

Также в данной главе показано, что в случае оценки модели  \textit{bert-base-multilingual-cased}, обученной на шестиклассовой подвыборке вопросов из \texttt{YAQTopics}, на подвыборке соответствующих 6 классов из \texttt{MASSIVE} для всех 51 поддерживаемых в \texttt{MASSIVE} языков, точность для каждого языка сильно коррелирует с аппроксимированном набором обучающей выборки для этого языка ( корреляция Спирмена 0.741 c p-значением 5.02e-10). Размер обучающей выборки был аппроксимирован при помощи возведения числа статей в Википедии для каждого языка на 11 октября 2018 года(дата выпуска статьи \cite{bert}) в степень 0.7, по аналогии с оригинальной статьей. 
%TODO - Спирмен, пи-значение, как пишется?

Данная корреляция была получена даже несмотря на то, что средняя статья в Википедии на разных языках имеет разное число токенов и предложений. Это приводит к предположению о том, что если бы для каждого языка имелось в явном виде число тренировочных примеров, которое модель \textit{bert-base-multilingual-cased} получала на этапе предобучения, корреляция была бы еще выше - но авторы оригинальной статьи не предоставили ни оригинальную обучающую выборку, ни её размер по языкам. 

При этом корреляция результатов модели на том или ином языке с генеалогическим расстоянием между этим языком и русским не является статистически значимой. Это приводит к выводу, что основной фактор, определяющий качество переноса знаний между языками в многоязычных моделях типа BERT - это размер выборки на предобучении для этого языка\footnote{Вероятно, для языков, которые являются очень лингвистически близкими, лингвистическая близость также влияет на качество переноса знаний, но оценка этого фактора требует дополнительных исследований.}.С учетом выводов Главы \ref{ch:tr-ag}, данный вывод может быть расширен и на многозадачные модели. 


 