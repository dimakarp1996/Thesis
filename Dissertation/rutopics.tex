\chapter{Исследование переноса знаний в многоязычных моделях на новом тематическом наборе данных}\label{ch:rutopics}
\section{Введение}
В предыдущей главе \ref{ch:tr-ag} был исследован перенос знаний в многозадачных многоязычных моделях. Тем не менее, в этой главе остался не исследован перенос знаний с русского языка на другие языки. Также, в этой главе осталось не раскрыто то, от чего зависит качество переноса знаний в многоязычных моделях на разные языки.
Помимо этого, прикладные задачи диалоговой платформы {DREAM} требовали создания русскоязычного набора данных для тематической классификации, которые подходят к применению в реальных диалоговых системах. Существующие наборы данных для тематической классификации, поддерживающие русский язык, имеют следующие проблемы:
\begin{itemize}
   \item[*] Часть таких наборов данных состоит из длинных обучающих примеров(как правило - новостей). Опыт применения моделей, обученных на наборе данных {DeepPavlov Topics} в диалоговой платформе DREAM, показывает(см. главу \ref{ch:mtldream}), что модели, обученные на таких данных, могут переобучаться на них и плохо себя показывать на реальных диалоговых задачах. Примерами таких наборов данных являются {MLSUM}~\cite{mlsum} и {XGLUE-nc}~\cite{xglue}.
   \item[*] Часть таких наборов данных является слишком специфичными и хорошо подходят для классификации узкоспециализированных вопросов, но не подходят для классификации широкого спектра тем из-за специфичной номенклатуры классов.  Примерами таких наборов данных являются~\cite{healthcare_facilities_reviews} и  ~\cite{pstu}
   \item[*] Некоторые наборы данных для тематической классификации лишены этих проблем, но либо имеют слишком маленькое число примеров~\cite{chatbotru}, либо имеют номенклатуру классов, далекую от покрытия всех потребностей диалоговой системы~\cite{massive}.
\end{itemize}
Данные вопросы были подробно освещены в статье \cite{rutopics}, по материалам которой написана данная глава. 

\textbf{Задачи}, поставленные в данной главе:
\begin{enumerate}
  \item \textbf{Проверить пригодность русскоязычного открытого набора тематических данных для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний на разговорных данных.}
  \item \textbf{Проверить зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков к языку дообучения.}
  \end{enumerate}

В качестве языка дообучения в данной главе использовался только русский язык. Использование других языков в качестве языков дообучения требует дополнительных исследований.

\section{Набор данных {YAQTopics}}

В работе изучается русскоязычный набор данных для тематической классификацииt - {YAQTopics}.
\subsection{Получение набора данных}
Этот набор данных с сервиса «Яндекс. Кью»~\cite{yandex_q} был получен по данной ссылке:\url{https://huggingface.co/datasets/its5Q/yandex-q/blob/main/full.jsonl.gz}.

В данный набор данных были включены примеры из 76 разных тем. Выбор тем осуществлялся, основываясь на наборе данных {DeepPavlov Topics} и потребностях диалоговой платформы \textbf{DREAM}. Тема каждого вопроса соответствовала теме этого вопроса из «Яндекс. Кью». Некоторые из выбранных тем могут быть похожими друг на друга, как и реальные темы из «Яндекс. Кью» - следовательно, прикладное использование набора данных {YAQTopics} может требовать объединения некоторых тем.

 Для каждого вопроса, выбирался также ответ наилучшего качества (или первый из таких ответов, если их было несколько). Для части вопросов ответ был пустым. 
 

% TODO ВЫБОРКА ТЕСТОВАЯ ВАЛИДАЦИОННАЯ ИЛИ РАЗБИЕНИЕ? singlelabel multilabel перевод) однометочная? многометочная? Формат чисел. {DREAM} - жирным

% TODO. CHECK THE TOPIC NUMBER. PROVIDE a LINK TO EVERY QUESTION in the final dataset version. 
\subsection{Разбиение и размеры}
Полученные пары вопрос-ответ были разбиты на две части. В часть 1 (однометочную) попали только те пары, в которых вопрос принадлежит только к одной теме, и при этом ответ на этот вопрос либо не существует, либо может быть найден только в этой же теме. Все остальные примеры принадлежат части 2 (многометочной). Все эксперименты, описанные в данной главе, проводились только с примерами из однометочной части {YAQTopics}.


Для всех тем, было выбрано 532590 уникальных вопросов, из которых 403938 было отвечено. При этом однометочная часть набора данных содержит 361650 вопросов, из которых 266597 было отвечено. Многометочная часть, в свою очередь, содержит 170930 вопросов, из которых 137431 было отвечено.
%todo - YAQTOPICS одними и теми же буквами как в статтк

Помимо этого, из однометочной части {YAQTopics} была дополнительно выделена равноразмерная часть данного набора данных. Если вопрос отвечен и суммаризованная версия вопроса при этом встречается только в одной теме (той же, что и тема ответа), то данный вопрос вместе с ответом и суммаризованным ответом включается не только в однометочную часть {YAQTopics}, но и в равноразмерную часть этого набора данных.
 
Размеры всех частей {YAQTopics} как для всего набора данных, так и для каждого из классов, с которыми проводились описанные в данной главе эксперименты, включены в Таблицу~\ref{tab:rutopics:sizes}.

%TODO
\begin{table}[t]
\centering
\scalebox{0.7}{
\begin{tabular}{|c||c|c|c|c|c|}
\textbf{тип данных}  & \multicolumn{2}{c|}{\textbf{однометочные}} & \multicolumn{2}{c|}{\textbf{многометочные}} & \multirow{2}{*}{\textbf{равноразмерные}}\\
\cline{1-5}
\textbf{класс}  & \multicolumn{1}{c|}{все} & \multicolumn{1}{c|}{отвеченные} & \multicolumn{1}{c|}{все} & \multicolumn{1}{c|}{отвеченные} & \\\hline \hline
\input{Dissertation/rutopics_sizes_data.tex}
\end{tabular}
}
\caption{Размеры набора данных {YAQTopics} по классу и части}
%\centering
\label{tab:rutopics:sizes}
\end{table}


\section{Выбор представления набора данных {YAQTopics}}\label{rutopics:prepr}

После получения набора данных {YAQTopics}, было необходимо выбрать метод предобработки данного набора данных, показывающий наилучшие результаты на разговорных задачах. Проводилось сравнение следующих трех методов предобработки:

\begin{itemize}
   \item \textbf{Q} означает использование только вопросов.
   \item \textbf{A} означает использование только ответов.
   \item \textbf{Q [SEP] A} означает, что если ответ на вопрос существует, используется конкатенация вопроса с ответом на этот вопрос при помощи токена [SEP]. Иначе используется просто вопрос.  
\end{itemize}

В предварительных экспериментах, вместо ответов использовались их суммаризованные версии. Суммаризация проводилась при помощи алгоритма TextRank~\cite{summarizer}. Использование только суммаризованных ответов показало стабильно худшие результаты, чем использование только несуммаризованных. При этом конкатенация вопросов к суммаризованным ответам не дает устойчивых изменений качества по сравнению с конкатенацией вопросов к ответам.

Для всех методов предобработки, обучение проводилось на равноразмерной версии {YAQTopics}(колонка «равноразмерные» из Таблицы~\ref{tab:rutopics:sizes}).
Такой режим обучения позволяет проводить честное сравнение между признаками, полученными разными методами предобработки, так как количество тренировочных примеров при данном режиме то же самое безотносительно способа предобработки данных. Результаты сравнения вышеупомянутых методов предобработки приводятся в Таблице~\ref{tab:rutopics:matched}. В этой таблице и всех таблицах этого раздела макро-усредненное f1 обозначается как f1.
 \subsection{Как сравнить представления набора данных друг с другом?}
Для оценки любого из упомянутых выше методов предобработки набора данных, модель для сравнения обучалась на тренировочных примерах из {YAQTopics}, принадлежащих любому из соответствующих набору данных {MASSIVE} шести классов и полученных в соответствии с этим методом. Валидация производилась на примерах из валидационной части MASSIVE, принадлежащих вышеупомянутым шести классам. После завершения обучения, данная модель оценивалась на поднаборе тренировочных+тестовых примеров из русского {MASSIVE}, принадлежащих соответствующим шести классам из этого набора данных. Этот поднабор обозначается как «объединенные тестовые данные».

При сравнении набора данных {YAQTopics} с набором данных {MASSIVE}, можно видеть, что только шесть классов из {MASSIVE} можно поставить в соответствие классам из  {YAQTopics}. Следовательно, нейросетевая модель в данных экспериментах обучалась только для шести соответствующих классов {YAQTopics}: \textit{Еда, напитки и кулинария} (соответствует классу \textit{cooking} из {MASSIVE}), \textit{Новости} (соответствует классу \textit{news} из {MASSIVE} ), \textit{Транспорт} (соответствует классу \textit{transport} из {MASSIVE}), \textit{Музыка} (соответствует классу \textit{music} из {MASSIVE}),\textit{Медиа и коммуникации} (соответствует классу \textit{social} из {MASSIVE}) и \textit{Погода} (соответствует классу \textit{weather} из {MASSIVE} class). Классы из набора данных {YAQTopics} никак не объединялись, хотя это предположительно могло бы дополнительно улучшить результаты на классах \textit{cooking} и \textit{transport} из набора данных {MASSIVE}.

Этот метод позволяет проверить пригодность набора данных {YAQTopics} для разговорной тематической классификации - по крайней мере, на выбранных шести классах. Впрочем, так как примеры для всех шести классов были получены похожим образом, можно ожидать, что другие классы из {YAQTopics} настолько же хорошо подходят для разговорной тематической классификации.

\subsection{Описание экспериментов для сравнения}
Эксперименты, описанные в Таблице~\ref{tab:rutopics:matched}, проводились на различных базовых моделях из библиотеки {Transformers}~\cite{huggingface_transformers} от HuggingFace : \textit{bert-base-multilingual-cased}~\cite{multilingual_bert}, \textit{DeepPavlov/distilrubert-tiny-cased-conversational}~\cite{distilrubert}, \textit{sberbank-ai/ruBert-base}~\cite{sbert_base}  \textit{DeepPavlov/rubert-base-conversational-cased}~\cite{rubert}. Все эти модели имеют архитектуру типа BERT. Последние 2 модели очень похожи, но имеют несколько отличающееся число параметров, так как в них применяются разные методы токенизации.

Данные всех экспериментов, описанных в этой главе, приведены в Таблице~\ref{appendix:rutopics:allruns}. 

Подробное сравнение всех базовых моделей приведено в Таблице~\ref{tab:rutopics:backbones}.

\begin{table*}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{1}{*}{\textbf{Модель}} & \multirow{1}{*}{\textbf{Сокращение}}  & \textbf{Многоязычность} &  \multicolumn{1}{c|}{\textbf{Число слоев}} & \textbf{Parameters}\\ \hline
\textit{DeepPavlov/distilrubert-tiny-cased-conversational}~\cite{distilrubert} & \textit{rubert-tiny} & нет & 2 & 107M\\ \hline
\textit{DeepPavlov/rubert-base-cased-conversational}~\cite{rubert} & \textit{rubert} & нет & 12 & 177.9M\\ \hline
\textit{bert-base-multilingual-cased}~\cite{multilingual_bert} & \textit{multbert} & да & 12 & 177.9M \\ \hline
\textit{sberbank-ai/ruBert-base}~\cite{sbert_base} & \textit{ru-sbert} & да & 12 & 178.3M\\ \hline
\end{tabular}
}
\caption{Параметры различных базовых моделей, рассмотренных в этой главе}
\label{tab:rutopics:backbones}
\end{table*}

\begin{table*}
\centering
\caption{ Точность (макро-F1) различных типов базовых моделей на объединенных тестовых данных {MASSIVE} для русского языка.
Модели были обучены на шестиклассовой \textbf{равноразмерной} подвыборке {YAQTopics}, предобработанной при помощи одного из нескольких режимов, описанных в Разделе~\ref{rutopics:prepr}. Условные обозначения моделей - как в  Таблице~\ref{tab:rutopics:backbones}. Усреднено по трем запускам.}
\scalebox{0.65}{
\label{tab:rutopics:matched}
\begin{tabular}{|c|c||c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Модель}} & \multirow{2}{*}{\textbf{Режим}}  &  \multicolumn{2}{c|}{\textbf{Все классы}} &  \multicolumn{2}{c|}{\textbf{music}} &  \multicolumn{2}{c|}{\textbf{cooking}} &  \multicolumn{2}{c|}{\textbf{news}} &  \multicolumn{2}{c|}{\textbf{transport}} &  \multicolumn{2}{c|}{\textbf{weather}} &  \multicolumn{2}{c|}{\textbf{social}} \\ 
\cline{3-16}
& & Точность & Macro-F1 & Точность & F1 & Точность & F1 & Точность & F1 & Точность & F1 & Точность & F1 & Точность & F1 \\ \hline
\textit{ru} &  \textbf{Q} & 85.0 & 84.3 & 94.7 & 87.5 & 98.4 & 86.0 & 82.5 & 82.7 & 92.1 & 92.1 & 82.5 & 89.6 & 66.1 & 68.0\\ %\hline
\textit{rutiny} &  \textbf{Q} & 85.7 & 85.2 & 95.0 & 87.5 & 98.7 & 87.3 & 82.2 & 82.9 & 92.8 & 92.3 & 84.3 & 90.6 & 67.3 & 70.3\\ %\hline
\textit{rusber} &  \textbf{Q} & 85.5 & 84.9 & 93.7 & 89.9 & 98.8 & 87.2 & 83.0 & 83.1 & 93.1 & 91.1 & 85.1 & 91.1 & 64.3 & 67.2\\ %\hline
\textit{mult} &  \textbf{Q} & 80.8 & 79.8 & 94.3 & 77.3 & 97.2 & 82.8 & 75.5 & 81.1 & 90.0 & 90.5 & 78.5 & 86.0 & 57.5 & 61.0\\ \hline
\textit{ru} &  \textbf{A} & 79.8 & 77.9 & 95.8 & 79.0 & 98.9 & 75.2 & 65.9 & 76.7 & 90.2 & 88.3 & 85.0 & 90.3 & 51.0 & 57.8\\ %\hline
\textit{rutiny} &  \textbf{A} & 82.4 & 80.9 & 96.1 & 81.8 & 99.3 & 78.2 & 72.8 & 81.2 & 88.6 & 89.8 & 87.2 & 91.2 & 57.9 & 63.3\\ %\hline
\textit{rusber} &  \textbf{A} & 82.6 & 80.9 & 94.3 & 83.4 & 98.9 & 80.8 & 74.4 & 80.2 & 90.6 & 89.4 & 89.3 & 90.9 & 52.7 & 60.6\\ %\hline
\textit{mult} &  \textbf{A} & 74.5 & 72.9 & 95.8 & 69.6 & 95.9 & 72.1 & 66.1 & 75.5 & 80.4 & 83.3 & 76.7 & 83.4 & 44.0 & 53.6\\ \hline
\textit{ru} &  \textbf{Q [SEP] A} & 85.4 & 84.9 & 94.0 & 88.5 & 97.6 & 87.1 & 82.5 & 83.7 & 93.1 & 91.5 & 83.6 & 90.0 & 67.1 & 68.8\\ %\hline
\textit{rutiny} &  \textbf{Q [SEP] A} & 85.3 & 84.7 & 94.3 & 87.4 & 97.9 & 86.4 & 79.3 & 81.4 & 91.6 & 92.8 & 86.0 & 91.0 & 68.2 & 69.1\\ %\hline
\textit{rusber} &  \textbf{Q [SEP] A} & 85.1 & 84.2 & 93.1 & 91.6 & 98.3 & 88.4 & 88.1 & 81.2 & 93.3 & 91.9 & 86.2 & 91.6 & 53.7 & 60.7\\ %\hline
\textit{mult} &  \textbf{Q [SEP] A} & 80.0 & 79.7 & 94.2 & 77.0 & 95.1 & 85.5 & 74.9 & 80.3 & 87.8 & 88.0 & 73.8 & 83.8 & 64.6 & 63.6\\ \hline
\end{tabular}
}
\end{table*}

\begin{table*}
\centering
\caption{ Точность (макро-F1) различных типов базовых моделей на объединенных тестовых данных {MASSIVE} для русского языка.
Модели были обучены на шестиклассовой \textbf{полной} подвыборке {YAQTopics}(из всей однометочной части), предобработанной при помощи одного из нескольких режимов, описанных в Разделе~\ref{rutopics:prepr}. Условные обозначения моделей - как в  Таблице~\ref{tab:rutopics:backbones}. Усреднено по трем запускам.}
\scalebox{0.65}{
\label{tab:rutopics:full}
\begin{tabular}{|c|c||c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Модель}} & \multirow{2}{*}{\textbf{Режим}}  &  \multicolumn{2}{c|}{\textbf{Все классы}} &  \multicolumn{2}{c|}{\textbf{music}} &  \multicolumn{2}{c|}{\textbf{cooking}} &  \multicolumn{2}{c|}{\textbf{news}} &  \multicolumn{2}{c|}{\textbf{transport}} &  \multicolumn{2}{c|}{\textbf{weather}} &  \multicolumn{2}{c|}{\textbf{social}} \\ 
\cline{3-16}
& & Точность & Macro-F1 & Точность & F1 & Точность & F1 & Точность & F1 & Точность & F1 & Точность & F1 & Точность & F1 \\ \hline
\textit{ru} &  \textbf{Q} & 85.0 & 84.3 & 94.7 & 87.5 & 98.4 & 86.0 & 82.5 & 82.7 & 92.1 & 92.1 & 82.5 & 89.6 & 66.1 & 68.0\\ %\hline
\textit{rutiny} &  \textbf{Q} & 85.7 & 85.2 & 95.0 & 87.5 & 98.7 & 87.3 & 82.2 & 82.9 & 92.8 & 92.3 & 84.3 & 90.6 & 67.3 & 70.3\\ %\hline
\textit{rusber} &  \textbf{Q} & 85.5 & 84.9 & 93.7 & 89.9 & 98.8 & 87.2 & 83.0 & 83.1 & 93.1 & 91.1 & 85.1 & 91.1 & 64.3 & 67.2\\ %\hline
\textit{mult} &  \textbf{Q} & 80.8 & 79.8 & 94.3 & 77.3 & 97.2 & 82.8 & 75.5 & 81.1 & 90.0 & 90.5 & 78.5 & 86.0 & 57.5 & 61.0\\ \hline
\textit{ru} &  \textbf{A} & 79.8 & 77.9 & 95.8 & 79.0 & 98.9 & 75.2 & 65.9 & 76.7 & 90.2 & 88.3 & 85.0 & 90.3 & 51.0 & 57.8\\ %\hline
\textit{rutiny} &  \textbf{A} & 82.4 & 80.9 & 96.1 & 81.8 & 99.3 & 78.2 & 72.8 & 81.2 & 88.6 & 89.8 & 87.2 & 91.2 & 57.9 & 63.3\\ %\hline
\textit{rusber} &  \textbf{A} & 82.6 & 80.9 & 94.3 & 83.4 & 98.9 & 80.8 & 74.4 & 80.2 & 90.6 & 89.4 & 89.3 & 90.9 & 52.7 & 60.6\\ %\hline
\textit{mult} &  \textbf{A} & 74.5 & 72.9 & 95.8 & 69.6 & 95.9 & 72.1 & 66.1 & 75.5 & 80.4 & 83.3 & 76.7 & 83.4 & 44.0 & 53.6\\ \hline
\textit{ru} &  \textbf{Q [SEP] A} & 85.4 & 84.9 & 94.0 & 88.5 & 97.6 & 87.1 & 82.5 & 83.7 & 93.1 & 91.5 & 83.6 & 90.0 & 67.1 & 68.8\\ %\hline
\textit{rutiny} &  \textbf{Q [SEP] A} & 85.3 & 84.7 & 94.3 & 87.4 & 97.9 & 86.4 & 79.3 & 81.4 & 91.6 & 92.8 & 86.0 & 91.0 & 68.2 & 69.1\\ %\hline
\textit{rusber} &  \textbf{Q [SEP] A} & 85.1 & 84.2 & 93.1 & 91.6 & 98.3 & 88.4 & 88.1 & 81.2 & 93.3 & 91.9 & 86.2 & 91.6 & 53.7 & 60.7\\ %\hline
\textit{mult} &  \textbf{Q [SEP] A} & 80.0 & 79.7 & 94.2 & 77.0 & 95.1 & 85.5 & 74.9 & 80.3 & 87.8 & 88.0 & 73.8 & 83.8 & 64.6 & 63.6\\ \hline+-
\end{tabular}
}
\end{table*}

Как можно видеть из Таблицы~\ref{tab:rutopics:matched}, модели, учиышиеся только на ответах, показывают лучшие результаты, чем учившиеся только на вопросах, а учившиеся только на ответах. Это верно для всех рассмотренных базовых моделях, что доказывает: вопросы - самый информативный элемент набора данных {YAQTopics}. 

Конкатенация вопросов к ответам не дает стойкого улучшения по сравнению с использованием только лишь вопросов. 

В общем и целом, все русскоязычные модели показывают похожие результаты, а многоязычная модель ожидаемо показывает результаты хуже, чем любая из русскоязычных. 

Все эти выводы также справедливы для экспериментов, в которых использовались все данные из части 1 набора данных {YAQTopics}, принадлежащие вышеупомянутым шести классам. Данные этих эксперим.

Для дальнейших экспериментов в этой главе был выбран режим предобработки \textbf{Q}, так как остальные режимы либо сложнее и при этом дают результаты не лучше, чем у \textbf{Q} (\textbf{Q [SEP] A}), либо показывают результаты хуже, чем у \textbf{Q} (\textbf{A}).

\section{Оценка для всех классов {YAQTopics}}

Другая важная задача - определение того, как хорошо в принципе могут классы из {YAQTopics} быть различими. Для этого мы проводим кросс-валидацию по 5 разбиениям на тренировочную и валидационнную выборку на данных из всех 76 классов из однометочной части {YAQTopics}.\footnote{Для каждого из разбиений - 80\% данных было тренировочными, 20\% валидационными и они же тестовыми, для разных разбиений это были разные 20\%.} Результаты представлены в Таблице~\ref{tab:crossvalidation}.


\begin{table*}
\centering
\caption{Точность (Макро-F1) различных базовых моделей для 5-кратной кросс-валидации на всех классах из наборе данных {YAQTopics} при обучении только на вопросах.
 Базовые модели обозначаются как в Таблице~\ref{tab:rutopics:backbones}, Разб. означает разбиение. Дисперсия не превосходит 0.65 для всех базовых моделей.}
\scalebox{0.65}{
\label{tab:crossvalidation}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Модель}} & \multicolumn{2}{c|}{\textbf{Среднее}} & \multicolumn{2}{c|}{\textbf{Разб. 1}} & \multicolumn{2}{c|}{\textbf{Разб. 2}} &\multicolumn{2}{c|}{\textbf{Разб. 3}} & \multicolumn{2}{c|}{\textbf{Разб. 4}} & \multicolumn{2}{c|}{\textbf{Разб. 5}} \\ 
\cline{2-13}
& Точность & Макро-F1 & Точность & Макро-F1 & Точность & Макро-F1 & Точность & Макро-F1   & Точность & Макро-F1 & Точность & Макро-F1 \\ \hline
%\textit{rusber} & 74.0 & 53.4 \\ \hline
%\textit{ru} & 73.7 & 52.5 \\ \hline
%\textit{rutiny} & 72.2 & 50.9 \\ \hline
%\textit{mult} & 71.4 & 51.9 \\ \hline
\textit{rusber} & 74.0 & 53.4 & 73.7 & 54.3 & 73.8 & 52.8 & 73.9 & 53.0 & 74.1 & 54.2 & 74.2 & 52.9\\
\textit{ru} & 73.7 & 52.5 & 73.5 & 52.9 & 73.7 & 51.9 & 73.6 & 52.3 & 73.9 & 53.1 & 73.9 & 52.3\\
\textit{rutiny} & 72.2 & 50.9 & 72.0 & 49.7 & 72.2 & 50.9 & 72.0 & 51.4 & 72.4 & 51.1 & 72.3 & 51.6\\
\textit{mult} & 71.4 & 51.9 & 71.2 & 52.4 & 71.5 & 51.9 & 71.5 & 51.4 & 71.2 & 51.6 & 71.7 & 52.1\\ \hline
\end{tabular}
}
\end{table*}

Результаты могут быть дополнительно улучшены при помощи объединения некоторых классов из похожих тем «Яндекс. Кью». Но даже без этого, русскоязычные недистиллированные базовые модели  показывают точность 73.7-74.0\%, в то время как дистиллированные базовые модели показывают себя несколько хуже (точность 72.2\%). Многоязычная базовая модель ожидаемо показывает себя по этой метрике несколько хуже этих моделей (точность 71.4\%). Это показывает, что тематические классы в этом наборе данных можно отличить друг от друга с достаточно высокой точностью.

\section{Перенос знаний между языками}
После выбора наилучшего метода использования набора данных {YAQTopics}, необходимо было ответить на следующие вопросы:
\begin{itemize}
\item[*]Как эффективно знания из {YAQTopics} переносятся между несколькими языками?
\item[*]Что влияет на эффективность этого переноса?
\end{itemize}
Чтобы ответить на эти вопросы, были получены предсказания модели \textit{bert-base-multilingual-cased} не только для руссского языка, но и для всех языков из набора данных {MASSIVE}. Данная модель обучалась в режиме \textbf{Q} из Таблицы \ref{tab:rutopics:matched}, на всех данных из шести выбранных в предыдущем разделе классов {YAQTopics}, имеющих только одну метку.

Для экспериментов использовалась версия 1.1 {MASSIVE}, содержащая каталанский язык. Так как {MASSIVE} и содержит как современную, так и традиционную версию китайской письменности, учитывались обе. Как и в Таблицах \ref{tab:rutopics:matched} и \ref{tab:rutopics:full}, полученные результаты были усреднены по трем запускам.
%To article - точно work claims?
Полученные результаты представлены в Таблице \ref{tab:rutopics:crosslingual}. Исходя из данной таблицы, можно сделать вывод о корреляции качества многоязычной модели BERT для разных языков с размером обучающей выборки для этих языков. Авторы модели \textit{bert-base-multilingual-cased} утверждают,\footnote{\url{https://github.com/google-research/bert/blob/master/multilingual.md}} что тренировочной выборкой модели \textit{bert-base-multilingual-cased} для каждого языка являлся размер Википедии для этого языка, при этом для обучающей выборки было применено экспоненциальное сглаживание со степенью 0.7 для балансировки языков.
%TO ARTICLE - pretraining sample size. %Smoothing of training sample - expressions as in the url.
Соответственно, в качестве приближения размера Википедии для каждого языка, был выбрано число статей Википедии для этого языка на 11 октября 2018 года(дату выпуска модели BERT), возведенное в степень 0.7.  Число статей Википедии для каждого языка на эту дату также представлено в Таблице~\ref{tab:rutopics:crosslingual}. Помимо этого, в Таблице~\ref{tab:rutopics:crosslingual} также представлена генеалогическая близость каждого языка к русскому, вычисленная в соответствии с работой~\cite{lang_sim}. 

% TODO UPDATE ALL RUNS
\begin{table*}
\caption{Точность (f1) модели \textit{bert-base-multilingual-cased} на объединенном тестовом наборе данных {MASSIVE} для всех языков. Модель обучалась на версии \textbf{Q} набора данных {YAQTopics}.\textbf{Код} означает код языка(ISO 639-1), \textbf{N} означает число статей в Википедии на этом языке на 11 октября 2018 года, \textbf{Дистанция} означает лингвистическую дистанцию между этим языком и русским, посчитанную в соответствии с работой~\cite{lang_sim}. Усреднено по трем запускам.}
\label{tab:rutopics:crosslingual}
\centering
   \scalebox{0.5}{
\begin{tabular}{|c|c|c||c|c|c|} \hline
\multirow{2}{*}{\textbf{Язык}}  & \multirow{2}{*}{\textbf{Код}} & \multirow{2}{*}{\textbf{Дистанция}} & \multirow{2}{*}{\textbf{Число статей}}  &  \multicolumn{2}{c|}{\textbf{Метрики}} \\ %\hline
\cline{5-6}
& & & & Точность & Макро-F1 \\ \hline \hline
русский & ru & 0 & 1,501,878 & 80.8 & 79.8\\
китайский (Тайвань) & zh-TW & 92.2 & 1,025,366 & 79.6 & 79.1\\
китайский & zh & 92.2 & 1,025,366 & 78.0 & 77.7\\
английский & en & 60.3 & 5,731,625 & 75.2 & 75.6\\
японский & ja & 93.3 & 1,124,097 & 72.4 & 70.5\\
словенский & sl & 4.2 & 162,453 & 70.3 & 69.0\\
шведский & sv & 59.5 & 3,763,579 & 70.2 & 69.6\\
малайский & ms & n/c & 320,631 & 68.9 & 67.7\\
итальянский & it & 45.8 & 1,466,064 & 68.8 & 68.0\\
индонезийский & id & 91.2 & 440,952 & 68.7 & 67.5\\
нидерландский & nl & 64.6 & 1,944,129 & 68.7 & 68.5\\
португальский & pt & 61.6 & 1,007,323 & 68.6 & 68.7\\
испанский & es & 51.7 & 1,480,965 & 68.2 & 68.0\\
датский & da & 66.2 & 240,436 & 67.8 & 66.7\\
французский & fr & 61.0 & 2,046,793 & 65.5 & 65.5\\
персидский & fa & 72.4 & 643,750 & 65.2 & 64.2\\
турецкий & tr & 86.2 & 316,969 & 64.5 & 62.4\\
вьетнамский & vi & 95.0 & 1,190,187 & 64.3 & 65.1\\
норвежский букмол & nb & 67.2 & 495,395 & 64.3 & 64.0\\
польский & pl & 5.1 & 1,303,297 & 64.2 & 62.2\\
азербайджанский & az & 87.7 & 138,538 & 63.9 & 63.1\\
каталанский & ca & 60.3 & 591,783 & 61.4 & 60.4\\
венгерский & hu & 87.2 & 437,984 & 61.3 & 60.0\\
иврит & he & 88.9 & 231,868 & 60.9 & 59.5\\
хинди & hi & 69.8 & 127,044 & 60.7 & 58.7\\
корейский & ko & 89.5 & 429,369 & 60.4 & 59.6\\
румынский & ro & 55.0 & 388,896 & 57.1 & 53.9\\
урду & ur & 66.7 & 140,939 & 56.4 & 55.9\\
арабский & ar & 86.5 & 619,692 & 56.2 & 55.7\\
каннада & kn & 90.8 & 23,844 & 56.1 & 53.0\\
филиппинский & tl & 91.9 & 80,992 & 55.0 & 51.3\\
телугу & te & 96.7 & 69,354 & 53.7 & 49.3\\
финский & fi & 88.9 & 445,606 & 53.3 & 51.3\\
бирманский & my & 86.0 & 39,823 & 52.5 & 49.7\\
африкаанс & af & 64.8 & 62,963 & 52.4 & 50.3\\
тамильский & ta & 94.7 & 118,119 & 52.4 & 50.1\\
немецкий & de & 64.5 & 2,227,483 & 52.2 & 51.6\\
албанский & sq & 69.4 & 74,871 & 51.5 & 47.2\\
латышский & lv & 49.1 & 88,189 & 49.6 & 48.4\\
малаялам & ml & 96.7 & 59,305 & 48.7 & 46.3\\
армянский & hy & 77.8 & 246,571 & 48.1 & 47.5\\
бенгальский & bn & 66.3 & 61,294 & 47.3 & 45.3\\
тайский & th & 89.5 & 127,010 & 46.5 & 44.9\\
греческий & el & 75.3 & 153,855 & 46.3 & 44.8\\
грузинский & ka & 96.0 & 124,694 & 39.2 & 38.1\\
яванский & jv & 95.4 & 54,964 & 38.7 & 37.1\\
монгольский & mn & 86.2 & 18,353 & 36.6 & 33.7\\
исландский & is & 68.9 & 45,873 & 32.6 & 29.9\\
суахили & sw & 95.1 & 45,806 & 31.0 & 28.0\\
валлийский & cy & 75.5 & 101,472 & 28.5 & 25.3\\
кхмерский & km & 97.1 & 6,741 & 16.1 & 8.6\\
амхарский & am & 86.6 & 14,375 & 12.1 & 5.0\\
\end{tabular}
}
\end{table*}
%TODO p-value p-значение
Корреляция Спирмена точности для каждого языка с экспоненциально сглаженным размером Википедии равняется 0.773 (p-значение 5.02e-10). При этом корреляция точности с генеалогической дистанцией до русского равна -0.323 (p-значение 0.022). Если же принять в расчёт при подсчете этой корреляции экспоненциально сглаженный размер Википедии как третью переменную, то частичная корреляция точности с генеалогической дистанцией до русского языка становится равной -0.151 с пи-значением 0.3, что не является статистически значимым.


\section{Выводы и анализ результатов} 

В данной главе изучается русскоязычный набор данных для разговорной тематической классификации - {YAQTopics}. Этот тематический набор данных объединяет большое количество примеров (361560 - принадлежащих одному классу, 170930 - 2 классам и более) с обширным охватом классов (76 классов). Этот набор данных сгруппирован по темам из «Яндекс.Кью»; для каждого вопроса приводится суммаризованный вариант ответа, ссылка на полный ответ и темы вопросов и ответов в «Яндекс.Кью».

Как можно видеть, набор данных {YAQTopics} подходит достаточно хорошо для разговорной тематической классификации. Так, для классификации вопросов, русскоязычные модели типа BERT, обученные на шестиклассовой подвыборке {YAQTopics}, показывают точность около 85.0\% на подвыборке соответствующих 6 классов из русскоязычного {MASSIVE}(Таблица \ref{tab:rutopics:full}).

Можно сделать предположение, что набор данных {YAQTopics} подходит также для вопросно-ответной классификации, однако проверка этого предположения требует дополнительных исследований.

Для обучения моделей на вопросах из всех 76 классах {YAQTopics}, все базовые модели показывают точность выше 70\%. Это показывает, что тематические классы в данном наборе данных достаточно хорошо различимы..
Русскоязычные модели показывают данные результаты, только если вопросы из  {YAQTopics} используются в тренировочных примерах (сами по себе или в конкатенации с ответами/суммаризованными ответами). Это доказывает, что вопросы - самая информативная часть данного набора данных.

В общем случае, данные результаты показывают важность размеченных коротких примеров в тематических наборах данных. 

На удивление, результаты на наборе данных {MASSIVE} практически не меняются для различных русскоязычных базовых моделей. Это показывает, что дистиллированные модели хорошо подходят для разговорных задач, особенно в условиях ограниченных вычислительных ресурсов.

При обучении моделей на всех 76 классах из {YAQTopics} и использовании в примерах только вопросов, все базовые модели показывают точность выше 70 процентов, несмотря на схожесть некоторых классов в данном наборе данных. Это показывает, что набор данных {YAQTopics} подходит для решения задачи классификации целиком, а не только своими шестью классами.

Также в данной главе показано, что в случае оценки модели  \textit{bert-base-multilingual-cased}, обученной на шестиклассовой подвыборке вопросов из {YAQTopics}, на подвыборке соответствующих 6 классов из {MASSIVE} для всех 51 поддерживаемых в {MASSIVE} языков, точность для каждого языка сильно коррелирует с аппроксимированном набором обучающей выборки для этого языка ( корреляция Спирмена 0.773 c p-значением 2.997e-11). Размер обучающей выборки был аппроксимирован при помощи возведения числа статей в Википедии для каждого языка на 11 октября 2018 года(дата выпуска статьи \cite{bert}) в степень 0.7, по аналогии с оригинальной статьей.
%TODO - Спирмен, пи-значение, как пишется?

Данная корреляция была получена даже несмотря на то, что средняя статья в Википедии на разных языках имеет разное число токенов и предложений. Это приводит к предположению о том, что если бы для каждого языка имелось в явном виде число тренировочных примеров, которое модель \textit{bert-base-multilingual-cased} получала на этапе предобучения, корреляция была бы еще выше - но авторы оригинальной статьи не предоставили ни оригинальную обучающую выборку, ни её размер по языкам. 

При этом корреляция результатов модели на том или ином языке с генеалогическим расстоянием между этим языком и русским не является статистически значимой. Это приводит к выводу, что основной фактор, определяющий качество переноса знаний между языками в многоязычных моделях типа BERT - это размер выборки на предобучении для этого языка.\footnote{Вероятно, для языков, которые являются очень лингвистически близкими, лингвистическая близость также влияет на качество переноса знаний, но оценка этого фактора требует дополнительных исследований.} С учетом выводов Главы \ref{ch:tr-ag}, данный вывод может быть расширен и на многозадачные модели.

Главные \textbf{выводы} из этой главы -
\begin{enumerate}
\item \textbf{Русскоязычный открытый набор тематических данных {YAQTopics} пригоден для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
\item \textbf{Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к языку дообучения.}
\end{enumerate}


 
