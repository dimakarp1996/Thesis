  \chapter{  Обзор диалоговой системы DREAM}\label{dream} 


Необходимость использования многозадачных нейросетевых моделей для обработки естественного языка обуславливает необходимость экономии вычислительных ресурсов при обработке естественного языка. Одной из ключевых областей, в которой широко применяются новейшие модели для обработки естественного языка, являются диалоговые системы.  Использование нейросетевых моделей, включая многозадачные, в диалоговых системах изучалось автором данном диссертационной работы на примере диалоговой системы DREAM, дважды принимавшей участие в конкурсе Alexa Prize Challenge, в составе единственной российской команды за всю историю данного соревнования. Ниже приводится подробный обзор данной диалоговой системы.

\section{Конкурс “Alexa Prize Socialbot Grand Challenge”}

Компания Amazon проводит конкурс “Alexa Prize Socialbot Grand Challenge” с 2017 года. “Alexa Prize Socialbot Grand Challenge” - это конкурс диалоговых систем широкого профиля, разрабатываемых университетскими командами из разных стран. Данные системы могут общаться с пользователями голосовых колонок “Alexa” от Amazon на различные популярные темы. Режим разговора с диалоговой системой во время конкурса включается командой “Alexa, let’s chat”.

После окончания разговора пользователю предлагается оценить качество диалога по шкале от 1 до 5 ( 1 - наименьшая оценка, 5 - наибольшая). 

Финальная цель данного конкурса - добиться следующих показателей: среднее качество диалога больше 4, среднее время разговора больше 20 минут. Данные показатели на сегодняшний момент находятся за пределами возможностей всех университетских команд. По причине данного фактора, конкурс является поэтапным. Каждый год компания Amazon организует “Alexa Prize Challenge”, в котором из большого числа заявок (несколько сотен в год) отбирается до 10 университетских команд для участия в конкурсе.

Данный конкурс имеет продолжительность более полугода и состоит из следующих этапов:
\begin{itemize}
\item[*] Подготовительный период. Команды работают над своими диалоговыми системами и тестируют их внутри своих команд.
\item[*] Период бета-тестирования на пользователях-сотрудниках “Amazon”. 
\item[*] Период начальной обратной связи (англ: Initial Feedback Period). В этот период системы-участники впервые становятся доступными обычным пользователям колонок, которые могут общаться с этими системами и ставить им ту или иную оценку. Рейтинги в этот период еще не влияют на отбор команд для прохода в следующий этап.
\item[*] Период четвертьфинала(англ: Quaterfinals). По рейтингам за последнюю неделю четвертьфиналов отбираются команды для прохода в полуфиналы.
\item[*] Период полуфинала(англ: Semifinals). По среднему рейтингу за все время полуфиналов отбираются команды для прохода в финалы.
\item[*] Период финала(англ: Finals). Во время финалов специально обученное жюри проводит слепое тестирование диалоговых систем. По результатам данного тестирования жюри выбирает итогового победителя. При этом изменения кода в периоде финалов уже запрещены.
\end{itemize}

Команда Московского физико-технического института “DREAM” была отобрана для участия в конкурсах “Alexa Prize Challenge 3” \cite{Alexa Prize SocialBot Grand Challenge 3 - Amazon Science} и “Alexa Prize Challenge 4” \cite{Alexa Prize SocialBot Grand Challenge 4 - Amazon Science}. В каждом из этих конкурсов \cite{DREAM Team / Alexa Prize 3,DREAM Team / Alexa Prize 4} в этой команде принимал участие автор данной диссертационной работы. Диалоговая система DREAM подробнее описана в \cite{Baymurzina_Kuznetsov_Evseev_Karpov_Sagirova_Peganov_Ignatov_Ermakova_Cherniavskii_Kumeyko_et al._2021,Kuratov_Yusupov_Baymurzina_Kuznetsov_Cherniavskii_Dmitrievskiy_Ermakova_Ignatov_Karpov_Kornev_et al._2019, 2021}.

\begin{figure}[ht]
  \centerfloat{
    \includegraphics[scale=0.27]{latex}
  }
  \caption{Архитектура диалоговой системы DREAM в конкурсе “Alexa Prize Challenge 3”}\label{fig:dream1}
\end{figure}


Диалоговая система DREAM для участия в конкурсе “Alexa Prize Challenge 3” разрабатывалась с нуля, на основе фреймворка “DeepPavlov Agent” -  разработки сотрудников лаборатории нейронных систем и глубокого обучения МФТИ. Разработка DREAM велась с 2019 года.

В связи с тем, что “DeepPavlov Agent” на тот момент находился на раннем этапе своего развития, код “DeepPavlov Agent” был скопирован непосредственно в репозиторий диалоговой системы и редактировался непосредственно в этом репозитории.  

Задача развертывания диалоговой системы на большое число пользователей решалась с использованием Docker Compose. \cite{Overview | Docker Documentation}

На Рисунке 10 представлена верхнеуровневая архитектура диалоговой системы DREAM на момент завершения ее участия в конкурсе “Alexa Prize Challenge 3”. Реплика, поступающая модели DREAM на вход, вместе с Dialog State(в котором хранится информация о диалоге вместе со всеми аннотациями) проходит через аннотаторы(Annotators). На основе аннотаций, полученных от аннотаторов, модуль Skill Selector, пользуясь оригинальным алгоритмом, выбирает навыки для генерации кандидатов на возможный ответ бота. Каждый навык генерирует возможный ответ с определенной степенью уверенности. Данные ответы фильтруются при помощи аннотаторов кандидатов на ответ, этим ответам присваиваются очки от модуля Cobot. На основе аннотаций, очков и фильтрации оригинальный разработанный модуль Response Selector выбирает финальный ответ-кандидат. Данный ответ проходит через постаннотаторы и в таком виде уже доводится до пользователя.

Диалоговая система принимает реплики пользователя на вход в виде текстовой транскрипции. При этом модуль тестовой транскрипции предоставляется компанией Amazon “из коробки”. Заметим, что ошибки этого модуля сами являлись причиной определенного процента ошибок диалоговой системы DREAM(около 10 процентов).

На вход модели, после каждой реплики пользователя, поступает список слов, которые распознала модель. Каждому слову соответствует степень уверенности распознавания речи. Например, после фразы пользователя “alexa how old are you” модель получает на вход от модуля текстовой транскрипции список следующего вида: [(“alexa”: 0.95), “how”:0.96, (“old”:0.8), (“you”: 0.9)]. Заметим, что подобные списки не разделены по предложениям и не имеют пунктуацию. Поэтому, чтобы реплики обрабатывались лучше, диалоговая система использует аннотатор Sentence Segmentation для восстановления пунктуации и разделения реплик на предложения. Кроме этого диалоговая система использует также модель Sentence Rewriting, заменяющую местоимения на сущности, которые были упомянуты ранее в диалоге.


\subsection{Первый этап разработки: навыки и аннотаторы}

На первом этапе разработки ключевыми интегрированными в бота DREAM навыками и аннотаторами, помимо упомянутых выше, являлись:

Удаленные сервисы, предоставленные командой “Amazon” -  классификатор тем CoBot Topics, классификатор диалоговых актов и тем CoBot DialogAct, вопросно-ответная система CoBot QA

Имеющиеся в открытом доступе навыки для диалога на общие темы, построенные на правилах - Alice, AIML Chit-Chat(встроенный под названием program-y). В дальнейшем данные навыки многократно совершенствовались - как в связи с паттернами ответов пользователей, наблюдавшихся в реальных диалогах с системой DREAM, так и в связи со специфичными требованиями правил \cite{SocialBot Grand Challenge Rules - Amazon Science}. Помимо этого, был добавлен навык Intent Responder для ответа на конкретные интенты и навыки-”затычки” Dummy Skill и Dummy Skill Dialog.

\subsection{Аннотаторы}

На следующих этапах разработки добавлялись иные аннотаторы реплик пользователя, часть из которых ( см. Рисунок 10) также использовалась как постаннотаторы для аннотации реплик диалоговой системы. Такие аннотаторы включают в себя:
\begin{itemize}
\item[*] Blacklisted Words Detector - используется для обнаружения нецензурных или просто оскорбительных слов или выражений. Данный аннотатор основан на регулярных выражениях и использует заданный вручную список слов.

\item[*] Intent Catcher - используется для обнаружения одного из 22 интентов. Данный аннотатор работает как на наборе регулярных выражений, обновлявшемся вручную в течение конкурса, так и на модели Universal Sentence Encoder \cite{Cer_Yang_Kong_Hua_Limtiaco_John_Constant_Guajardo-Cespedes_Yuan_Tar_et al._2018} 

\item[*] Toxic Classification - нейросетевой multilabel классификатор, определяющий, относится ли реплика к любому из этих класссов - ненависть, оскорбление, обсценная лексика, очень_токсичный, секс, угроза, токсичный ( identity_hate, insult, obscene, sexual_explicit, threat, toxic). Данный аннотатор основывается на модели “разговорный BERT”, которая является частью библиотеки DeepPavlov и которая была дообучена на данных с Kaggle “Jigsaw Unintended Bias in Toxicity Classification” \cite{Jigsaw Unintended Bias in Toxicity Classification | Kaggle}

\item[*] Sentiment Classification - нейросетевой классификатор тональности, основанный на модели “разговорный BERT” \cite{DeepPavlov/sentiment_sst_conv_bert.json at 0.9.0 · deeppavlov/DeepPavlov · GitHub}, обученной на наборе данных Stanford Sentiment Treebank \cite{Socher_Perelygin_Wu_Chuang_Manning_Ng_Potts_2013}. Классификатор распознает три класса - положительный, отрицательный, нейтральный.

\item[*] Dialog Termination - нейросетевой классификатор - предсказатель завершения диалога. Ближе к концу конкурса, когда у команды DREAM накопилась достаточно большая база диалогов(сотни тысяч), на основе вышеупомянутой модели “разговорный BERT” была обучена модель-постаннотатор, которая для каждой реплики бота определяла вероятность завершения пользователем диалога после этой реплики. На основании очков от этой модели Response Selector фильтровал реплики-кандидаты. Данная модель является личным вкладом автора диссертационной работы.

\item[*] Emotion Classification -  нейросетевой классификатор эмоций, основанный на модели “BERT-Base-uncased”, обученный на наборе данных с Kaggle страницы Eray Yildiz \cite{Eray Yildiz | Novice | Kaggle}. Эти данные содержали 6 классов - ярость, грусть, любовь, радость,удивление, любовь. Для корректной работы классификатора необходимо, чтобы в данных присутствовали также примеры, принадлежащие нейтральному классу. Для этого были добавлены примеры из датасета ScenarioSA \cite{Yazhou Zhang_2019}, которым был присвоен нейтральный класс. Итоговый набор данных сохранен по адресу \cite{Emotion classification dataset (retrieved from Kaggle, supplemented by the neutral example from ScenarioSA dataset)}.
\end{itemize}
Модель \textbf{Emotion Classification} является личным вкладом автора, в связи с чем она описывается более подробно, чем остальные. После первой эпохи при обучении с оптимизатором Adam и скоростью обучения 5*10-5 данной моделью была достигнута точность 94.2\% на валидационном наборе данных. Классификатор обучался как multilabel, но для метрик предсказанным считался самый вероятный класс. Матрица ошибок данного классификатора представлена ниже.


\begin{table}[htbp]
\centering
\caption {Матрица ошибок классификатора эмоций в конкурсе “Alexa Prize Challenge 3”}
\label{tab:dream1}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|c|c|c|c|c|c|c|c}
\hline
Настоящий класс/Предсказанный класс & Ярость & Страх & Удовольствие & Любовь & Грусть & Удивление & Нейтральный\\
\hline
Ярость & 5933 & 49 & 38 & 2 & 22 & 291 & 1 \\
Страх & 263 & 4624 & 18 & 0 & 12 & 1 & 419 \\
Удовольствие & 17 & 5 & 14697 & 1138 & 4 & 27 & 112 \\
Любовь & 1 & 1 & 14 & 3867 & 0 & 4 & 1 \\
Грусть & 6 & 3 & 2 & 1 & 3109 & 0 & 0 \\
Удивление & 48 & 229 & 36 & 7 & 9 & 13725 & 16 \\
Нейтральный & 1 & 2 & 44 & 0 & 0 & 2 & 1609
\hline
\end{tabular}
}
\end{table}



Результат данного классификатора в данном конкурсе использовался навыками обсуждения эмоций и обсуждения коронавируса, которые будут подробнее описаны ниже.
мфти 

Последние 4 описанных модели основаны на подходе, описанном в главе данной диссертации “Предварительно обученные языковые модели” с дообучением данных языковых моделей на конкретную задачу. 

\subsection{Навыки открытого домена}

В течение конкурса командой DREAM активно создавались навыки открытого домена для того, чтобы как можно большее число тем было покрыто хотя бы на минимальном уровне. Были созданы следующие навыки открытого домена:

TF-IDF Retrieval использует диалоги за прошлый месяц, получившие хорошую оценку (5) и плохую (1-2). Получая на вход пользовательскую фразу, он строит TF-IDF векторное представление данной фразы и выбирает фразу бота из получивших хорошую оценку диалогов, максимально близкую по косинусному расстоянию к данной пользовательской фразе и не принадлежащую при этом к множеству диалогов, получивших плохую оценку. Уверенность данного навыка соответствует косинусному расстоянию между векторными представлениями фразы пользователя и бота, но не превышает при этом некоторе постоянное значение. Векторизатор для получения представлений был обучен на конкатенации датасетов TopicalChat\cite{Karthik Gopalakrishnan_2019}, PersonaChat \cite{Zhang_Dinan_Urbanek_Szlam_Kiela_Weston_2018} и Wizard of Wikipedia \cite{Emily Dinan_2018}. Разработка данного навыка относится к личному вкладу автора.  Это единственный навык, который интегрировал в себя новые диалоговые данные из конкурса в автоматическом режиме.

В дальнейшем было также обучено подмножество аналогичных навыков, покрывающих разные темы из датасета TopicalChat  - книги, развлечения, мода, фильмы, музыка, политика, технологии, спорт и животные - каждый на основе соответствующего набора данных из TopicalChat. 


Генеративный навык является другой разработкой автора. В данном навыке использовалась модель типа GPT\cite{Radford_Narasimhan_Salimans_Sutskever_2018} с добавлением “персоны” для улучшения качества генерации модели. Данная модель дообучалась в различных экспериментах на PersonaChat, на TopicalChat, на Wizards of Wikipedia или на сочетании всех этих датасетов. В качестве персоны(сообщения, исходя из которого генерировалась дальнейшая реплика) в данных экспериментах использовались в качестве условия для генерации, соответственно, персона для примеров из датасета PersonaChat, одно из предложений, на которое была отсылка в Wizards of Wikipedia(далее - WOW) для примеров из Wizards of Wikipedia и один из наиболее релевантных фактов, связанных с этой фразой(по TF-IDF) для примеров из TopicalChat. Максимальная длина предложения со всей диалоговой историей и персоной равнялась 512 токенов.  Данная модель продолжает проводившуюся ранее автором работу над диалоговой моделью “с персоной” \cite{Болотин_Карпов_Рашков_Шкурак_2019}.

Несмотря на хорошие результаты по метрике perplexity(см. Таблица 2) навык не был включен в систему DREAM из-за своей недостаточной логической консистентности.


\begin{table} [htbp]%
    \centering
    \parbox{9cm}{
    \caption{Точность (перплексия) для генеративного навыка}%
    \label{tab:dream2}% label всегда желательно идти после caption
    \renewcommand{\arraystretch}{1.5}%% Увеличение расстояния между рядами, для улучшения восприятия.
    \begin{SingleSpace}
        \begin{tabular}{@{}@{\extracolsep{20pt}}llllllll@{}} %Вертикальные полосы не используются принципиально, как и лишние горизонтальные (допускается по ГОСТ 2.105 пункт 4.4.5) % @{} позволяет прижиматься к краям
            \toprule     %%% верхняя линейка
            Модель & Метрики на PersonaChat & Метрики на TopicalChat & Метрики на WOW & Метрики на всех 3 датасетах \\
            \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5
GPT обученный на PersonaChat & 90(12.3) & - & - & - \\
GPT обученный на TopicalChat & - & 96(9.7) & - & - \\
GPT обученный на  WOW & - & - & 86.7(27.2) & - \\
GPT обученный на всех 3 датасетах & 86(14.2) & 92(11.6) & 83(31.5) & 92(16.3) \\
        \end{tabular}%
    \end{SingleSpace}
    }
\end{table}


ConveRT Reddit - нейросетевой ранжирующий навык, обученный на наборе комментариев с сайта REDDIT \cite{Reddit - Dive into anything} (отфильтрованном аннотаторами Cobot Conversation Evaluator и Toxic Classifier до 80 тыс.примеров) и использующий нейросетевую модель CONVERT \cite{Henderson_Casanueva_Mrkšic_Su_Vulic_Others_2019} для получения векторных представления реплики и контекста(конкатенации предыдущих реплик). Данная модель вместо модели BERT была выбрана в целях экономии вычислительных ресурсов и для повышения быстродействия.

\subsection{Навыки закрытого домена}

Тем не менее, вышеупомянутых навыков все еще в большинстве случаев было недостаточно для того, чтобы вести долгий, логически завершенный диалог на популярные темы. В связи с этим также был создан ряд навыков закрытого домена, основанных на правилах, использовании нейросетевых аннотаций и при необходимости делающий внешние запросы. Такие навыки, как Movie Skill, Game Skill, News Skill, Weather Skill, Small Talk Skill, Personal Info Skill, News Skill, Christmas Skill, Valentine’s Day Skill, Superbowl Skill, Oscar Skill, подробно описаны в \cite{Baymurzina_Kuznetsov_Evseev_Karpov_Sagirova_Peganov_Ignatov_Ermakova_Cherniavskii_Kumeyko_et al._2021,Kuratov_Yusupov_Baymurzina_Kuznetsov_Cherniavskii_Dmitrievskiy_Ermakova_Ignatov_Karpov_Kornev_et al._2019, 2021}. Ниже будут описаны три навыка закрытого домена, являющихся личным вкладом автора.

Emotion Skill возвращает шаблонные ответы на эмоции, обнаруженные аннотатором Emotion Classification.В частности, навык может подсказать совет,рассказать шутку или успокоить пользователя. Основная часть навыка была разработана автором самостоятельно.

Book Skill, используя базу данных Amazon Evi \cite{Evi(software) - Wikipedia}, находит названия книг и фамилии авторов. Используя данные именованные сущности, навык поддерживает разговор о данных книгах либо авторах. Помимо этого, навык также может рекомендовать книги, используя информацию из базы данных GoodReads \cite{Goodreads | Meet your next favorite book} и аннотации из модели CoBot. Одной из технических проблем при разработке данного навыка являлось то, что некоторые названия книг заставляли реагировать и Book Skill, и Emotion Skill. Проблема была решена при помощи изменения уверенности навыка Book Skill в таких ситуациях.

Coronavirus Skill был добавлен на завершающем этапе конкурса, когда в связи с эпидемией COVID-19 (дело происходило в марте-июне 2020 года) пользователи стали часто поднимать эту тему в разговорах с диалоговой системой DREAM. Навык использовал данные о случаях коронавируса и смертях от него, взятых из Центра системной научной инженерии Университета Джона Хопкинса \cite{GitHub - CSSEGISandData/COVID-19: Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE}. Навык использует факты, сравнения и научно обоснованные советы для того, чтобы успокоить пользователя с учетом его возраста. Навык использует аннотации от Emotion Classification.

\subsection{Response Selector и Skill Selector}

При большом числе сценарных навыков, у многих пользователей тем не менее в середине конкурса возникали трудности с тем, чтобы “попасть” в какой-то конкретный навык. В связи с этим диалог часто становился логически неконсистентным. Для решения данной проблемы был реализован метод “направляющих вопросов”, подразумевающих в качестве ответа мнение пользователя о заданной теме и/или выбор пользователем конкретной темы для обсуждения ( фильма, книги, игры). Данные вопросы могли добавляться как на уровне навыка, так и на уровне Response Selector. Как показано в \cite{Kuratov_Yusupov_Baymurzina_Kuznetsov_Cherniavskii_Dmitrievskiy_Ermakova_Ignatov_Karpov_Kornev_et al._2019, 2021}, использование подобного метода помогло повысить рейтинг диалоговой системы.
Алгоритм выбора навыков Skill Selector основан на постоянном включении нетематических навыков, включении тематических навыков при определенных условиях на аннотации реплики пользователя и использовании специального режима при обработке реплик, классифицированных Toxic Classification как токсичные или просто принадлежащим к “острым” темам. Подробнее данный алгоритм описан в работе \cite{Баймурзина_2021}.
Алгоритм выбора ответа Response Selector в начале участия команды DREAM в конкурсе просто выбирал навык с максимальной уверенностью. В дальнейшем туда были интегрированы оценки от Cobot Conversation Evaluator, фильтрация с использованием постаннотаторов и набор иных эвристик. Подробнее данный алгоритм описан в той же работе \cite{Баймурзина_2021}.
\subsection{Вклад автора работы}
Аннотаторы Emotion Classification и Dialog Termination, навыки открытого домена TF-IDF Retrieval и генеративный навык, а также навыки закрытого домена Book Skill, Coronavirus Skill и (в своей основной части) Emotion Skill были разработаны автором данной диссертационной работы самостоятельно.
В работе \cite{Kuratov_Yusupov_Baymurzina_Kuznetsov_Cherniavskii_Dmitrievskiy_Ermakova_Ignatov_Karpov_Kornev_et al._2019} показано, что использование Book skill и TF-IDF Retrieval помогло повысить рейтинг диалоговой системы в декабре 2019 года с 3.01 до 3.19.  В конце января-начале февраля 2020 года добавление истории диалога в TF-IDF Retrieval помогло дополнительно повысить рейтинг диалоговой системы до 3.25.  Также в начале февраля 2020 года года, несмотря на общее падение рейтингов диалоговой системы(вероятно, связанное  с беспокойством пользователей по поводу новой коронавирусной инфекции), улучшение навыка Emotion Skill помогло повысить медианное время диалога с 58 до 73 секунд. Прирост рейтинга диалоговой системы в начале марта 2020 года был вероятно связан с добавлением и улучшением навыка Coronavirus Skill.

\section{Архитектура диалоговой системы DREAM в “Alexa Prize Challenge 4”}


\begin{figure}[ht]
  \includegraphics[scale=0.27]{latex}
  \caption{Архитектура диалоговой системы DREAM в конкурсе “Alexa Prize Challenge 4”}\label{fig:dream2}
\end{figure}
Диалоговая система DREAM для участия в конкурсе следующего, 2021 года основывалась на доработанной системе прошлого года. Её схема представлена на рисунке 11.


Задача развертывания диалоговой системы решалась с использованием Kubernetes. \cite{Kubernetes - Wikipedia}
Ключевые принципы работы диалоговой системы остались прежними, однако ее аннотаторы и навыки поменялись следующим образом.

\subsection{Изменения, связанные с аннотаторами}

Одним из главных изменений, сделанных в диалоговой системе DREAM, являлась оптимизация вычислительных мощностей для экономии видеопамяти. Это было связано с высокими издержками на эксплуатацию данных мощностей - каждый месяц расходовалось “кредитов” вычислительных мощностей на сумму до 9 тысяч долларов США. Для данной оптимизации шесть моделей-классификаторов: Emotion Classifier, Sentiment Classifier, Toxic Classifier, CoBot Topic Classifier и CoBot DialogAct Classifier (последний классификатор считался за 2, т.к возвращал тему и интент) были объединены в один классификатор Combined Classifier. В условиях острого дефицита временных ресурсов, связанного с быстрой динамикой конкурса, был выбран способ реализации многозадачного обучения “Независимые метки” из статьи  \cite{Karpov_Burtsev_2021}, описанный также в разделе “Использование псевдоразметки данных в многозадачных моделях для решения задач     GLUE и SuperGLUE”. Подробнее эксперименты, связанные с обучением данной модели, описаны ниже в разделе “Использование в диалоговой системе DREAM многозадачных моделей”. Данная модель использовалась как постаннотатор всё время конкурса, а как классификатор пользовательских фраз - при условии, что получение аннотаций от CoBot невозможно или задерживается(т.к модель CoBot имеет лимит на количество входящих запросов, такие ситуации возникали),  Данная модель является личным вкладом автора диссертационной работы. 
Другим важным изменением является добавление модели для классификации диалоговых актов MIDAS Classifier, обученной на базе набора данных MIDAS \cite{Yu_Yu_2019}. На первом этапе, в феврале, была интегрирована предоставленная авторами модель, на втором, в апреле, она была заменена собственной моделью, обученной только на семантических классах из данного набора данных, так как в модели DREAM используется только этот набор классов. 

Полный список используемых семантических классов:
\begin{itemize}
\item[*] открытый вопрос/мнение (open_question_opinion)
\item[*] открытый личный вопрос(open_question_personal)
\item[*] вопрос да/нет(yes_no_question)
\item[*] вопрос для пояснения(clarifying_question)
\item[*] команда(command)
\item[*] неверная команда (dev_command)
\item[*] признательность(appreciation)
\item[*] мнение(opinion)
\item[*] жалоба(complaint)
\item[*] комментарий(comment)
\item[*] утверждение(statement)
\item[*] другие ответы(other_answers)
\item[*] положительный ответ(pos_answer)
\item[*] отрицательный ответ(neg_answer)
\item[*] открытый фактический вопрос(open_question_factual)
\end{itemize}
Обе модели были обучены на основе вышеупомянутой модели “разговорный BERT”.  Работа над данным аннотатором тоже является личным вкладом автора диссертационной работы. 
Помимо этого, с середины конкурса использовался аннотатор Cobot Entities от Amazon как удаленный сервис. Данный аннотатор извлекал сущности и классифицировал их на несколько видов.
Также для рекомендации пользователю следующей темы (поддерживаемой имеющимся сценарным навыком) на основании текущего контекста был создан аннотатор Topic Recommendation, подробно описанный в \cite{Baymurzina_Kuznetsov_Evseev_Karpov_Sagirova_Peganov_Ignatov_Ermakova_Cherniavskii_Kumeyko_et al._2021}.
Одним из ключевых изменений стала интеграция баз знаний - добавление компонентов Entity Linking, Wiki Parser и Fact Retrieval.Компонент Fact Retrieval получает для распознанных Cobot Entities сущностей факты из Википедии и WikiHow \cite{wikiHow: How-to instructions you can trust.}.  Компонент Entity Linking соотносит каждую сущность, распознанную Cobot Entities, с идентификатором в системе WikiData \cite{Vrandečić_Krötzsch_2014}. Компонент Wiki Parser извлекает из этих идентификаторов триплеты - наборы (субъект, соотношение, объект). Entity Linking и Wiki Parser широко использовались в навыках закрытого домена, таких, как Book Skill и Gossip Skill, что позволило существенно улучшить их качество работы.
Также из всех навыков, которые делали запрос к удаленным сервисам(пример -  Cobot QA, News API Skill), модули запросов были оформлены как отдельные аннотаторы, что позволяло делиться полученной информацией между навыками.
Для того, чтобы определять, задал ли пользователь фактоидный вопрос ( что в соответствии с алгоритмом, описанным в \cite{Baymurzina_Kuznetsov_Evseev_Karpov_Sagirova_Peganov_Ignatov_Ermakova_Cherniavskii_Kumeyko_et al._2021}, определяет приоритетность включения части упомянутых выше навыков), был также добавлен аннотатор Factoid Classification. Этот аннотатор был основан на модели BERT, обученной на наборе данных YAHOO ССЫЛКА.
Помимо добавления новых навыков, инкрементальным улучшениям подвергались и старые навыки. В частности, автор работы большое время посвятил работе над Intent Catcher. 

\subsection{Изменения, связанные со сценарными навыками}
Одной из ключевых проблем, с которыми сталкивалась диалоговая система DREAM на момент проведения конкурса “Alexa Prize Challenge 3”, являлось недостаточное количество сценарных навыков. (У команды-победителя сценарные навыки покрывали больше популярных тем на разговор хотя бы в несколько шагов, чем у команды DREAM). Те сценарные навыки, которые были реализованы, не были унифицированы распространялись на другие темы, в связи с чем качество разговоров бота на многие темы были низкими, также возникали сложности с отладкой навыка человеком, который его не разрабатывал. Для решения этой проблемы Денисом Кузнецовым был разработан фреймворк для построения диалоговых систем Dialog Flow Framework(DFF) \cite{Dialog Flow Framework}  , позволяющий удобно записывать сценарий для диалогового графа. На основе данного фреймворка было разработано большое количество сценарных тематических навыков - Animals Skill, Food Skill, Sport Skill, Science Skill, Music Skill, Gossip Skill, Gaming Skill, Bot Persona Skill, Travel Skill, а также переведен на использование DFF навык Movie Skill. Разработка подобных сценарных навыков позволила отключить использование соответствующих ранжирующих навыков, основанных на TF-IDF.

Помимо Book Skill, Coronavirus Skill и Emotion Skill,автор диссертационной работы отвечал еще за 2 сценарных навыка.
Одним из этих навыков был Grounding Skill. Навык решал задачу установления взаимопонимания с пользователем. Используя информацию из истории диалога о том, какие сущности были упомянуты и какие были намерения у пользователя и у бота, навык генерирует шаблонную фразу-подтверждение. Этой фразой навык показывает, что бот понимает, о чем говорит пользователь. Например, если в аннотациях фразу есть сущность Fortnite и интент Opinion_RequestIntent, навык выдает фразу “You wanted to hear my thoughts about Fortnite, am I correct?"

Другим навыком являлся Gossip Skill. В этом навыке отношение диалоговой к различным знаменитостям определялось случайно, и навык, используя WikiData и тональность реплики пользователя при его разговоре о той или иной знаменитости, обсуждал их. За работу над этим навыком автор диссертационной работы отвечал не все время(в отличие от первого навыка), но значительную часть времени.

\subsection{Изменения, связанные с навыками открытого домена}

Хотя сценарные навыки позволили “вытягивать” значительное число диалогов и улучшить тем самым их рейтинг, они все еще не могли покрыть все популярные темы и их подтемы. Для решения данной задачи были разработаны следующие навыки открытого домена, помимо упомянутых выше:
\begin{itemize}
\item[*] Knowledge Grounding Skill - нейросетевая генеративная модель ParlAI Blender 90M \cite{Roller_Dinan_Goyal_Da Ju_Williamson_Liu_Xu_Ott_Shuster_Smith_et al._2020}, дообученная на наборе диалогов Topical Chat Enriched \cite{Hedayatnia_Kim_Liu_Gopalakrishnan_Eric_Hakkani-Tur_2020}.
\item[*] Wiki Skill - универсальный сценарный навык открытого домена. Он может обсуждать найденные в репликах пользователя сущности с использованием соответствующей страницы Википедии, что позволяет вести логически консистентный диалог по большому количеству популярных объектов, которые находятся за пределами внимания сценарных навыков.
\end{itemize}
'subsection{Изменения Response Selector и Skill Selector}

Ключевые изменения в Response Selector и Skill Selector включали в себя более плавные переходы между парами тем; использование специфичных переходных фраз, относящихся к 2 темам одновременно, либо обычных связующих фраз как во время конкурса “Alexa Prize Challenge 3”, но вместе со связующими фактами. 
Помимо этого, в связи с ростом количества и разнообразия сценарных навыков одной только уверенности перестало хватать для определения очередности их включения. В связи с этим сценарные навыки была добавлена приоритизация с возможными флагами продолжения “can continue”, “can not continue” и “must continue”.
Подробнее обо всех изменениях в алгоритмах Response Selector и Skill Selector можно прочитать в работе \cite{Баймурзина_2021}.

\subsection{Вклад автора работы}
Личным вкладом автора данной диссертационной работы является:
\begin{itemize}
\item[*] Обучение и интеграция классификационной многозадачной нейросетевой модели “6 в 1” (Combined Classification), что помогло сэкономить вычислительные ресурсы(данные эксперименты подробнее описаны в следующих разделах)
\item[*] Обучение модели классификации интентов на основе семантических классов из набора данных MIDAS (Midas Classification), до этого - интеграция предобученной модели, обученной на всем наборе данных MIDAS
\item[*] Разработка сценарного навыка Grounding Skill, значительное участие в разработке навыка закрытого домена Gossip skill
\item[*] Значительное улучшение сценарных навыков Book Skill(на основе Wikidata), Emotion Skill и аннотатора Intent Catcher. Технические решения, применяемые при работе над этими навыками, использовались также в сторонней работе автора, на которую получено свидетельство о депонировании \cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}.
\item[*] Активное участие в отладке других навыков и аннотаторов на основе ежедневного анализа диалогов системы DREAM и ее личного тестирования
\end{itemize}

В конце февраля-начале марта, как показано  в работе \cite{Baymurzina_Kuznetsov_Evseev_Karpov_Sagirova_Peganov_Ignatov_Ermakova_Cherniavskii_Kumeyko_et al._2021}, интеграция Midas Classification и изменение модели диалога в сторону более частого показа Book Skill помогли поднять рейтинг диалоговой системы DREAM с ~3.11 до ~3.28. 

