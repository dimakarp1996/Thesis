  \chapter{  Использование в диалоговой системе DREAM многозадачных моделей}\label{ch:mtldream} 

\section{Использование многозадачных моделей с одним линейным слоем }
\subsection{Использование многозадачных моделей с одним линейным слоем для объединения и замены классификаторов реплик}
Автором данной диссертационной работы многозадачные модели для диалоговой системы DREAM начали использоваться во время конкурса Alexa Prize Challenge 4.Необходимость использования многозадачных моделей была обусловлена как необходимостью экономии вычислительных ресурсов(в первую очередь видеопамяти),
так и лимитом на количество ежедневных запросов к сервисам Amazon, который часто превышался в условиях интенсивных нагрузок конкурса.В связи с этим, была поставлена задача объединить шесть моделей - модель для классификации эмоций(далее будет использоваться также название emotion classification), модель для классификации тональности(далее будет использоваться также название sentiment classification), модель для классификации токсичности(далее будет использоваться также название toxic classification), модель Cobot Topics, модель Cobot DialogAct Topics и модель Cobot DialogAct Intents. 

Первой версией многозадачной модели, использовавшейся в диалоговой системе DREAM, являлась модель, имеющая такую же архитектуру,
как и модель, описанная в главе \label{ch:pseudolabel}.

 Заметим, что набор данных из конкурса Alexa Prize Challenge 3 для обучения модели имел следующую особенность - все пользовательские фразы имели аннотации сразу от всех моделей. В связи с этим, модель BERT в первой серии экспериментов обучалась на этих данных, получая на вход предсказания этих моделей(сохранённые в архиве диалогов во время конкурса) в качестве меток. Иными словами, использовался подход, аналогичный подходу "Жёсткие независимые метки" из вышеупомянутого раздела, но без объединения меток. 
 
Все имеющиеся данные были поделены в пропорции 90/8/2 между тренировочным, тестовым и валидационным датасетом. Перед делением были отфильтрованы дубликаты среди фраз. В первом экспериментальном сеттинге каждой фразе присваивалась наиболее часто встречаемая метка для данной фразы и задачи (если встречалось более 1 метки). 

В первой серии экспериментов сравнивались следующие способы обучения:
\begin{itemize}
\item[*] Обучение отдельной модели BERT для каждой из задач
\item[*] Обучение одной модели BERT для трех задач Cobot и другой - для трех остальных задач
\item[*] Обучение одной модели BERT для всех 6 задач
\end{itemize}

Все эти способы сравнивались не только друг с другом, но и (для не-Коботовских задач) с результатами оригинальной модели. 

Особо отмечаю, что "чистого" набора данных для решения Коботовских задач автор диссертационной работы не имел, а те диалоговые данные, что были доступны автору, было запрещено отдавать на разметку в связи с соображениями пользовательской приватности. По этой причине модели, заменяющие Коботовские сервисы (Cobot Topics, Cobot DialogAct Topics, Cobot DialogAct Intents) оценивались исключительно по соответствию своих предсказаний предсказаниям оригинальных моделей(на тестовом разбиении). Соответственно, оригинальные модели Cobot Topics, Cobot Dialogact Topics и Cobot Dialogact Intents в рамках данного эксперимента(как и всех упомянутых ниже) имеют accuracy и f1, равные 1. 

Модели для классификации эмоций, сентимента и токсичности оценивались на тестовых частях своих наборов данных\cite{socher_2013},\cite{na_website_ndo_emo},\cite{na_website_ndm_toxic} . 


Отметим также, что для каждой из задач могло быть предсказано больше 1 метки.
Максимальная длина предложения в проводимых экспериментах равнялась 32 токена, скорость обучения равнялась \num{1e-5}. Использовался оптимизатор AdamW с параметром decay, равным 0.01. В качестве F1-метрики использовался macro-f1. Размер батча считался равным 128. Тренировка запускалась без ограничений по числу эпох, но с остановкой в случае неулучшения средней точности в течение 5 эпох.



\begin{table}[htbp]
\centering
\caption {Accuracy(f1) без диалоговой истории для многозадачной модели с одним линейным слоем}
\label{mtldream:1}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|}
\hline
Задача | Модель & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории\end{tabular}  & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории \\ жесткие метки\end{tabular} &  \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ без истории \\ жесткие метки\end{tabular} & \begin{tabular}[c]{@{}l@{}}Оригинальные\\ модели\end{tabular} \\
\hline
cobot topics & \textbf{0.819(0.8)} & 0.802(0.781) & 0.818(0.795) & 1(1) \\
\hline
cobot dialogact topics & 0.805(0.626) & 0.799(0.616) & \textbf{0.814(0.632)} & 1(1) \\
\hline
cobot dialogact intents & 0.752(0.635) & 0.745(0.626) & \textbf{0.767(0.63)} & 1(1) \\
\hline
emotion classification & 0.401(0.245) & 0.72(0.641) & \textbf{0.788(0.754)} & 0.92(0.751) \\
\hline
sentiment classification & 0.683(0.607) & 0.727(0.609) & \textbf{0.733(0.585)} & 0.721(0.681) \\
\hline
toxic classification & 0.932(0.194) & 0.931(0.18) & \textbf{0.935(0.186)} & 0.922(0.596) \\
\hline
factoid classification & 0.805(0.806) & 0.816(0.814) & \textbf{0.829(0.831)} & 0.886(0.884) \\
\hline
\end{tabular}
}
\end{table}



После этой серии экспериментов, была проведена следующая серия для того, чтобы доказать, что добавление диалоговой истории улучшает показатели моделей, заменяющих Коботовские. Данное предположение было обусловлено тем, что API модели Cobot DialogAct от Amazon, классифицирующей темы и интенты, принимало на вход историю диалога. 
Для проверки этого предположения был сформирован новый набор Коботовских данных, разбитый между тренировочной, тестовой и валидационной выборкой в пропорции 80/10/10. Каждый из примеров содержал историю диалога (максимум 3 предыдущие фразы), конкатенированную с последней фразой через токен [SEP] . Заметим, что данный шаг влечет за собой увеличение размера датасета, так как одной и той же финальной фразе могут соответствовать несколько примеров. Фильтрация дубликатов осуществлялась как на уровне фразы, так и на уровне диалога - ни один диалог из тестовой выборки и ни одна фраза из тестовой выборки не могли быть в тренировочной или валидационной выборке. Как и в предыдущей серии экспериментов, предсказания модели от Amazon использовались как "настоящие" метки. Максимальная длина предложения была повышена с 32 до 64. Все остальные параметры были аналогичны предыдущей серии экспериментов.


\begin{table}[htbp]
\centering
\caption {Accuracy(f1) с диалоговой историей для многозадачной модели с 1 линейным слоем, только Коботовские задачи}
\label{mtldream:2}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|}
\hline
Задача | Модель & \begin{tabular}[c]{@{}l@{}}Без истории\\ 1 модель\end{tabular} & \begin{tabular}[c]{@{}l@{}}С историей\\ 1 модель \end{tabular} & \begin{tabular}[c]{@{}l@{}}Без истории\\ 3 разные модели\end{tabular} & \begin{tabular}[c]{@{}l@{}}С историей\\ 3 разные модели \end{tabular} \\
\hline
\hline
cobot topics & \textbf{0.795(0.818)} & 0.785(0.814) & \textbf{0.804(0.828)} & 0.802(0.825) \\
\hline
cobot dialogact topics & 0.752(0.683) & \textbf{0.841(0.82)} & 0.759(0.685) & \textbf{0.837(0.816)} \\
\hline
cobot dialogact intents & 0.666(0.669) & \textbf{0.777(0.755)} & 0.672(0.668) & \textbf{0.779(0.765)} \\
\hline
Видеопамять, Мб & 3500 & 3502 & 10500 & 10506 \\     
\hline
\end{tabular}
}
\end{table}

Данный эксперимент показал потенциал улучшения качества многозадачной модели. Тем не менее, в связи с ограничением по вычислительным мощностям, было принято решение не увеличивать размер входа многозадачной модели с 32 до 64 и не добавлять туда историю. Такому решению также способствовал тот факт, что большинство выявлявшихся на Коботовских задачах при ручном тестировании ошибок многозадачной модели  было связано не с несоответствием выхода многозадачной модели выходу оригинальной модели, а с неидеальностью самой разметки, использовавшейся при обучении. 
На задачах же, на которых у нас была "чистая" разметка, просадка, связанная с использованием многозадачной модели, была относительно небольшой (у классификаторов эмоций и тональности точность упала на 6\%, f1 упало для классификатора эмоций на 7\%,для классификатора тональности на 10\%). Данные показатели были сочтены приемлемыми. Именно поэтому классификатор без истории был встроен в диалоговую систему DREAM, он же использовался в этой системе в течение всего конкурса Alexa Prize Challenge 4.

\subsection{Использование многозадачных моделей с одним линейным слоем для замены модели для оценки диалога}
Другой классификационной моделью с одним линейным слоем, использовавшейся в диалоговой системе DREAM, стала замена CoBot Conversation Evaluator. Данная модель была встроена после окончания конкурса Alexa Prize Challenge 4(в сентябре 2021 года) с тем, чтобы после прекращения доступа к Amazon API продолжать получать оценки диалога по 5 параметрам: isResponseInteresting(ответ интересный), responseEngagesUser(ответ развлекает пользователя), isResponseComprehensible(ответ понятный), isResponseErroneous(ответ ошибочный), isResponseOnTopic(ответ по теме). Обученный на массиве диалогов из Alexa Prize Challenge 4, линейный слой предсказывал вектор из 5 величин от 0 до 1, метрик для мониторинга считалась средним квадратичным отклонением. 

Размер батча равнялся 32, максимальный размер диалога - 128 токенов, все остальные параметры обучения были как в предыдущем эксперименте. Размер тренировочной выборки составлял 11456585 диалогов(75\%), тестовой 356250 тыс(2.23\%),валидационной 3462611 тыс(22.67\%).  Дубликаты фильтровались на уровне фразы.

При помощи нейросетевой модели было достигнуто СКО равное 0.31 на тестовом наборе данных. Данный уровень СКО был сочтен достаточно хорошим для использования в диалоговой системе DREAM, дальнейшие возможности его улучшения не изучались.


\section{Использование модели PAL-BERT в диалоговой системе DREAM} 

Летом 2021 года под руководством автора диссертационной работы модель типа PAL-BERT \cite{stickland_2019} была успешно встроена в одну из веток библиотеки DeepPavlov. Это дало возможность провести серию экспериментов для того, чтобы исследовать возможности дальнейшего улучшения качества и покрытия многозадачной модели в диалоговой системе DREAM. Везде в нижеописанных экспериментах в модели PAL-BERT использовался  тип сэмплирования annealed с рекомендованными авторами работы \cite{stickland_2019} параметрами.

Заметим, что во всех нижеописанных экспериментах использовались только те предсказания модели Cobot на диалогах DREAM, которые были получены после 10 февраля 2021, т.к именно в этот день Amazon обновил свою модель.

На момент проведения экспериментов, модель PAL-BERT поддерживала только решение single-label задач (1 задача - 1 класс) в связи с техническими особенностями имплементации. В связи с этим, полученные наборы данных для классификации токсичности и для классификации Коботовских данных были переработаны следующим образом. Примерам, у которых вероятность каждого токсичного класса была ниже 0.5, был присвоен класс "не токсичный", остальным самый вероятный класс (или самый редко встречаемый, если 2 класса имеют одинаковую вероятность).

Аналогичным образом были переработаны и наборы для классификации Коботовских данных, так как часть из них имела больше 1 метки(т.к на вход Cobot API  подавалась фраза пользователя, разбитая аннотатором SentSeg на предложения, было около 5\% таких случаев). 

В первом эксперименте модель PAL-BERT была сравнена с моделью-заменой Cobot, аналогичной предыдущему разделу, на объединении трех задач - cobot topics, cobot dialogact topics и cobot dialogact intents, без истории и с размером батча 32.

\begin{table}[htbp]
\centering
\caption {Accuracy(f1) с диалоговой историей для многозадачной модели с 1 линейным слоем, только Коботовские задачи}
\label{mtldream:3}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|}
\hline
Задача | Модель & Модель с одним линейным слоем & PAL-BERT \\
\hline
\hline
cobot topics & 0.826(0.606) & \textbf{0.828(0.807)} \\
\hline
cobot dialogact topics & 0.803(0.626) & \textbf{0.816(0.637)} \\
\hline
cobot dialogact intents & 0.763(0.637) & \textbf{0.774(0.639)} \\  
\hline
\end{tabular}
}
\end{table}

Заметим, что в связи с другим набором данных и разбиением, данные метрики не сопоставимы с метриками из таблицы ~\ref{mtldream:2}.
 
В данном эксперименте модель PAL-BERT показала себя лучше, чем модель с 1 линейным слоем, но для окончательных выводов необходимо более подробное сравнение.

Во втором эксперименте была поставлена цель объединить предсказания для 7 задач. К задачам классификации токсичности, эмоций, тональности, cobot topics, cobot dialogact topics и cobot dialogact intent была добавлена задача классификации фактоидности вопроса. Актуальность добавления этой задачи была обусловлена добавлением в языковую модель DREAM навыков, применение которых зависит от того, является вопрос фактоидным или нет.

Для обучения использовались данные с Alexa Prize 4, собранные после 10 февраля 2021 года. Использовались только примеры, имеющие метки от Коботовских моделей. Размер тренировочной выборки составлял 1024617 примеров(75\%), размер валидационной выборки 235482 примера(17.23\%), размер тестовой выборки 106056 примеров(7.76\%)

Каждый из таких примеров был дополнительно размечен существующими однозадачными моделями Sentiment Classification, Emotion Classification, Toxic Classification и Factoid Classification. Размеры каждого из наборов данных до и после дополнительной псевдоразметки подробнее указаны в Приложении. 

Разметка для всех задач была переведена в режим “1 задача - 1 метка” следующим образом:
\begin{itemize}
\item[*] Для задач классификации токсичности, был добавлен класс “не токсичный”({not\_toxic}) с вероятностью, такой, что ее сумма с максимальной вероятностью любого токсичного класса равняется 1
\item[*] Для задач классификации эмоций, вероятность нейтрального класса была сокращена до 0, если вероятность любого не-нейтрального класса была больше, чем 0.5.
\item[*] Для задач cobot topics, cobot dialogact topics и cobot dialogact intents, если классов было больше 1, выбирался реже всего встречаемый класс.
\end{itemize}
Все полученные таким образом вероятности были нормализованы по L2-метрике.

Ниже приводится сравнение для 3 экспериментов, проведенных на этих данных:
\begin{itemize}
\item[*] Модель “7 в 1, без истории”, как в разделе “Использование многозадачных моделей с одним линейным слоем для объединения и замены классификаторов реплик”. 
\item[*] Модель “7 в 1,без истории, жесткие метки” - как предыдущая, но с использованием жестких меток - там, где предсказанные вероятности использовались как метки, максимальная вероятность считалась равной 1, а остальные считались равными 0. 
\item[*] Модель “PAL-BERT, без истории, жесткие метки” училась на тех же данных, что и предыдущие, но использовала архитектуру PAL-BERT. Также размер батча равнялся не 32, а 64(с 2 шагами аккумуляции градиента). Приводятся данные только по обучению модели PAL-BERT на “жестких” метках, так как без их “огрубления” модель показала слишком высокую склонность к переобучению.
\end{itemize}
Данные модели оценивались как на используемом наборе данных, так и  (для не-Коботовских задач) на “чистых” наборах тестовых данных из “своих” датасетов.В случае, если для задачи есть “чистый” набор только у валидационных данных, он же и считался набором у тестовых данных.
Предсказания модели вида “7 в 1” для каждой задачи переводились в режим “1 пример - 1 метка” следующим образом - предсказанной меткой считалась метка, имеющая максимальную вероятность из предсказанных.

\begin{table}[htbp]
\centering
\caption {Accuracy(f1) с диалоговой историей для многозадачной модели с 1 линейным слоем и PAL-BERT на псевдоразмеченных данных из Alexa Prize Challenge 4, оценка на “чистых” тестовых данных для не-коботовских задач и на псевдоразмеченных для коботовских задач.}
\label{mtldream:4}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|}
\hline
Задача | Модель & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории\end{tabular}  & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории \\ жесткие метки\end{tabular} &  \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ без истории \\ жесткие метки\end{tabular} & \begin{tabular}[c]{@{}l@{}}Оригинальные\\ модели\end{tabular} \\

\hline
\hline
cobot topics & \textbf{0.819(0.8)} & 0.802(0.781) & 0.818(0.795) & 1(1) \\
\hline
cobot dialogact topics & 0.805(0.626) & 0.799(0.616) & \textbf{0.814(0.632)} & 1(1) \\
\hline
cobot dialogact intents & 0.752(0.635) & 0.745(0.626) & \textbf{0.767(0.63)} & 1(1) \\
\hline
emotion classification & 0.401(0.245) & 0.72(0.641) & \textbf{0.788(0.754)} & 0.92(0.751) \\
\hline
sentiment classification & 0.683(0.607) & 0.727(0.609) & \textbf{0.733(0.585)} & 0.721(0.681) \\
\hline
toxic classification & 0.932(0.194) & 0.931(0.18) & \textbf{0.935(0.186)} & 0.922(0.596) \\
\hline
factoid classification & 0.805(0.806) & 0.816(0.814) & \textbf{0.829(0.831)} & 0.886(0.884) \\
\hline
\end{tabular}
}
\end{table}

Низкие показатели классификатора эмоций в “7 в 1, без истории” связаны с несоответствием между количеством меток в “ чистых” тестовых данных(1 пример - 1 метка) и “многометочных” тренировочных данных(в которых у 1 примера может быть много меток, т.к используемый в Alexa Prize аннотатор Emotion Classification являлся mutlilabel).

Как можно видеть из эксперимента, PAL-BERT превосходит модели “7 в 1” на “чистых” данных для не-Коботовских задач. Для коботовских задач, PAL-BERT превосходит эти модели на задачах cobot dialogact topics и cobot dialogact intents, а так же примерно соответствует их уровню на задачах cobot topics.

В  третьей серии экспериментов для обучения использовались также те данные, которые получали оригинальные модели для тренировки. В связи с существенным дисбалансом в размерах наборов данных, проверялась также возможность их псевдоразметки. Сравнивались следующие эксперименты:  
\begin{itemize}
\item[*] Модель “7 в 1, PAL-BERT, без псевдоразметки”. Для данного эксперимента модель PAL-BERT обучалась на “своих” данных каждой задачи: для cobot topics - данные без истории(приведенные к формату single-label) из предыдущего эксперимента, для cobot dialogact topics и cobot dialogact intents - данные с историей(приведенные к формату single-label) из предыдущего эксперимента, для задач классификации эмоций, токсичности, тональности и фактоидности - оригинальные наборы данных. Все гиперпараметры обучения соответствовали предыдущим, кроме того, что применялось 10 шагов аккумуляции градиента при размере батча 64 для ускорения обучения.

Заметим, что размеры наборов тренировочных данных для данного эксперимента были примерно следующие - размер датасета для классификации фактоидности ~4 тысячи примеров, для классификации тональности ~8 тысяч примеров, для классификации токсичности ~150 тысяч примеров, для классификации эмоций и решения задачи cobot topics по ~400 тысяч примеров и для решения задач cobot dialogact topics и cobot dialogact intents по ~1.2 млн примеров. В связи с сильным дисбалансом в размерах наборов данных, в следующих экспериментах проводилась их псевдоразметка.

\item[*] Модель “7 в 1, PAL-BERT, псевдоразметка неКоботовских данных”. Данный эксперимент аналогичен предыдущему, с тем изменением, что данные для классификаций эмоций, токсичности, тональности и фактоидности псевдоразмечены: все примеры из набора данных Alexa Prize 4, псевдоразмеченные как в предыдущей серии экспериментов, были добавлены к соответствующим наборам данных. При условии контроля дубликатов. Метки, полученные от однозадачных моделей, были сделаны “жесткими”. Размеры наборов данных для задач классификации эмоций, токсичности, тональности и фактоидности были таким образом увеличены на ~450 тысяч примеров. 

\item[*] Модель “7  в 1, PAL-BERT, полная псевдоразметка”. Данный эксперимент аналогичен предыдущему, с тем исключением, что данные были псевдоразмечены и для Коботовских задач.  Псевдоразметка для Коботовских данных осуществлялась при помощи модели для 3 задач с историей с одним линейным слоем, чьи результаты показаны в соответствующей таблице ( нумерация - потом). Благодаря псевдоразметке, размер набора данных  cobot topics увеличился на 1.1 млн примеров, а размеры наборов данных cobot dialogact topics и cobot dialogact intents на 2.4 млн примеров каждый. В связи с большим количеством примеров, число шагов для аккумуляции градиента было увеличено до 30.

\item[*] Модель “7 в 1, без истории, базовый”. Используются те же данные, что и для модели “PAL-BERT, полная псевдоразметка”, с тем исключением, что у задач cobot dialogact topics и cobot dialogact intents история не используется, что привело к сокращению этих наборов данных. Архитектура модели такая же, как в предыдущем разделе - 1 линейный слой для все задачи.

\item[*] Модель “7 в 1, с историей, базовый”. Эксперимент аналогичен предыдущему, но для всех Коботовских примеров добавляется история аналогично предыдущей серии экспериментов.

\item[*] Модель “7 в 1, PAL-BERT, псевдоразметка только для классификации тональности и фактоидности.” Эксперимент аналогичен эксперименту “7 в 1, PAL-BERT, полная псевдоразметка”, но псевдоразметка данных осуществлялась только для задач классификации тональности и фактоидности, как имевших меньше всего примеров.

\end{itemize}
Заметим также, что для всех экспериментов, и для всех вероятностей, полученных из предсказаний однозадачных моделей для псевдоразметки, была произведена L2-нормализация. До L2-нормализации предсказания обрабатывались так же, как и в предыдущей серии экспериментов.

Также для всех псевдоразмеченных наборов данных, L2-нормализованная максимальная вероятность была принята равной 1, а все остальные - равными 0.

Для всех не-Коботовских задач оценка моделей проводилась строго на оригинальных тестовых данных, без псевдоразметки.

Обучение проводилось при следующих настройках - размер батча равнялся 64, начальная скорость обучения 4e-5, уменьшается в 2 раза при неулучшении средней точности 2 эпохи, 10 максимум тренировочных эпох, критерий остановки обучения - неулучшение средней точности 5 эпох, 30 шагов аккумуляции градиента, базовая модель - bert base uncased. Остальные параметры обучения были аналогичны предыдущей серии экспериментов.

\begin{table}[htbp]
\centering
\caption {Точность(f1) для оценки моделей в третьей серии экспериментов. Для не-Коботовских задач при оценке используются оригинальные тестовые наборы данных, для коботовских - тестовое разбиение данных.}
\label{mtldream:5}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|c|c|c|}
\hline
Модель/Задача &  \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории\\базовый\end{tabular} &\begin{tabular}[c]{@{}l@{}}7 в 1\\ с историей\\базовый\end{tabular} & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT\\без псевдоразметки\end{tabular}  & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ псевдоразметка \\ только \\ неКоботовских \\данных\end{tabular} & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ полная \\псевдоразметка\end{tabular} & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\псевдоразметка \\только \\для sentiment\\ и factoid\end{tabular} & \begin{tabular}[c]{@{}l@{}} Оригинальные \\ модели \end{tabular}\\
\hline
\hline
cobot topics & \textbf{0.701(0.666)} & 0.568(0.533) & 0.833(0.81) & 0.831(0.808) & \textbf{0.863(0.843)} & 0.828(0.81) & 1(1) \\
\hline
cobot dialogact topics & 0.756(0.519) & 0.852(0.667) & \textbf{0.871(0.704)} & 0.869(0.704) & \textbf{0.906(0.804)} & 0.868(0.698) & 1(1) \\
\hline
cobot dialogact intents & 0.515(0.406) & 0.728(0.516) & \textbf{0.768(0.563)} & 0.765(0.561) & \textbf{0.828(0.685)} & 0.753(0.554) & 1(1) \\
\hline
emotion classification & 0.905(0.88) & 0.917(0.883) & \textbf{0.927(0.906)} & 0.924(0.893) & 0.923(0.897) & 0.926(0.91) & 0.92(0.751) \\
\hline
sentiment classification & 0.72(0.633) & 0.713(0.657) & \textbf{0.706(0.648)} & 0.727(0.659) & 0.713(0.647) & \textbf{0.754(0.664)} & 0.721(0.681) \\
\hline
toxic classification & 0.938(0.199) & 0.932(0.21) & \textbf{0.928(0.253)} & 0.932(0.298) & 0.932(0.269) & \textbf{0.939(0.259)} & 0.922(0.596) \\
\hline
factoid classification & 0.789(0.809) & 0.794(0.817) & \textbf{0.834(0.831)} & 0.846(0.844) & \textbf{0.869(0.866)} & 0.854(0.853) & 0.886(0.884) \\
\hline
\end{tabular}
}
\end{table}

\section{Выводы}
Как можно видеть, PAL-BERT превосходит базовые модели на всех задачах. Добавление истории в базовые модели улучшает их качество на задачах cobot dialogact topics и cobot dialogact intents, но ухудшает их качество на задаче cobot topics.

На маленьких наборах данных, таких, как наборы данных для классификации тональности и фактоидности (изначальный размер каждого из наборов - менее 10 тыс. примеров, см. Приложение) результаты могут быть существенно улучшены при помощи псевдоразметки данных. Результаты на Коботовских задачах также существенно улучшаются благодаря псевдоразметке данных.

При этом псевдоразметка ухудшает результаты для задач, где она не была применена, и не приносит улучшений для задач классификации эмоций и токсичности.

По итогам данного эксперимента, в диалоговую систему DREAM была встроена модель \textbf{7 в 1, PAL-BERT, полная псевдоразметка} в конце 2021 года. 

\clearpage
