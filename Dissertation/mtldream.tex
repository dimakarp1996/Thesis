  \chapter{  Использование в диалоговой платформе DREAM многозадачных моделей}\label{ch:mtldream} 

\section{Использование многозадачных моделей с одним линейным слоем }
\subsection{Использование многозадачных моделей с одним линейным слоем для объединения и замены классификаторов реплик}
Автором данной диссертационной работы многозадачные модели для диалоговой платформы DREAM начали использоваться во время конкурса Alexa Prize Challenge 4.Необходимость использования многозадачных моделей была обусловлена как необходимостью экономии вычислительных ресурсов(в первую очередь видеопамяти),
так и лимитом на количество ежедневных запросов к сервисам Amazon, который часто превышался в условиях интенсивных нагрузок конкурса.В связи с этим, была поставлена задача объединить шесть моделей - модель для классификации эмоций(далее будет использоваться также название emotion classification), модель для классификации тональности(далее будет использоваться также название sentiment classification), модель для классификации токсичности(далее будет использоваться также название toxic classification), модель Cobot Topics, модель Cobot DialogAct Topics и модель Cobot DialogAct Intents. 

Первой версией многозадачной модели, использовавшейся в диалоговой платформу DREAM, являлась модель, имеющая такую же архитектуру,
как и модель, описанная в главе \ref{ch:pseudolabel}.

 Заметим, что набор данных из конкурса Alexa Prize Challenge 3 для обучения модели имел следующую особенность - все пользовательские фразы имели аннотации сразу от всех моделей. В связи с этим, модель BERT в первой серии экспериментов обучалась на этих данных, получая на вход предсказания этих моделей(сохранённые в архиве диалогов во время конкурса) в качестве меток. Иными словами, использовался подход, аналогичный подходу "Жёсткие независимые метки" из вышеупомянутого раздела, но без объединения меток. 
 
Все имеющиеся данные были поделены в пропорции 90/8/2 между тренировочным, тестовым и валидационным датасетом. Перед делением были отфильтрованы дубликаты среди фраз. В первом экспериментальном сеттинге каждой фразе присваивалась наиболее часто встречаемая метка для данной фразы и задачи (если встречалось более 1 метки). 

В первой серии экспериментов сравнивались следующие способы обучения:
\begin{itemize}
\item[*] Обучение отдельной модели BERT для каждой из задач
\item[*] Обучение одной модели BERT для трех задач Cobot и другой - для трех остальных задач
\item[*] Обучение одной модели BERT для всех 6 задач
\end{itemize}

Все эти способы сравнивались не только друг с другом, но и (для не-Коботовских задач) с результатами оригинальной модели. 

Особо отмечаю, что "чистого" набора данных для решения Коботовских задач автор диссертационной работы не имел, а те диалоговые данные, что были доступны автору, было запрещено отдавать на разметку в связи с соображениями пользовательской приватности. По этой причине модели, заменяющие Коботовские сервисы (Cobot Topics, Cobot DialogAct Topics, Cobot DialogAct Intents) оценивались исключительно по соответствию своих предсказаний предсказаниям оригинальных моделей(на тестовом разбиении). Соответственно, оригинальные модели Cobot Topics, Cobot Dialogact Topics и Cobot Dialogact Intents в рамках данного эксперимента(как и всех упомянутых ниже) имеют accuracy и f1, равные 1. 

Модели для классификации эмоций, сентимента и токсичности оценивались на тестовых частях своих наборов данных\cite{socher_2013},\cite{na_website_ndo_emo},\cite{na_website_ndm_toxic} . 


Отметим также, что для каждой из задач могло быть предсказано больше 1 метки.
Максимальная длина предложения в проводимых экспериментах равнялась 32 токена, скорость обучения равнялась \num{1e-5}. Использовался оптимизатор AdamW с параметром decay, равным 0.01. В качестве F1-метрики использовался macro-f1. Размер батча считался равным 128. Тренировка запускалась без ограничений по числу эпох, но с остановкой в случае неулучшения средней точности в течение 5 эпох.



\begin{table}[htbp]
\centering
\caption {Accuracy(f1) без диалоговой истории для многозадачной модели с одним линейным слоем}
\label{mtldream:1}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|}
\hline
Задача | Модель & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории\end{tabular}  & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории \\ жесткие метки\end{tabular} &  \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ без истории \\ жесткие метки\end{tabular} & \begin{tabular}[c]{@{}l@{}}Оригинальные\\ модели\end{tabular} \\
\hline
cobot topics & \textbf{0.819(0.8)} & 0.802(0.781) & 0.818(0.795) & 1(1) \\
\hline
cobot dialogact topics & 0.805(0.626) & 0.799(0.616) & \textbf{0.814(0.632)} & 1(1) \\
\hline
cobot dialogact intents & 0.752(0.635) & 0.745(0.626) & \textbf{0.767(0.63)} & 1(1) \\
\hline
emotion classification & 0.401(0.245) & 0.72(0.641) & \textbf{0.788(0.754)} & 0.92(0.751) \\
\hline
sentiment classification & 0.683(0.607) & 0.727(0.609) & \textbf{0.733(0.585)} & 0.721(0.681) \\
\hline
toxic classification & 0.932(0.194) & 0.931(0.18) & \textbf{0.935(0.186)} & 0.922(0.596) \\
\hline
factoid classification & 0.805(0.806) & 0.816(0.814) & \textbf{0.829(0.831)} & 0.886(0.884) \\
\hline
\end{tabular}
}
\end{table}



После этой серии экспериментов, была проведена следующая серия для того, чтобы доказать, что добавление диалоговой истории улучшает показатели моделей, заменяющих Коботовские. Данное предположение было обусловлено тем, что API модели Cobot DialogAct от Amazon, классифицирующей темы и интенты, принимало на вход историю диалога. 
Для проверки этого предположения был сформирован новый набор Коботовских данных, разбитый между тренировочной, тестовой и валидационной выборкой в пропорции 80/10/10. Каждый из примеров содержал историю диалога (максимум 3 предыдущие фразы), конкатенированную с последней фразой через токен [SEP] . Заметим, что данный шаг влечет за собой увеличение размера датасета, так как одной и той же финальной фразе могут соответствовать несколько примеров. Фильтрация дубликатов осуществлялась как на уровне фразы, так и на уровне диалога - ни один диалог из тестовой выборки и ни одна фраза из тестовой выборки не могли быть в тренировочной или валидационной выборке. Как и в предыдущей серии экспериментов, предсказания модели от Amazon использовались как "настоящие" метки. Максимальная длина предложения была повышена с 32 до 64. Все остальные параметры были аналогичны предыдущей серии экспериментов.


\begin{table}[htbp]
\centering
\caption {Accuracy(f1) с диалоговой историей для многозадачной модели с 1 линейным слоем, только Коботовские задачи}
\label{mtldream:2}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|}
\hline
Задача | Модель & \begin{tabular}[c]{@{}l@{}}Без истории\\ 1 модель\end{tabular} & \begin{tabular}[c]{@{}l@{}}С историей\\ 1 модель \end{tabular} & \begin{tabular}[c]{@{}l@{}}Без истории\\ 3 разные модели\end{tabular} & \begin{tabular}[c]{@{}l@{}}С историей\\ 3 разные модели \end{tabular} \\
\hline
\hline
cobot topics & \textbf{0.795(0.818)} & 0.785(0.814) & \textbf{0.804(0.828)} & 0.802(0.825) \\
\hline
cobot dialogact topics & 0.752(0.683) & \textbf{0.841(0.82)} & 0.759(0.685) & \textbf{0.837(0.816)} \\
\hline
cobot dialogact intents & 0.666(0.669) & \textbf{0.777(0.755)} & 0.672(0.668) & \textbf{0.779(0.765)} \\
\hline
Видеопамять, Мб & 3500 & 3502 & 10500 & 10506 \\     
\hline
\end{tabular}
}
\end{table}

Данный эксперимент показал потенциал улучшения качества многозадачной модели. Тем не менее, в связи с ограничением по вычислительным мощностям, было принято решение не увеличивать размер входа многозадачной модели с 32 до 64 и не добавлять туда историю. Такому решению также способствовал тот факт, что большинство выявлявшихся на Коботовских задачах при ручном тестировании ошибок многозадачной модели  было связано не с несоответствием выхода многозадачной модели выходу оригинальной модели, а с неидеальностью самой разметки, использовавшейся при обучении. 
На задачах же, на которых у нас была "чистая" разметка, просадка, связанная с использованием многозадачной модели, была относительно небольшой (у классификаторов эмоций и тональности точность упала на 6\%, f1 упало для классификатора эмоций на 7\%,для классификатора тональности на 10\%). Данные показатели были сочтены приемлемыми. Именно поэтому классификатор без истории был встроен в диалоговую платформу DREAM, он же использовался в этой системе в течение всего конкурса Alexa Prize Challenge 4.

\subsection{Использование многозадачных моделей с одним линейным слоем для замены модели для оценки диалога}
Другой классификационной моделью с одним линейным слоем, использовавшейся в диалоговой системе DREAM, стала замена CoBot Conversation Evaluator. Данная модель была встроена после окончания конкурса Alexa Prize Challenge 4(в сентябре 2021 года) с тем, чтобы после прекращения доступа к Amazon API продолжать получать оценки диалога по 5 параметрам: isResponseInteresting(ответ интересный), responseEngagesUser(ответ развлекает пользователя), isResponseComprehensible(ответ понятный), isResponseErroneous(ответ ошибочный), isResponseOnTopic(ответ по теме). Обученный на массиве диалогов из Alexa Prize Challenge 4, линейный слой предсказывал вектор из 5 величин от 0 до 1, метрик для мониторинга считалась средним квадратичным отклонением. 

Размер батча равнялся 32, максимальный размер диалога - 128 токенов, все остальные параметры обучения были как в предыдущем эксперименте. Размер тренировочной выборки составлял 11456585 диалогов(75\%), тестовой 356250 тыс(2.23\%),валидационной 3462611 тыс(22.67\%).  Дубликаты фильтровались на уровне фразы.

При помощи нейросетевой модели было достигнуто СКО равное 0.31 на тестовом наборе данных. Данный уровень СКО был сочтен достаточно хорошим для использования в диалоговой платформе DREAM, дальнейшие возможности его улучшения не изучались.


\section{Использование модели PAL-BERT в диалоговой платформе DREAM} 

Летом 2021 года под руководством автора диссертационной работы модель типа PAL-BERT \cite{stickland_2019} была успешно встроена в одну из веток библиотеки DeepPavlov. Это дало возможность провести серию экспериментов для того, чтобы исследовать возможности дальнейшего улучшения качества и покрытия многозадачной модели в диалоговой платформе DREAM. Везде в нижеописанных экспериментах в модели PAL-BERT использовался  тип сэмплирования annealed с рекомендованными авторами работы \cite{stickland_2019} параметрами.

Заметим, что во всех нижеописанных экспериментах использовались только те предсказания модели Cobot на диалогах DREAM, которые были получены после 10 февраля 2021, т.к именно в этот день Amazon обновил свою модель.

На момент проведения экспериментов, модель PAL-BERT поддерживала только решение single-label задач (1 задача - 1 класс) в связи с техническими особенностями имплементации. В связи с этим, полученные наборы данных для классификации токсичности и для классификации Коботовских данных были переработаны следующим образом. Примерам, у которых вероятность каждого токсичного класса была ниже 0.5, был присвоен класс "не токсичный", остальным самый вероятный класс (или самый редко встречаемый, если 2 класса имеют одинаковую вероятность).

Аналогичным образом были переработаны и наборы для классификации Коботовских данных, так как часть из них имела больше 1 метки(т.к на вход Cobot API  подавалась фраза пользователя, разбитая аннотатором SentSeg на предложения, было около 5\% таких случаев). 

В первом эксперименте модель PAL-BERT была сравнена с моделью-заменой Cobot, аналогичной предыдущему разделу, на объединении трех задач - cobot topics, cobot dialogact topics и cobot dialogact intents, без истории и с размером батча 32.

\begin{table}[htbp]
\centering
\caption {Accuracy(f1) с диалоговой историей для многозадачной модели с 1 линейным слоем, только Коботовские задачи}
\label{mtldream:3}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|}
\hline
Задача | Модель & Модель с одним линейным слоем & PAL-BERT \\
\hline
\hline
cobot topics & 0.826(0.606) & \textbf{0.828(0.807)} \\
\hline
cobot dialogact topics & 0.803(0.626) & \textbf{0.816(0.637)} \\
\hline
cobot dialogact intents & 0.763(0.637) & \textbf{0.774(0.639)} \\  
\hline
\end{tabular}
}
\end{table}

Заметим, что в связи с другим набором данных и разбиением, данные метрики не сопоставимы с метриками из таблицы ~\ref{mtldream:2}.
 
В данном эксперименте модель PAL-BERT показала себя лучше, чем модель с 1 линейным слоем, но для окончательных выводов необходимо более подробное сравнение.

Во втором эксперименте была поставлена цель объединить предсказания для 7 задач. К задачам классификации токсичности, эмоций, тональности, cobot topics, cobot dialogact topics и cobot dialogact intent была добавлена задача классификации фактоидности вопроса. Актуальность добавления этой задачи была обусловлена добавлением в языковую модель DREAM навыков, применение которых зависит от того, является вопрос фактоидным или нет.

Для обучения использовались данные с Alexa Prize 4, собранные после 10 февраля 2021 года. Использовались только примеры, имеющие метки от Коботовских моделей. Размер тренировочной выборки составлял 1024617 примеров(75\%), размер валидационной выборки 235482 примера(17.23\%), размер тестовой выборки 106056 примеров(7.76\%)

Каждый из таких примеров был дополнительно размечен существующими однозадачными моделями Sentiment Classification, Emotion Classification, Toxic Classification и Factoid Classification.

Размеры каждого из наборов данных до и после псевдоразметки указаны в Приложении \ref{appendix:n-samples}. 

Разметка для всех задач была переведена в режим “1 задача - 1 метка” следующим образом:
\begin{itemize}
\item[*] Для задач классификации токсичности, был добавлен класс “не токсичный”({not\_toxic}) с вероятностью, такой, что ее сумма с максимальной вероятностью любого токсичного класса равняется 1
\item[*] Для задач классификации эмоций, вероятность нейтрального класса была сокращена до 0, если вероятность любого не-нейтрального класса была больше, чем 0.5.
\item[*] Для задач cobot topics, cobot dialogact topics и cobot dialogact intents, если классов было больше 1, выбирался реже всего встречаемый класс.
\end{itemize}
Все полученные таким образом вероятности были нормализованы по L2-метрике.

Ниже приводится сравнение для 3 экспериментов, проведенных на этих данных:
\begin{itemize}
\item[*] Модель “7 в 1, без истории”, как в разделе “Использование многозадачных моделей с одним линейным слоем для объединения и замены классификаторов реплик”. 
\item[*] Модель “7 в 1,без истории, жесткие метки” - как предыдущая, но с использованием жестких меток - там, где предсказанные вероятности использовались как метки, максимальная вероятность считалась равной 1, а остальные считались равными 0. 
\item[*] Модель “PAL-BERT, без истории, жесткие метки” училась на тех же данных, что и предыдущие, но использовала архитектуру PAL-BERT. Также размер батча равнялся не 32, а 64(с 2 шагами аккумуляции градиента). Приводятся данные только по обучению модели PAL-BERT на “жестких” метках, так как без их “огрубления” модель показала слишком высокую склонность к переобучению.
\end{itemize}
Данные модели оценивались как на используемом наборе данных, так и  (для не-Коботовских задач) на “чистых” наборах тестовых данных из “своих” датасетов.В случае, если для задачи есть “чистый” набор только у валидационных данных, он же и считался набором у тестовых данных.
Предсказания модели вида “7 в 1” для каждой задачи переводились в режим “1 пример - 1 метка” следующим образом - предсказанной меткой считалась метка, имеющая максимальную вероятность из предсказанных.

\begin{table}[htbp]
\centering
\caption {Accuracy(f1) с диалоговой историей для многозадачной модели с 1 линейным слоем и PAL-BERT на псевдоразмеченных данных из Alexa Prize Challenge 4, оценка на “чистых” тестовых данных для не-коботовских задач и на псевдоразмеченных для коботовских задач.}
\label{mtldream:4}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|}
\hline
Задача | Модель & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории\end{tabular}  & \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории \\ жесткие метки\end{tabular} &  \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ без истории \\ жесткие метки\end{tabular} & \begin{tabular}[c]{@{}l@{}}Оригинальные\\ модели\end{tabular} \\

\hline
\hline
cobot topics & \textbf{0.819(0.8)} & 0.802(0.781) & 0.818(0.795) & 1(1) \\
\hline
cobot dialogact topics & 0.805(0.626) & 0.799(0.616) & \textbf{0.814(0.632)} & 1(1) \\
\hline
cobot dialogact intents & 0.752(0.635) & 0.745(0.626) & \textbf{0.767(0.63)} & 1(1) \\
\hline
emotion classification & 0.401(0.245) & 0.72(0.641) & \textbf{0.788(0.754)} & 0.92(0.751) \\
\hline
sentiment classification & 0.683(0.607) & 0.727(0.609) & \textbf{0.733(0.585)} & 0.721(0.681) \\
\hline
toxic classification & 0.932(0.194) & 0.931(0.18) & \textbf{0.935(0.186)} & 0.922(0.596) \\
\hline
factoid classification & 0.805(0.806) & 0.816(0.814) & \textbf{0.829(0.831)} & 0.886(0.884) \\
\hline
\end{tabular}
}
\end{table}

Низкие показатели классификатора эмоций в “7 в 1, без истории” связаны с несоответствием между количеством меток в “ чистых” тестовых данных(1 пример - 1 метка) и “многометочных” тренировочных данных(в которых у 1 примера может быть много меток, т.к используемый в Alexa Prize аннотатор Emotion Classification являлся mutlilabel).

Как можно видеть из эксперимента, PAL-BERT превосходит модели “7 в 1” на “чистых” данных для не-Коботовских задач. Для коботовских задач, PAL-BERT превосходит эти модели на задачах cobot dialogact topics и cobot dialogact intents, а так же примерно соответствует их уровню на задачах cobot topics.

В  третьей серии экспериментов для обучения использовались также те данные, которые получали оригинальные модели для тренировки. В связи с существенным дисбалансом в размерах наборов данных, проверялась также возможность их псевдоразметки. Сравнивались следующие эксперименты:  
\begin{itemize}
\item[*] Модель “7 в 1, PAL-BERT, без псевдоразметки”. Для данного эксперимента модель PAL-BERT обучалась на “своих” данных каждой задачи: для cobot topics - данные без истории(приведенные к формату single-label) из предыдущего эксперимента, для cobot dialogact topics и cobot dialogact intents - данные с историей(приведенные к формату single-label) из предыдущего эксперимента, для задач классификации эмоций, токсичности, тональности и фактоидности - оригинальные наборы данных. Все гиперпараметры обучения соответствовали предыдущим, кроме того, что применялось 10 шагов аккумуляции градиента при размере батча 64 для ускорения обучения.

Заметим, что размеры наборов тренировочных данных для данного эксперимента были примерно следующие - размер датасета для классификации фактоидности ~4 тысячи примеров, для классификации тональности ~8 тысяч примеров, для классификации токсичности ~150 тысяч примеров, для классификации эмоций и решения задачи cobot topics по ~400 тысяч примеров и для решения задач cobot dialogact topics и cobot dialogact intents по ~1.2 млн примеров. В связи с сильным дисбалансом в размерах наборов данных, в следующих экспериментах проводилась их псевдоразметка.

\item[*] Модель “7 в 1, PAL-BERT, псевдоразметка неКоботовских данных”. Данный эксперимент аналогичен предыдущему, с тем изменением, что данные для классификаций эмоций, токсичности, тональности и фактоидности псевдоразмечены: все примеры из набора данных Alexa Prize 4, псевдоразмеченные как в предыдущей серии экспериментов, были добавлены к соответствующим наборам данных. При условии контроля дубликатов. Метки, полученные от однозадачных моделей, были сделаны “жесткими”. Размеры наборов данных для задач классификации эмоций, токсичности, тональности и фактоидности были таким образом увеличены на ~450 тысяч примеров. 

\item[*] Модель “7  в 1, PAL-BERT, полная псевдоразметка”. Данный эксперимент аналогичен предыдущему, с тем исключением, что данные были псевдоразмечены и для Коботовских задач.  Псевдоразметка для Коботовских данных осуществлялась при помощи модели для 3 задач с историей с одним линейным слоем, чьи результаты показаны в соответствующей таблице ( нумерация - потом). Благодаря псевдоразметке, размер набора данных  cobot topics увеличился на 1.1 млн примеров, а размеры наборов данных cobot dialogact topics и cobot dialogact intents на 2.4 млн примеров каждый. В связи с большим количеством примеров, число шагов для аккумуляции градиента было увеличено до 30.

\item[*] Модель “7 в 1, без истории, базовый”. Используются те же данные, что и для модели “PAL-BERT, полная псевдоразметка”, с тем исключением, что у задач cobot dialogact topics и cobot dialogact intents история не используется, что привело к сокращению этих наборов данных. Архитектура модели такая же, как в предыдущем разделе - 1 линейный слой для все задачи.

\item[*] Модель “7 в 1, с историей, базовый”. Эксперимент аналогичен предыдущему, но для всех Коботовских примеров добавляется история аналогично предыдущей серии экспериментов.

\item[*] Модель “7 в 1, PAL-BERT, псевдоразметка только для классификации тональности и фактоидности.” Эксперимент аналогичен эксперименту “7 в 1, PAL-BERT, полная псевдоразметка”, но псевдоразметка данных осуществлялась только для задач классификации тональности и фактоидности, как имевших меньше всего примеров.

\end{itemize}
Заметим также, что для всех экспериментов, и для всех вероятностей, полученных из предсказаний однозадачных моделей для псевдоразметки, была произведена L2-нормализация. До L2-нормализации предсказания обрабатывались так же, как и в предыдущей серии экспериментов.

Также для всех псевдоразмеченных наборов данных, L2-нормализованная максимальная вероятность была принята равной 1, а все остальные - равными 0.

Для всех не-Коботовских задач оценка моделей проводилась строго на оригинальных тестовых данных, без псевдоразметки.

Обучение проводилось при следующих настройках - размер батча равнялся 64, начальная скорость обучения 4e-5, уменьшается в 2 раза при неулучшении средней точности 2 эпохи, 10 максимум тренировочных эпох, критерий остановки обучения - неулучшение средней точности 5 эпох, 30 шагов аккумуляции градиента, базовая модель - bert base uncased. Остальные параметры обучения были аналогичны предыдущей серии экспериментов.

\begin{table}[htbp]
\centering
\caption {Точность(f1) для оценки моделей в третьей серии экспериментов. Для не-Коботовских задач при оценке используются оригинальные тестовые наборы данных, для коботовских - тестовое разбиение данных.}
\label{mtldream:5}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|c|c|c|}
\hline
Модель/Задача &  \begin{tabular}[c]{@{}l@{}}7 в 1\\ без истории\\базовый\end{tabular} &\begin{tabular}[c]{@{}l@{}}7 в 1\\ с историей\\базовый\end{tabular} & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT\\без псевдоразметки\end{tabular}  & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ псевдоразметка \\ только \\ неКоботовских \\данных\end{tabular} & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\ полная \\псевдоразметка\end{tabular} & \begin{tabular}[c]{@{}l@{}}7 в 1\\ PAL-BERT \\псевдоразметка \\только \\для sentiment\\ и factoid\end{tabular} & \begin{tabular}[c]{@{}l@{}} Оригинальные \\ модели \end{tabular}\\
\hline
\hline
cobot topics & \textbf{0.701(0.666)} & 0.568(0.533) & 0.833(0.81) & 0.831(0.808) & \textbf{0.863(0.843)} & 0.828(0.81) & 1(1) \\
\hline
cobot dialogact topics & 0.756(0.519) & 0.852(0.667) & \textbf{0.871(0.704)} & 0.869(0.704) & \textbf{0.906(0.804)} & 0.868(0.698) & 1(1) \\
\hline
cobot dialogact intents & 0.515(0.406) & 0.728(0.516) & \textbf{0.768(0.563)} & 0.765(0.561) & \textbf{0.828(0.685)} & 0.753(0.554) & 1(1) \\
\hline
emotion classification & 0.905(0.88) & 0.917(0.883) & \textbf{0.927(0.906)} & 0.924(0.893) & 0.923(0.897) & 0.926(0.91) & 0.92(0.751) \\
\hline
sentiment classification & 0.72(0.633) & 0.713(0.657) & \textbf{0.706(0.648)} & 0.727(0.659) & 0.713(0.647) & \textbf{0.754(0.664)} & 0.721(0.681) \\
\hline
toxic classification & 0.938(0.199) & 0.932(0.21) & \textbf{0.928(0.253)} & 0.932(0.298) & 0.932(0.269) & \textbf{0.939(0.259)} & 0.922(0.596) \\
\hline
factoid classification & 0.789(0.809) & 0.794(0.817) & \textbf{0.834(0.831)} & 0.846(0.844) & \textbf{0.869(0.866)} & 0.854(0.853) & 0.886(0.884) \\
\hline
\end{tabular}
}
\end{table}

\section{Выводы}
Как можно видеть, PAL-BERT превосходит базовые модели на всех задачах. Добавление истории в базовые модели улучшает их качество на задачах cobot dialogact topics и cobot dialogact intents, но ухудшает их качество на задаче cobot topics.

На маленьких наборах данных, таких, как наборы данных для классификации тональности и фактоидности (изначальный размер каждого из наборов - менее 10 тыс. примеров, см. Приложение) результаты могут быть существенно улучшены при помощи псевдоразметки данных. Результаты на Коботовских задачах также существенно улучшаются благодаря псевдоразметке данных.

При этом псевдоразметка ухудшает результаты для задач, где она не была применена, и не приносит улучшений для задач классификации эмоций и токсичности.

По итогам данного эксперимента, в диалоговую платформу DREAM была встроена модель \textbf{7 в 1, PAL-BERT, полная псевдоразметка} в конце 2021 года. Данная модель использовалась в диалоговой платформе DREAM до момента ее замены на трансформер-агностичную модель. 

\section{Использование многозадачной трансформер-агностичной модели в диалоговой платформе DREAM} 

Многозадачная модель, основанная на модели PAL-BERT, помогла добиться существенной экономии вычислительных ресурсов. Тем не менее, модели подобного рода имеют и свои недостатки. Так, модель PAL-BERT не является трансформер-агностичной, что ограничивает использование подобных моделей с разными типами трансформеров в качестве их "ядра". Помимо этого, было необходимо расширить набор задач, поддерживаемых многозадачной  нейросетевой моделью в диалоговой платформе DREAM, а также  улучшить обучающую выборку для борьбы с переобучением этой модели. 

В связи с этим было принято решение использовать многозадачную трансформер-агностичную модель, описанную в главе \ref{sec:tr-ag}, для решения задач диалоговой платформы DREAM. В данной модели к описанным выше задачам была добавлена классификация интентов на диалоговых данных из набора данных MIDAS, подробнее описанных в разделе \ref{sec:midas}. Помимо этого, была добавлена классификация на новом тематическом наборе данных DeepPavlov Topics\cite{dp_topics}, которая позволила расширить набор покрываемых тем. 

Итоговая многозадачная модель обучалась одновременно для \textbf{девяти} задач. Ниже будет подробно описана каждая из этих задач вместе с обучающим набором данных для этой задачи. 
\begin{itemize} 
\item[*]\textbf{Классификация тональности}. Для данной задачи использовался набор данных DynaBench(r1+r2)\cite{dynabench}, содержащий \~ 94 тысячи тренировочных примеров. Этот набор данных превосходит по своему размеру более чем в 11 раз используемый ранее набор данных SST\cite{sst}, что помогло уменьшить переобучение модели. Каждый пример принадлежал к одному из трех классов, как и в исходных данных. 

\item[*]\textbf{Классификация фактоидности}. Для данной задачи использовался набор данных YAHOO\cite{yahoo}, аналогичный используемому ранее. Как и в предыдущем разделе, валидационная выборка считалась тестовой. 

\item[*]\textbf{Классификация интентов MIDAS}. Автор обучал эту модель на наборе данных MIDAS, как и в главе \ref{ch:dream}. Аналогично этой главе, автор использовал только семантические классы из набора данных MIDAS, и только данные, имеющие только одну метку. 

Мы использовали данный набор данных  в двух режимах. В первом режиме данных MIDAS использовались с историей (добавление предыдущих фраз к реплике осуществлялось с использованием токена [SEP], как и для задачи \textbf{cobot dialogact topics} при использовании предыдущих многозадачных моделей).

Так как после того, как все данные в задачах \textbf{cobot} стали использоваться без диалоговой истории, диалоговая история использовалась только для задачи классификации интентов MIDAS, была предпринята попытка обойтись во втором режиме без истории вообще. При обучении модели в данном режиме, качество модели почти не пострадало, а для задачи MIDAS было даже небольшое улучшение(см. Таблицу \ref{tab:tr-ag-dream}). При этом без поддержки истории, можно было использовать в 2 раза меньшую максимальную длину реплики, а также на каждом шаге только один раз прогонять базовую модель перед применением задаче-специфичных линейных слоев(а не два раза - для версии примера с историей и для версии примера без нее). Это позволило дополнительно уменьшить время предсказания на 25 процентов. 

\item[*]\textbf{Классификация эмоций}.Для классификации эмоций мы использовали набор данных \texttt{go\_emotions}\cite{go_emotions}, с объединением всех 28 классов из этого набора до 7 базовых типов эмоций по Экману (ярость, грусть, удовольствие, нейтральная, удивление, отвращение, страх). Данный набор базовых типов соответствовал используемому ранее в диалоговой платформе DREAM, с поправкой на то, что вместо эмоции "отвращение" использовалась эмоция "любовь", но ни для одной из этих двух эмоций не имелось сценарной метрики. Замена использовавшегося ранее набора данных для классификации эмоций на \texttt{go\_emotions} помогла уменьшить уровень переобучения модели. 
%multilabel = многометочный? 
 Набор данных go\_emotions содержал 42 тысячи тренировочных примеров, из которых 39.5 тысячи имели одну метку, оставшиеся - более, чем одну. 

Добавление примеров, имевших больше чем 1 метку, в данные (и соответственно, обработка выхода базовой модели, как для multilabel задач) ухудшало результаты для singlelabel примеров. Это ухудшение носило стойкий характер - оно сохранялось и для моделей, обученных только на go\_emotions, причём подбор границы для multilabel классификации по валидационному набору данных не помог убрать это ухудшение. Даже если для каждого из классов go\_emotions считать отдельной задачей определение вероятности того, принадлежит ли пример к тому или иному классу, это всё равно не помогало уменьшить ухудшение: как при объединении меток эмоций с оригинальных 28 до 7, так и без такого объединения. 
В связи с этим автор диссертационной работы использовал для данной задачи исключительно примеры, имеющие только одну метку. И задача считалась singlelabel. 
%TODO - никаких "мы использовали" нигде
 \item[*]\textbf{Классификация токсичности}. Для задачи классификации токсичности использовался тот же набор данных \cite{toxic_kaggle}, что и в предыдущем разделе. Данный набор имел примерно 162 тысячи тренировочных примеров. Данные преобразовывались к singlelabel формату, как и в предыдущем разделе. 
\item[*]\textbf{Тематическая классификация}. Для задачи тематической классификации использовался набор данных \texttt{DeepPavlov Topics}\cite{dp_topics}, содержащий 1.8 миллионов тренировочных примеров. Каждый из примеров относится к одному из 33 классов. Соответственно, задача считалась singlelabel - попытки считать эту задачу multilabel приводили только к ухудшению качества модели. 
К сожалению, реализации тематической классификации исключительно на основании этого набора данных всё еще не хватало для того, чтобы многозадачная модель проходила тесты. Это было связано с двумя вещами. Во-первых, набор данных \texttt{DeepPavlov Topics} не покрывает некоторые классы, присутствующие в классификаторах\texttt{Cobot Topics} и \texttt{Cobot DialogAct Topics} ( Weather\_Time, Sex\_Profanity, Inappropriate\_Content). Во-вторых, даже по тем классам, которые соотносились с классами \texttt{Cobot Topics} и \texttt{Cobot DialogAct Topics}, основная часть примеров в \texttt{DeepPavlov Topics} были существенно длиннее, чем в этих двух наборов данных. А сами примеры были взяты из текстов, а не из диалоговой речи. В связи с этим, в многозадачной трансформер-агностичной модели в диалоговой платформе DREAM одна голова, обученная на \texttt{DeepPavlov Topics}, отвечает за задачу тематической классификации в рамках номенклатуры этого набора данных, а три другие головы, обученные на \texttt{Cobot Topics}, \texttt{Cobot DialogAct Topics} и \texttt{Cobot DialogAct Intents} - за классификацию в рамках соответствующих задач. При этом для каждой из этих задач ее набор данных претерпел изменения, описанные ниже
\item[*]\textbf{Cobot topics}. Обучение для данного набора данных производилось на наборе данных DREAM-2,полученном из используемого ранее набора данных DREAM следующим образом. 
Во-первых, все multilabel примеры были преобразованы в singlelabel с оставлением только наиболее редко встречаемого класса. Это позволило улучшить качество обучающей выборки, в основном в связи с тем, что до данного изменения основная часть multilabel примеров имела вид (класс-исключение, обычный класс),где класс-исключение - это Phatic либо Other. Во-вторых, из данного набора был убран наиболее встречаемый класс-исключение (Phatic), так как даже модель, обученная только на singlelabel версии данного набора данных, слишком часто путала его с другими классами(что было видно по матрице ошибок). \footnote{Была также попытка убрать из данного набора данных не один класс-исключение, а оба, но это изменение только понизило качество модели.}
Оба этих изменения понизили вероятность переобучения модели на "классы-исключения", улучшив ее качество на реальных задачах. Итоговый размер тренировочной выборки составил около 216 тысяч примеров. 
% TODO - заглавные буквы в названиях коботовских датасетов! Единообразно
\item[*]\textbf{Cobot dialogact topics}. Мы обучали модель для решения этой задачи на непубличном наборе данных DREAM-2. Данный набор данных был получен из  описанного в предыдущем разделе практически тем же способом, что и \texttt{Cobot topics} : точно так же все примеры были приведены к singlelabel формату, точно так же и по той же самой причине был исключен наиболее часто встречаемый "класс-исключение" (Other).
 Единственным отличием было то, что, так как наборы данных для задач \texttt{Cobot DialogAct Topics} и \texttt{Cobot DialogAct Intents} содержали историю, из них она была удалена. Данное изменение повлияло только на три процента примеров из набора, которые могли классифицироваться по-разному в зависимости от своей истории. Для каждого из этих примеров был выбран наиболее часто встречаемый класс после приведения к singlelabel формату. Финальный размер набора данных - около 127 тысяч примеров.

\item[*]\textbf{Cobot dialogact intents}. Мы обучали модель для решения этой задачи на непубличном наборе данных DREAM-2. Данный набор данных был получен из описанного в предыдущем разделе набора данных DREAM тем же способом, что и для \textbf{Cobot dialogact topics} - с поправкой на то, что мы не исключали "мусорный" класс из данных, так как матрица ошибок для классификатора, обученного на singlelabel данных только для этой задачи, показала, что нет таких пар классов, которые модель слишком часто "путает" друг с другом, и значит, необходимости в этом нет. Размер очищенного набора данных:318 тысяч примеров. 
\end{itemize}
Также наборы \texttt{Cobot Topics}, \texttt{Cobot DialogAct Topics} и \texttt{Cobot DialogAct Intents} были переразбиты в соотношении 70/15/15 - 70 процентов тренировочных примеров, 15 тестовых, 15 валидационных\footnote{В силу другого разбиения, результаты для этих задач не сопоставимы напрямую с задачами из предыдущих таблиц.}.

Размеры наборов данных для каждой из задач приведены в Аппендиксе \ref{Appendix:dream-tr-ag-sizes}. 

При обучении моделей использовались следующие гиперпараметры - размер батча 640 для дистиллированных моделей и 320 для обычных, максимум 30 тренировочных эпох, критерий останова - неулучшение средней точности в течение 3 эпох, оптимизатор AdamW с начальной скоростью обучения 2e-5, бетами (0.9,0.99) и уменьшением скорости обучения в 2 раза, если средняя точность не улучшалась в течение 2 эпох. 

В целях достижения наилучшего баланса между использованием памяти, временем предсказания и тестовыми метриками, в диалоговую платформу DREAM была встроена многозадачная модель distilbert-base-uncased, обучавшаяся на размере батча 640, в которой ни для одной из задач(включая MIDAS) не использовалась диалоговая история.
Мы приводим результаты в таблице \ref{tab:tr-ag-dream} 
%TODO  ВСТАВИТЬ ТАБЛИЦУ 

\begin{table}[htbp]
\centeringш
\caption {Точность/взвешенный macro F1) для оценки моделей в экспериментах с трансформер-агностичными моделями. Для не-Коботовских задач при оценке используются оригинальные тестовые наборы данных, для коботовских - тестовое разбиение данных. Мы обозначаем как distilbert модель distilbert-base-uncased, как bert модель bert-base-uncased. "Однозадачный" означает, что отдельная модель обучалась для каждой из задач.}
\label{tab:tr-ag-dream}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
Задача/модель & Размер обучающей выборки &\begin{tabular}[c]{@{}l@{}}distilbert\\однозадачный\\с историей в MIDAS\end{tabular} & \begin{tabular}[c]{@{}l@{}}distilbert\\многозадачный\\с историей в MIDAS\end{tabular}   & \begin{tabular}[c]{@{}l@{}}distilbert\\многозадачный\\без истории в MIDAS\end{tabular}  & \begin{tabular}[c]{@{}l@{}}bert\\однозадачный\\с историей в MIDAS\end{tabular} &  \begin{tabular}[c]{@{}l@{}}bert\\многозадачный\\с историей в MIDAS\end{tabular}\\
\hline
\hline
Классификация эмоций                            & 39.5к & 70.47/70.30  & 68.18/67.86  & 67.59/67.32                  & 71.48/71.16  & 67.27/67.23 \\
Классификация токсичности                       & 1.62m & 94.53/93.64  & 93.84/93.5   & 93.86/93.41                  & 94.54/93.15  & 93.94/93.4  \\
Классификация тональности                       & 94k   & 74.75/74.63  & 72.55/72.21  & 72.22/71.9                   & 75.95/75.88  & 75.65/75.62 \\
Классификация фактоидности                      & 3.6k  & 81.69/81.66  & 81.02/81.07  & 80.0/79.86                   & 84.41/84.44  & 80.34/80.09 \\
Классификация интентов MIDAS                    & 7.1k  & 80.53/79.81  & 72.73/71.56~ & 73.69/73.26(without history) & 82.3/82.03   & 77.01/76.38 \\
{Тематическая классификация\\DeepPavlov Topics} & 1.8m  & 87.48/87.43  & 86.98/86.9   & 87.01/87.05                  & 88.09/88.1   & 87.43/87.47 \\
Cobot topics~                                   & 216k  & 79.88/79.9   & 77.31/77.36  & 77.45/77.35                  & 80.68/80.67  & 78.21/78.22 \\
Cobot dialogact topics~                         & 127k  & 76.81/76.71  & 76.92/76.79  & 76.8/76.7                    & 77.02/76.97  & 76.86/76.74 \\
Cobot dialogact intents                         & 318k  & 77.07/77.7   & 76.83/76.76  & 76.65/76.57                  & 77.28/77.72  & 76.96/76.89 \\
Средее для 9 задач                                     & 4218k & 80.36/       & 78.48/78.22  & 78.36/78.15                  & 81.31/81,12    & 79.3/79.11  \\
Видеопамяти использовано, Мб                             &       & 2418*9=21762 & 2420         & 2420                         & 3499*9=31491 & 3501        

\hline
\end{tabular}
}
\end{table}
\subsection{Экономия памяти GPU, CPU и быстродействия} 
\label{economy}
Использование многозадачной трансформер-агностичной модели в диалоговой системе DREAM позволило достичь существенной экономии всех видов вычислительных ресурсов для классификации.
\subsubsection{Экономия рассчетных показателей} 
\label{economy_predicted} 
 Если бы в DREAM не использовалось многозадачное обучение и модели для каждой из девяти рассмотренных задач были реализованы на основании  distilbert-base-uncased, то на них пришлось бы выделить не ~2420 Мб видеопамяти и ~2909 Мб оперативной памяти, а ~21762 Мб видеопамяти и ~14000 Мб оперативной памяти. По сравнению с таким раскладом, экономия видеопамяти в платформе DREAM составила ~90\%, а экономия оперативной памяти ~79\%. Данная экономия представляет собой выигрыш от многозадачности. 

Если бы модели для каждой из девяти задач были реализованы на основании bert-base-uncased, на них пришлось бы выделить ~31500 Мб видеопамяти и ~23346 Мб оперативной памяти. По сравнению с таким раскладом, экономия видеопамяти в платформе DREAM составила ~92\%, а экономия оперативной памяти ~88\%. Данное увеличение экономии представляет собой дополнительный выигрыш от трансформер-агностичности, которая помогла быстро подставить дистиллированный трансформер вместо обычного. 

Причем, как будет показано в следующем подразделе \ref{economy_real}, вклад трансформер-агностичности в улучшение показателей модели в реальности был гораздо более существенным, чем можно было бы подумать исходя только из этих цифр. 

\subsubsection{Экономия по сравнению с многозадачным PAL-BERT}
\label{economy_real} 
По сравнению с классификаторами в версии диалоговой платформы DREAM до внедрения многозадачной трансформер-агностичной модели (т.е основанной на модели PAL-BERT) многозадачная трансформер-агностичная модель дала экономию видеопамяти в 75 процентов, экономию оперативной памяти в 57 процентов и экономию времени на классификацию в 80-85 процентов.
 
Такая большая экономия времени на классификацию в основном связана с эффектом от трансформер-агностичности\footnote{Хотя, конечно, роль сыграло и то, что для задачи классификации интентов MIDAS больше не требовался отдельный классификатор.}. Если при использовании PAL-BERT для каждой задачи было необходимо получать предсказания многозадачной модели "с нуля", даже если они принимают одну и ту же фразу на вход, то при использовании многозадачной трансформер-агностичной модели появилась возможность один раз получить выход базового трансформера для этой фразы и дальше для всех других задчач, принимающих ее на вход, работать с этим выходом только линейными слоями, которые на порядки быстрее. 

\subsection{Преимущество по сравнению с многозадачной моделью с одним линейным слоем}

Многозадачная трансформер-агностичная модель является логичным усовершенствованием многозадачной модели с одним линейным слоем. По сравнению с данной моделью, многозадачная трансформер-агностичная модель имеет больше гибкости, так как не требует меток для каждой из задач у каждого примера. При этом подобная модель лучше адаптируется к каждой конкретной задаче, так как при обучении на примерах из каждой задачи у этой модели обновляются веса только тех нейронов в финальных линейных, которые отвечают конкретно за эту задачу. В то же время, у модели с одним линейным слоем пример из каждой задачи при обучении чуточку "сбивает" веса \textbf{всех} задач. Данный эффект можно сгладить, используя псевдоразметку каждого примера для каждой задачи уже обученными однозадачными моделями, но это требует больших затрат времени и вычислительных мощностей, а также вносит в обучающую выборку для каждой задачи искажения, связанные с необходимостью видеть большое количество не свойственных этой задаче примеров, размеченных каким-то неидеальным образом. По итогам применения моделей с псевдоразмеченными данными в рамках диалоговой платформы DREAM был сделан вывод, что такая реализация многозадачных моделей увеличивает риск переобучения. Поэтому от практического применения данного метода в дальнейшем было решено отказаться.

