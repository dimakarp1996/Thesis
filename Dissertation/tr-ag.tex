\chapter{Многозадачные энкодер-агностичные модели}\label{ch:tr-ag}
% TODO -- ЧТОБЫ ВЕЗДЕ НАЗЫВАЛИСЬ инвариантнЫМИ, А НЕ ИНВАРИАНТНЫМИ!!!!
Многозадачные нейросетевые модели, описанные в Главе~\ref{ch:pseudolabel}, позволяют добиться существенной экономии вычислительных ресурсов. Тем не менее, к числу их неустранимых недостатков относится негибкость. Они поддерживают только один тип голов (многометочные), они требуют наличия меток для каждой задачи у каждого примера.

В связи с этим была поставлена цель поиска и исследования более эффективных архитектур. В частности, было необходимо выбрать многозадачную нейросетевую архитектуру, лишенную описанных выше недостатков архитектуры из Главы~\ref{ch:pseudolabel}, и сравнить ее с аналогами. Помимо этого, необходимо было исследовать перенос знаний в выбранной нейросетевой архитектуре: как перенос знаний между задачами, так и перенос знаний между языками при использовании многозадачных моделей. При этом задачи для исследования было необходимо выбрать исходя из потребностей реальных диалоговых платформ, например, платформы DeepPavlovDream, описанную в Главе~\ref{ch:mtldream}.

Помимо этого, необходимости развития обработки естественного текста на русском языке диктовали необходимость расширения данных исследований на русский язык. Помимо проверки выводов данного исследования для русского языка, особый интерес представлял также перенос данных с английского языка на русский. 

В связи с этим в рамках работы над данной главой была поставлена задача \textbf{Получить оценку зависимости качества работы энкодер-агностичных моделей на диалоговых задачах от размера обучающей выборки, в том числе при переносе знаний между языками.}

Ещё одна задача, которая решалась в рамках данной главы - \textbf{интегрировать энкодер-агностичные многозадачные нейросетевые модели в open-source библиотеку для решения задач машинного обучения.} Решение данной задачи обеспечивает доступность достигнутых в диссертации результатов для широкого круга пользователей.

Архитектура, исследование которой проводилось, описана в следующем разделе. Попытки улучшения данной архитектуры описаны отдельно. 

\section{Архитектура энкодер-агностичные многозадачной модели}\label{ch:tr-ag:architecture}
Рассмотренная многозадачная энкодер-агностичная модель работает на основе архитектуры Трансформер (ниже также просто «энкодер-агностичная модель»). Она состоит из базовой модели и задаче-специфичных линейных слоев.

Принцип работы данной модели выглядит следующим образом:
\begin{itemize}

  \item Как и в оригинальной статье~\cite{bert}, возвращаются финальные скрытые состояния для всех токенов и выход пулингового слоя базовой модели-трансформера. 
  
  \item Как и в оригинальной статье, применяется дропаут, по умолчанию равный 0.2.\footnote{Варьирование дропаута как на этом этапе, так и после каждого слоя внимания не привело к улучшению характеристик модели.} Для задач выбора из нескольких вариантов ответа или классификации каждого токена в предложении, выход преобразуется аналогично соответствующим задачам.

  \item После этого этапа, применяется задаче-специфичный линейный слой с размерностью выхода {n}. Для всех задач, кроме регрессии или выбора из нескольких вариантов ответа, \footnote{Для задачи выбора из нескольких вариантов ответа, каждой метке изначально относится несколько примеров. Т.е с таким числом классов после преобразования формы число реальных и предсказанных меток соответствует друг другу.} {n} равняется числу классов для задачи. Во всех других случаях {n} равняется 1.
 
  \item В конце применяется функция потерь. Если для каждого примера из задачи ожидается только одна метка, применяется категорическая кросс-энтропия, в остальных случаях -- бинарная кросс-энтропия. 

\end{itemize}

Обращу отдельное внимание на то, что в каждом тренировочном батче для данной нейросетевой многозадачной модели должны содержаться примеры только из одной задачи. В противном случае эффективный размер батча для каждой из задач оказывался меньше задаваемого изначально, что приводило к ухудшению метрик модели. 

Такая многозадачная модель почти не требует дополнительных параметров, и, как следствие, дополнительных вычислительных ресурсов (кроме линейных слоев, которые требуют на порядки меньше ресурсов, чем тело архитектуры Трансформер). Так, для моделей типа distilBERT, предложенная многозадачная модель требует всего лишь примерно на  0.1\% больше видеопамяти, чем любая из соответствующих ей однозадачных моделей. В зависимости от числа задач, числа классов и "тела" многозадачной модели, количество дополнительных параметров варьируется вокруг этого числа. 

При этом данная модель является энкодер-агностичной, что позволяет быстро подставлять в нее разные типы базовых моделей. Это выгодно отличает данную модель от иерархических многозадачных моделей, таких, как~\cite{stickland_2019} и~\cite{TaskEmbedded2021}.

Для всех описанных ниже экспериментов были использованы модели, основанные на архитектуре типа BERT, но абсолютно тот же подход может применяться и к другим нейросетевым моделям на базе архитектуры Трансформер.

Данная модель успешно интегрирована в open-source библиотеку DeepPavlov, имевшую более 500000 скачиваний на момент встраивания кода.\footnote{Ссылка на интеграцию: \url{https://github.com/deeppavlov/DeepPavlov/releases/tag/1.1.1}}. Её реализация основана на классе {AutoModel} из HuggingFace, который разрешает использовать разнве модели, основанные на архитектуре Трансформер.\footnote{Список поддерживаемых моделей: \url{https://huggingface.co/transformers/v3.0.2/model_doc/auto.html\#automodel}}
Исследования, представленные в данной главе, описаны также в работе~\cite{rumtl}, первым автором которой является автор данной диссертационной работы.
%TODO -- ссылка на коммит как будет интегрирована



\subsection{Какие эксперименты не сработали}\label{ch:tr-ag:failed_attempts} 
Автор диссертационной работы пробовал большое количество различных вариантов улучшения архитектуры многозадачной энкодер-агностичной модели по сравнению с описанными в разделе~\ref{ch:tr-ag:architecture}.
\begin{itemize} 
 \item Первой серией идей было использование LSTM-представления [CLS]-токена или конкатенация этого представления с самим [CLS]-токеном. При проверке на валидационном наборе данных GLUE, прироста средней точности по сравнению с описаннрй выше архитектурой данные эксперименты не дали. 
\item Второй серией идей являлось использование задаче-специфичных тренируемых токенов. А именно, идеи заключались в том, чтобыприсваивать каждой из задач какой-нибудь неиспользуемый токен из словаря BERT (каждой задаче -- свой токен). И добавлять этот токен сразу же после [CLS]-токена к каждой из задач. После чего проводить классификацию не просто по [CLS]-токену, а либо по конкатенации [CLS]-токена и задаче-специфичного токена, либо же просто по задаче-специфичному токену. На наборе данных GLUE эти идеи не привели к улучшению метрик.

 Для случая, когда к каждому примеру добавляется не один задаче-специфичный токен, а сразу все задаче-специфичные токены по очереди\footnote{То есть, к примеру, для двухзадачной классификации, каждый пример имеет вид \textit{$[CLS] [TOKEN\_FOR\_TASK1] [TOKEN\_FOR\_TASK2][TOKENIZED\_EXAMPLE]$}}, улучшения при проведении классификации как в предыдущем пункте также не последовало. 
Вероятно, провал этих экспериментов связан с тем, что если [CLS]-токен был хорошо предобучен на оригинальном BERT для проведения классификации, то задаче-специфичные токены предобучены не были, а какая-то дополнительная полезная информация, зависящая от задачи, через них так и не передавалась или наоборот, она слишком хорошо передавалась через [CLS]-токен. 

\item Хотя исследование разных методов сэмплирования задач при многозадачном обучении не является фокусом данной диссертационной работы, автор также проводил эксперименты и с разными методами сэмплирования. Так, вариант перехода для каждой задачи в режим сходимости (с делением функции потерь для этой задачи на 4), если на ней нет заметного улучшения, и выхода из этого режима, если на этой задаче появляется заметное ухудшение, не сработал. Эксперимент, в котором после некого числа эпох (достаточно большого, чтобы измерить дисперсию модели), модель обучалась только на некой доле самых сложных примеров с самой высокой дисперсией, тоже не сработал.\footnote{Справедливости ради, существуют и эффективные способы улучшения сэмплирования, дававшие заметный прирост метрик -- например,~\cite{GradTS}. Данный подход вполне можно объединить с предлагаемым в моей диссертации.}
\end{itemize}

В числе неудачных экспериментов также можно упомянуть эксперименты по дистилляции более крупных моделей BERT в более мелкие, которые проводились путем добавления в функцию потерь нового члена, "приближающего" веса более крупной модели к соответствующим весам более мелкой (по метрике СКО). Эта идея не сработала. Автор предполагает, что это было связано с тем, что данный способ является слишком грубым для того, чтобы приблизиться к адекватной аппроксимации сложных нейросетевых функций, которые используются в модели BERT. В связи с этим, в дальнейшем идеи с приближением весов не проверялись. 
\subsection{Преимущество энкодер-агностичной многозадачной модели над многозадачной моделью с одним линейным слоем}
\label{ch:tr-ag:advantages}

Многозадачная энкодер-агностичная модель является логичным усовершенствованием многозадачной модели с одним линейным слоем. По сравнению с данной моделью, многозадачная энкодер-агностичная модель имеет больше гибкости, так как не требует меток для каждой из задач у каждого примера. %При этом подобная модель лучше адаптируется к каждой конкретной задаче, так как при обучении на примерах из каждой задачи у этой модели обновляются веса только тех нейронов в финальных линейных слоях, которые отвечают конкретно за эту задачу. В то же время, у модели с одним линейным слоем пример из каждой задачи при обучении чуточку "сбивает" веса \textbf{всех} задач.

Данный эффект можно компенсировать, используя псевдоразметку каждого примера для каждой задачи уже обученными однозадачными моделями, но это требует больших затрат времени и вычислительных мощностей, а также вносит в обучающую выборку для каждой задачи искажения, связанные с необходимостью видеть большое количество не свойственных этой задаче примеров, размеченных каким-то неидеальным образом. Так, для задачи классификации тональности доля положительных обучающих примеров после псевдоразметки, описанной в главе~\ref{ch:mtldream}, уменьшилась с 42.4\% до 12.7\%~\ref{appendix:mtl-dream:palbert:sentiment}. При этом все плюсы от псевдоразметки там, где она оправдана, можно получить и при применении многозадачной энкодер-агностичной модели -- которая к тому же предоставляет и возможность выбора, на каких задачах делать псевдоразметку, а на каких не делать.

Другое преимущество многозадачной энкодер-агностичной модели, проявляющееся даже на параллельно размеченных данных, заключается в большей гибкости голов. Если модель с одним линейным слоем по факту поддерживает только один тип головы, а имеено многометочные, то многозадачная энкодер-агностичная модель поддерживает и однометочные головы для каждой задачи. Реальное применение показало, что на тех задачах, где выход модели можно представить в однометочном виде, его лучше представлять именно  в таком виде. Это, по всей видимости, связано с тем, что задача "выбрать один самый вероятный класс" проще для линейного слоя, чем задача "выбрать сколько-то классов, чья вероятность выше какой-то границы". И применяя энкодер-агностичную модель, можно сознательно выбирать решение именно этой задачи.

Еще одно преимущество многозадачной энкодер-агностичной модели, которое в рамках этой работы еще не было раскрыто до конца, заключается в том, что она поддерживает больший спектр задач. В частности, она (в реализации на момент написания диссертационной работы) поддерживает такие задачи, как распознавание именованных сущностей или выбор из нескольких вариантов ответа, которые невозможно реализовать в рамках модели с одним линейным слоем.


\section{Наборы данных}

Исходя из специфики прикладного применения диалоговой платформы Dream, было выбрано пять ключевых диалоговых задач для исследования переноса знаний. Это классификация эмоций, классификация токсичности, классификация тональности, классификация интентов и тематическая классификация. Так как одной из задачей диссертационной работы являлось исследование межъязыкового переноса знаний, было подготовлено по два набора данных для каждой из этих задач: русскоязычный и англоязычный набор. Отдельно обращаю внимание, что для классов, одинаковых в русском и английском языке, индексы соответствующих используемых моделью классов были тоже одинаковыми. Размеры каждого из наборов данных по классу и разбиению на тренировочную, тестовую и валидационную выборку приведены в Приложении~\ref{appendix:sizes_tr-ag}.

Ниже подробно описаны наборы данных для каждой из диалоговых задач. 

\subsection{Классификация эмоций}
\subsubsection{Англоязычные данные}
В качестве англоязычного набора данных для классификации эмоций, использовался набор данных {go\_emotions}~\cite{go_emotions}. Этот набор данных состоит из коротких комментариев из Реддита,\footnote{\url{http://reddit.com}} таких, как \textit{LOL. Super cute!} или \textit{Yikes. I admire your patience}. Все эмоции из данного набора данных были сгруппированы в семь типов по Экману, а именно \textit{ярость}, \textit{страх}, \textit{отвращение}, \textit{рядость}, \textit{удивление}, \textit{грусть}, и \textit{нейтральная}.

После такой группировки, были выбраны только примеры, содержащие только одну метку. Исследование возможностей улучшения классификации таких примеров за счет использования примеров, содержащих более чем одну метку, успехом не увенчалось -- подробнее эти попытки описаны в главе~\ref{ch:mtldream}. 

Примерно 80 процентов данного набора данных, а именно около 39.5 тысяч примеров, составляли тренировочные данные. Размер валидационной выборки примерно равнялся размеру тестовой. 

\subsubsection{Русскоязычные данные}
В качестве русскоязычного набора данных для классификации эмоций, использовался набор данных {CEDR}~\cite{ru_emotions}.\footnote{Набор данных был получен по адресу \url{https://huggingface.co/datasets/cedr}} Примеры из этого набора могут принадлежать пяти классам -- \textit{ярость}, \textit{страх}, \textit{радость}, \textit{удивление}, and \textit{грусть}. Помимо этого, примеры из этого набора могут принадлежать более чем одному классу или (в отличие от {go\_emotions}) не принадлежать ни к какому классу.

При подготовке набора данных, примеры, которые не принадлежат ни одному классу, были обозначены как принадлежащие классу \textit{нейтральный}, после чего были выбраны только примеры, принадлежащие одному классу. Соответственно, номенклатура такого набора данных была такая же, как и у англоязычного набора данных, с поправкой на отсутствие класса \textit{отвращение}. Впрочем, так как примеров из этого класса и в англоязычном-то наборе данных было меньше, чем 1.5\%, на перенос знаний это сильно не повлияло. 

В оригинальной работе набор данных CEDR ыюбыл разбит только на тренировочную и тестовую выборки в соотношении 80/20. В целях получения полноценной валидационной выборки, 12.5\% тренировочных примеров из CEDR было выделено как валидационный набор данных. Финальный размер тренировочных русскоязычных данных составил около 6.5 тысяч примеров.
 % TODO проверить


\subsection{Классификация тональности}

\subsubsection{Англоязычные данные} 
В качестве англоязычного набора данных для классификации тональности, использовался набор данных {DynaSent} (r1)~\cite{sentiment}, состоящий из предложений, возникающих в диалогах. Чтобы не переусложнять набор данных по сравнению с русскоязычными данными, использовались только примеры из первого этапа сбора данных DynaSent. В данном наборе данных есть 80.5 тысяч тренировочных примеров, разделенных на три класса -- положительный, отрицательный, нейтральный.

\subsubsection{Русскоязычные данные} 
В качестве русскоязычного набора данных для классификации тональности, использовался набор данных {RuReviews}~\cite{ru_sentiment}. Данный набор данных содержит отзывы из крупного российского электронного магазина из категории "Женские товары и ассексуары". Данный набор данных был выбран, потому что он имеет достаточно большой размер (82.6 тысяч тренировочных примеров) и находится в открытом доступе, несмотря на свою специфичность. Так как авторы набора данных не предоставили его разбиение на тренировочную, валидационную и тестовую выборки, он был разбит на эти три категории в тех же пропорциях, что и у набора данных {DynaSent} (r1).

\subsection{Классификация токсичности}
\subsubsection{Русскоязычные данные}
Для английского языка в работе использовался набор данных {Wiki Talk}~\cite{toxic} для задачи классификации токсичности. В этом наборе данных, состоящем из комментариев из Википедии и имевшем примерно 127.6 тысяч тренировочных примеров, есть всего два класса: \textit{toxic} и \textit{not toxic}. К первому классу относится примерно 10 процентов примеров (часть из которых слишком неблагозвучна для того, чтобы приводить их в диссертации). Ко второму классу, соответственно, примерно 90 процентов.  В работе использовалась предобработанная версия набора данных, предоставленная HuggingFace.\footnote{\url{https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic}} Данная версия подверглась незначительной очистке -- к примеру, если какая фраза начиналась и заканчивалась с кавычек, эти кавычки удалялись.
%CHECK SIZES
\subsubsection{Англоязычные данные}
Для русского языка в работе использовался двухклассовый набор данных {RuToxic}~\cite{ru_toxic}. Этот набор данных состоял из комментариев из Двача, крупнейшего русскоязычного анонимного форума.\footnote{\url{http://2ch.hk}} Набор данных состоит из примерно 162 тысяч примеров, примерно 31 тысяча из которых -- токсичные. Так как авторы не предоставили оригинальное разбиение данных на тренировочную, валидационную и тестовую выборку в своем репозитории\footnote{Ссылка на репозиторий: \url{https://github.com/s-nlp/rudetoxifier}}, набор данных был разбит на тренировочную, валидационную и тестовую выборку в тех же пропорциях, что и англоязычный набор данных. Итоговая тренировочная выборка содержала примерно 93.3 тысячи примеров.

\subsection{Классификация интентов и тематическая классификация }
%TODO. Набор данных -- - датасет? Топик -- тема? Единообразно сделать
В работе использовался набор данных {MASSIVE}~\cite{massive} для классификации интентов и для тематической классификации как для русского, так и для английского языка. Этот набор данных основан на англоязычном наборе данных SLURP\cite{slurp}, содержащем фразы, предназначенные голосовому ассистенту.
 Все примеры из этого набора данных были одновременно размечены (с адаптацией под национальные особенности) для 51 языка, включая русский и английский. Этот набор данных содержит для каждого языка 11514 тренировочных примера, 2033 валидационных примера и 2974 тестовых примера. Каждый пример принадлежит одному из 60 интентов и одной из 18 тем. 

Для каждой задачи, число примеров для каждого класса в тренировочных, валидационных и тестовых данных приведено в Аппендиксе~\ref{appendix:sizes_tr-ag} 
% TODO. Как смотрится ссылка? 

\section {Настройки экспериментов}\label{ch:tr-ag:settings}
%TODO. Беты единообразно
%TODO. Почему не тюним скорость обучения? Васю спросить о ссылке на статью
Для всех описанных в данной главе экспериментов, автор работы использовал оптимизатор AdamW~\cite{kingma_2014} с  $\beta_1$=0.9, $\beta_2$=0.99 и начальной скоростью обучения 2e-5.\footnote{Данные $\beta_1$ и $\beta_2$ использовались и во всех остальных описанных в диссертации экспериментах, если явно не указано иное.}  В качестве метрики, определяющей остановку обучения, использовалась средняя точность для всех задач\footnote{Или точность для одной задачи, если модели обучались в однозадачном режиме.}. Если на валидационных данных средняя точность не росла в течение двух эпох подряд, скорость обучения уменьшалась в два раза. Если на валидационных данных средняя точность не росла в течение трех эпох подряд, обучение прекращалось. В качестве итоговой версии модели, выбиралась модель с наилучшей средней точностью на валидационных данных.

Как правило, обучение завершалось в течение менее, чем 10-15 эпох, и всегда -- в течение менее, чем 25 эпох. 

Размер батча при обучении моделей был выбран равным 160 для того, чтобы максимально быстро проводить серии экспериментов на доступных в рамках Лаборатории нейронных сетей и глубокого обучения МФТИ вычислительных мощностях -- видеокартах Nvidia GeForce 1080 Ti и Tesla A100.
%TODO названия видеокарт
При обучении, примеры для каждой задачи выбрались с вероятностью, пропорциональной размеру её набора данных. Ниже подобный способ выбора примеров будет обозначаться как простое сэмплирование. Были также проведены предварительные эксперименты (на русскоязычных и англоязычных дистиллированных моделях, на полной обучающей выборке) с выбором других способов сэмплирования: а именно однородного (с одинаковой вероятностью выбора примера для каждой из задач) и аннеализованное (описанное в~\cite{stickland_2019}). Данные эксперименты не показали стойкого улучшения показателей по сравнению с простым сэмплированием, поэтому использовалось именно оно. 

Результаты всех экспериментов на диалоговых данных были усреднены по 3-5 запускам.\footnote{Для каждого из таких запусков различались инициализация задаче-специфичных слоев и случайное семя при сэмплировании.} Подробные результаты для каждого запуска приведены в Приложении~\ref{appendix:allruns_tr-ag}.

\section{Многозадачные и однозадачные модели -- эксперименты на полном наборе данных} 
% TODO BACKBONE ВИДЕОПАМЯТЬ ТЕРМИНЫ
Для английского языка, проводились эксперименты на трех разных базовых моделях типа BERT: \textit{distilbert-base-cased}~\cite{distilbert}, \textit{bert-base-cased}, И \textit{bert-large-cased}~\cite{bert}.  Эти три модели существенно различаются по объему потребляемых вычислительных ресурсов. Так, 
\textit{distilbert-base-cased} требует на 40\% меньше видеопамяти, чем \textit{bert-base-cased}, а \textit{bert-large-cased} требуетзанимает в  3.1 раза больше видеопамяти, чем \textit{bert-base-cased}. Таким образом, эти три базовые модели покрывают большое количество разных способов использования нейросетевых классификаторов для диалоговых моделей. 

Для русского языка, эксперименты проводились с базовыми моделями \textit{DeepPavlov/distilrubert-base-cased-conversational}~\cite{distilrubert} and \textit{DeepPavlov/rubert-base-cased-conversational}~\cite{rubert}.

Результаты экспериментов на описанных выше диалоговых данных для англоязычных и русскоязычных моделей приведены в Таблице~\ref{tab:tr-ag:en_results} и Таблице~\ref{tab:tr-ag:ru_results} соответственно. Для каждого эксперимента, приведена точность и усредненное macro-f1.
% TODO Average F1 macro? Как говорится? 

Другой важной исследовательской задачей является оценка многозадачной энкодер-агностичной модели на других типах задач и данных, отличающихся от приведенных выше. В целях решения данной задачи, автор также провел аналогичные эксперименты для англоязычных моделей на бенчмарке GLUE~\cite{wang_2018} с теми же самыми гиперпараметрами.\footnote{В связи с тем, что результаты на бенчмарке GLUE оценивается на сервере, у которого есть жесткие ограничения на то, сколько раз подряд можно отправлять свои результаты, усреднение по нескольким запускам на бенчмарке GLUE не проводилось.}. Результаты этих экспериментов представлены в таблице~\ref{tab:tr-ag:mtl_glue}.

Для всех таблиц в этой главе режим S означает отдельную модель для каждую из задач и режим M многозадачную модель. "Число батчей" означает число батчей, которые видела модель при своем обучении.

\begin{table*}
 \caption{Метрики англоязычных моделей (точность/макро-F1) для пяти англоязычных диалоговых задач.Режим S означает однозадачные модели, режим M означает многозадачные модели. \textit{distilbert} означает \textit{distilbert-base-cased}, \textit{bert} - \textit{bert-base-cased}, \textit{bert-large} - \textit{bert-large-cased}. Усреднено по трем запускам.}
 \label{tab:tr-ag:en_results}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Модель} & \multirow{2}{*}{Режим} & \multirow{2}{*}{Среднее} & Эмоции & Тональность & Токсичность & Интенты & Темы & Число \\
& & & 39.4k & 80.5k & 127.6k & 11.5k & 11.5k & батчей \\ \hline \hline
\textit{\multirow{2}{*}{distilbert}} & S & \textbf{82.9/78.4} & \textbf{70.3/63.1} & 74.7/74.3 & 91.5/81.2 & \textbf{87.4/82.7} & \textbf{91.0/90.6} & 11390 \\ %\hline
 & M  & 82.1/77.2 & 67.7/60.7 & \textbf{75.2/75.0} & 90.6/79.8 & 86.3/80.4 & 90.8/90.1 & 14000 \\ \hline
\textit{\multirow{2}{*}{bert}} & S & \textbf{83.9/79.7} & \textbf{71.2/64.2} & 76.1/75.8 & \textbf{93.2/83.5} & \textbf{87.9/84.2} & \textbf{91.3/90.7} & 9470 \\ %\hline
 & M &  83.0/78.4 & 69.0/63.1 & \textbf{76.5/76.4} & 91.4/80.8 & 87.1/81.2 & 91.2/90.6 & 11760 \\ \hline
\textit{\multirow{2}{*}{bert-large}} & S &  \textbf{84.7/80.5} & \textbf{70.9/64.4} & \textbf{80.5/80.4} & \textbf{92.1/82.2} & \textbf{88.4/84.9} & 91.3/90.7 & 8526 \\ %\hline
 & M  & 83.6/78.7 & 69.0/61.8 & 79.0/78.9 & 91.3/80.9 & 87.3/80.9 & \textbf{91.3/90.8} & 11200 \\ \hline
 \end{tabular}
 }
\end{table*}
 
\begin{table*}
 \caption{Метрики русскоязычных моделей (точность/f1 macro) для пяти диалоговых задач. Режим S означает однозадачные модели, режим M означает многозадачные модели. \textit{distilrubert} означает базовую модель \textit{DeepPavlov/distilrubert-base-cased-conversational}, \textit{rubert} - базовую модель \textit{DeepPavlov/rubert-base-cased-conversational}. Усреднено по трем запускам.}
 \label{tab:tr-ag:ru_results}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Модель} & \multirow{2}{*}{Режим} & \multirow{2}{*}{Среднее} & Эмоции & Тональность & Токсичность & Интенты & Темы & Число \\
& & & 6.5k & 82.6k & 93.3k & 11.5k & 11.5k & батчей \\ \hline \hline
\textit{\multirow{2}{*}{distilrubert}} & S & 86.9/84.1 & 82.2/76.1 & 77.9/78.2 & 97.1/95.4 & 86.7/81.6 & 90.4/89.5 & 8472 \\
 & M & 86.3/82.6 & 81.0/74.6 & 77.7/77.7 & 96.9/95.0 & 85.2/75.9 & 90.7/89.9 & 8540 \\ \hline
\textit{\multirow{2}{*}{rubert}} & S & 86.5/83.4 & 80.9/75.3 & 78.0/78.2 & 97.2/95.6 & 86.2/79.1 & 90.0/89.0 & 7999 \\ 
 & M & 86.2/82.6 & 80.5/73.8 & 77.6/77.6 & 96.8/95.0 & 85.3/76.9 & 90.5/89.8 & 8113 \\ \hline
 \end{tabular}
 }
 \end{table*}

\begin{table*}
\caption{Метрики многозадачной энкодер-агностичной модели для набора задач GLUE. M.Corr означает корреляцию Мэттью, P/S означает корреляцию Пирсона-Спирмена, Acc точность, F1 - макро-F1. Режим S означает однозадачные модели, режим M означает многозадачные модели. Размер означает размер тренировочного набора данных. \textit{distilbert} означает \textit{distilbert-base-cased}, \textit{bert} - \textit{bert-base-cased}, \textit{bert-large} - \textit{bert-large-cased}.}
\label{tab:tr-ag:mtl_glue}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{3}{*}{Модель} & \multirow{3}{*}{Режим}  & Среднее & CoLA & SST-2 & MRPC &STS-B &QQP&MNLI & QNLI & RTE & AX & Число \\
\cline{3-11}
   &  & Размер  & 8.6k & 67.3k & 2.5k & 5.7k & 363.8k & 392.7k & 104.7k & 2.5k & как у MNLI & батчей \\ 
\cline{3-11}   
   &  & метрика  & M.Corr & Acc & F1/Acc & P/S Corr & F1/Acc & Acc (m/mm) & Acc & Acc & M.Corr &  \\ \hline \hline
Человек & - & 87.1 & 66.4 & 97.8 & 86.3/80.8 & 92.7/92.6 & 59.5/80.4 & 92.0/92.8 & 91.2 & 93.6 & - & -\\ \hline
%\textit{\multirow{2}{*}{distilbert-base-cased}} & S & 73.1 & \textbf{42.4} & \textbf{92.1} & 85.6/\textbf{80.3} & 78.8/76.8 & \textbf{69.5/88.5} & \textbf{81.3/80.8} & \textbf{87.5} & 49.8 & 29.9 & 70846 \\ 
\textit{\multirow{2}{*}{distilbert}} & S & 73.3 & \textbf{42.4} & \textbf{92.1} & 85.6/\textbf{80.3} & 78.8/76.8 & \textbf{69.5/88.5} & \textbf{81.3/80.8} & \textbf{87.5} & 52.1 & 29.9 & 70861 \\ 
 & M & \textbf{74.5} & 36.0 & 91.0 & \textbf{85.7}/79.9 & \textbf{82.6/81.6} & 68.4/87.4 & 80.4/80.3 & 86.0 & \textbf{69.5} & \textbf{30.1} & 88905 \\  \hline
\textit{\multirow{2}{*}{bert}} & S & 77.3 & \textbf{53.7} & \textbf{93.2} & \textbf{87.7/82.8} & 83.8/82.2 & \textbf{70.3/88.9} & \textbf{83.8/83.1} & \textbf{90.6} & 62.1 & 32.1 & 42722\\ 
 & M & \textbf{77.8} & 45.8 & 92.9 & 86.8/82.2 & \textbf{85.3/84.7} & 70.2/88.6 & 83.5/82.6 & 90.1 & \textbf{74.5} & \textbf{32.8} & 112613\\  \hline
\textit{\multirow{2}{*}{bert-large}} & S & \textbf{79.5} & \textbf{59.2} & \textbf{94.9} & 85.0/80.6 & \textbf{85.8/84.5} & 70.5/89.1 & \textbf{86.7/85.6} & 92.2 & 70.1 & \textbf{39.4} & 37290 \\ 
 & M & \textbf{79.5} & 50.8 & 94.1 & \textbf{87.3/82.8} & 83.8/83.9 & \textbf{71.0/89.2} & 85.9/85.0 & \textbf{92.4} & \textbf{78.5} & 38.5 & 53343 \\  \hline
\end{tabular}
}
\end{table*}


В общем и целом, метрики многозадачных энкодер-агностичных моделей на диалоговых как для русского, так и для английского языка примерно соответствуют метрикам однозадачных моделей.
 Для бенчмарка GLUE многозадачные модели дпже превосходят по своей средней метрике однозадачные модели за счет малоразмерных задач (STS-B, AX и особенно RTE), на которых лучше работает перенос знаний с задач, у которых более крупная обучающая выборка. 

При этом данная архитектура работает не хуже архитектуры MT-DNN, описанной в Главе~\ref{ch:nn}.
Эта архитектура требует больше параметров, чем рассмотренный способ, за счет использования стохастических сетей ответа в задаче-специфичных слоях.

Однако Таблица~\ref{tab:tr-ag:comparison} показывает, что использование данного способа не привело к улучшению метрик.

\begin{table*}
 \caption{Точность/f1 macro на задачах из Таблицы~\ref{tab:tr-ag:en_results} для различных многозадачных моделей и число параметров у этих моделей, для базовой модели distilbert-base-cased. Энкодер-агн. означает энкодер-агностичную модель. Усреднено по 3 запускам.}
 \label{tab:tr-ag:comparison}
\centering
\resizebox{\textwidth}{!}{%%
%\scalebox{0.65}{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Модель} & Число & \multirow{2}{*}{Среднее} & Эмоции & Тональность & Токсичность & Интенты & Темы & Число \\
& параметров & & 39.4k & 80.5k & 127.6k & 11.5k & 11.5k & батчей \\ \hline \hline
{Энкодер-агн.} & 65,850,714 & 82.1/77.2 & 67.7/60.7 & {75.2/75.0} & 90.6/79.8 & 86.3/80.4 & 90.8/90.1 & 14,000  \\ \hline
{MT-DNN} & 68,014,424 & 82.1/77.4 & 67.5/59.9 & 73.9/73.5 & 91.5/80.9 & 87.0/82.4 & 91.0/90.4 & 19,600 \\ \hline
%XCA~\cite{el-nouby2021xcit} & 73,014,824 & 82.2/77.3 & 68.1/61.3 & 74.4/73.9 & 90.8/80.0 & 86.8/80.8 & 90.9/90.5 & 14,000 \\ \hline
%{Задаче-специфичное внимание}~\cite{TaskEmbedded2021} & 73,045,064 & 82.3/77.1 & 68.2/61.2 & 74.8/74.3 & 91.3/80.8 & 86.4/78.8 & 90.9/90.4 & 13,440 \\ \hline
%{Модули-призраки}~\cite{GhostBERT2021} & 74,311,904 &82.4/77.1 & 68.3/60.6 & 75.0/74.6 & 91.7/81.2 & 86.3/78.9 & 90.7/90.2 & 11,200 \\ \hline
\end{tabular}}
\end{table*}

Среди поставленных в работе задач было также исследование того, как будет меняться эффект переноса знаний при уменьшении размера обучающей выборки. Данному исследованию посвящен следующий раздел. 

\subsection{Эффект уменьшения размера обучающей выборки (англоязычные данные)}
% TODO -- Автор делал или в пассивном залоге? Как писать? 
В работе был также исследован эффект уменьшения размера обучающей выборки для англоязычных данных. В частности, автор работы обучал модель с теми же гиперпараметрами, что и в предыдущем режиме, но только на небольшой доле тренировочных данных. При этом валидационные и тестовые данные, для чистоты эксперимента, не менялись. В связи с малым размером обучающей выборки, для этого эксперимента данные усреднялись по пяти запускам. Для ускорения вычислений, эксперименты в этом разделе проводились только для базовой модели \textit{distilbert-base-cased}. 

Особо отмечаю, что для каждого такого эксперимента разбиение было одним и тем же, то есть при проведении любого эксперимента с тем или иным процентом тренировочных данных в этих данных содержались данные из всех экспериментов с меньшими процентами тренировочных данных. 

Результаты данного эксперимента представлены в Таблице~\ref{tab:tr-ag:en_dialog_part} и на Графике~\ref{fig:tr-ag:en_dialog_part}. Результаты для каждой задачи представлены на Графике~\ref{fig:tr-ag:en_dialog_part_n_samples}. % TODO -- ВСТРОИТЬ ГРАФИК

Из представленных данных можно увидеть, что в общем и целом, многозадачный перенос знаний работает лучше для задач с меньшим числом примеров (при условии, что в обучающей выборке есть задачи, у которых число примеров существенно больше). 

В общем и целом, можно сделать вывод, что метрики многозадачных моделей превосходят метрики для однозадачных моделей только на небольших данных (2-5\% от всего набора англоязычных данных), и уже на 9\% от набора англоязычных данных это преимущество исчезает. Более подробно результаты этого эксперимента проанализированы в разделе~\ref{ch:tr-ag:discussion_conclusion}

\begin{figure}
\caption{Средняя точность для англоязычных диалоговых задач. Эффект уменьшения тренировочных данных. Результаты усреднены по пяти запускам.}
%\begin{minipage}{1\textwidth}
\centering
\begin{tikzpicture}
\label{fig:tr-ag:en_dialog_part}
\begin{axis}[xlabel = Процент используемых тренировочных данных,
ylabel = Средняя точность,
legend pos= south east,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={2,3,5,7,9,10,15},
ymin=40,ymax=85,
legend cell align={left},
legend style={nodes={scale=0.7, transform shape}}
]
\addplot[color=blue,solid, mark=*] coordinates {
(2, 64.8)%50
(3, 68.8)%50
(5, 71.7)%100
(7,74.2)
%(7.5,74.6)
% (8,74.9)
(9,75.4)
(10, 75.9)%300
(15, 77.4)
};
\addlegendentry{Многозадачные модели}
\addplot[color=green,dashed,mark=*] coordinates {
(2, 44.9)%50
(3, 59.6)%100
(5, 69.1)%300
(7,73.5)
%(7.5,73.5)
% (8,73.8)%500
(9,76.7)
(10,77.1)
(15, 78.5)
};
\addlegendentry{Однозадачные модели}
\end{axis}%
\end{tikzpicture}%
%\end{minipage}
\end{figure}

\begin{table*}
\caption{Точность/ макро-F1 для запусков на части тренировочных данных.  Режим M означает многозадачные модели, режим S означает однозадачные модели, и Доля означает долю использованных тренировочных данных. Базовая модель \textit{distilbert-base-cased}. Усреднено по пяти запускам. }
\label{tab:tr-ag:en_dialog_part}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 \multirow{2}{*}{Режим} &  \multirow{2}{*}{Доля} &  \multirow{2}{*}{Среднее} & Эмоции & Тональность & Токсичность & Интенты & Темы & Число \\
& & & 39.4k & 80.5k & 127.6k & 11.5k & 11.5k & батчей \\
\hline \hline
S & 15\% & 78.5/70.9 & 65.8/50.6 & 69.3/68.8 & 92.2/81.2 & 78.7/68.8 & 86.3/85.1 & 2173 \\ \hline
M & 15\% & 77.4/70.6 & 64.0/55.0 & 68.3/67.7 & 91.6/80.0 & 76.9/64.6 & 86.4/85.4 & 4741 \\ \hline
S & 10\% & 77.1/68.4 & 64.6/45.0 & 68.3/67.8 & 92.2/81.0 & 75.5/64.7 & 84.8/83.3 & 1579 \\ \hline
M & 10\% & 75.9/69.1 & 62.6/53.6 & 66.6/65.8 & 91.5/79.7 & 74.3/63.2 & 84.6/83.3 & 4295 \\ \hline
S & 9\% & 76.7/67.4 & 64.6/43.9 & 68.2/67.7 & 91.8/80.4 & 74.4/62.7 & 84.2/82.4 & 1457 \\ \hline
M & 9\% & 75.4/67.8 & 62.1/52.4 & 66.5/65.7 & 91.4/79.5 & 72.4/58.5 & 84.4/83.0 & 3695 \\ \hline
%S & 8\% & 73.8/64.6 & 63.7/43.5 & 67.6/67.0 & 92.0/80.5 & 62.0/49.7 & 83.9/82.1 & 1381 \\ \hline
%M & 8\% & 74.9/67.2 & 61.7/51.4 & 66.7/66.0 & 91.5/79.5 & 71.1/57.3 & 83.6/81.7 & 3511 \\ \hline
%S & 7.5\% & 73.5/64.0 & 63.8/42.5 & 67.4/66.9 & 91.6/80.1 & 61.3/48.6 & 83.6/81.7 & 1293 \\ \hline
%M & 7.5\% & 74.6/66.9 & 61.0/50.2 & 67.0/66.4 & 91.5/79.5 & 70.3/56.9 & 83.2/81.4 & 2995 \\ \hline
S & 7\% & 73.5/64.0 & 63.3/42.1 & 67.9/67.4 & 91.8/80.1 & 61.4/49.4 & 83.3/81.1 & 1251 \\ \hline
M & 7\% & 74.2/66.4 & 61.1/50.4 & 65.8/65.1 & 91.0/78.9 & 70.0/56.3 & 83.1/81.3 & 2882 \\ \hline
S & 5\% & 69.1/59.0 & 62.5/38.9 & 66.9/66.3 & 91.8/79.9 & 42.7/30.8 & 81.6/78.8 & 901 \\ \hline
M & 5\% & 71.7/62.4 & 60.5/48.6 & 64.4/63.4 & 90.8/78.5 & 62.4/44.4 & 80.2/77.3 & 2381 \\ \hline
S & 3\% & 59.6/49.0 & 60.6/37.7 & 65.2/64.5 & 91.8/79.3 & 26.5/16.9 & 54.0/46.5 & 584 \\ \hline
M & 3\% & 68.8/58.1 & 58.6/42.7 & 62.5/61.3 & 91.0/78.3 & 55.5/37.1 & 76.4/71.0 & 1566 \\ \hline
S & 2\% & 44.9/31.5 & 48.7/21.7 & 39.6/26.5 & 91.8/79.0 & 2.6/0.2 & 41.4/30.1 & 274 \\ \hline
M & 2\% & 64.8/52.1 & 57.6/38.4 & 61.4/60.1 & 90.8/78.0 & 44.2/23.5 & 69.9/60.4 & 923 \\ \hline
\end{tabular}
}
\end{table*}



\pgfplotsset{every tick label/.append style={font=\tiny}}
\begin{figure}[!ht]
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число тренировочных примеров,
ylabel = Точность,
title=Средняя точность,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={5k, 8k, 14k, 19k, 24k, 27k, 41k, 271k},
ymin=40,ymax=90,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 44.9)
(1, 59.6)
(2, 69.1)
(3, 73.5)
(4, 76.7)
(5, 77.1)
(6, 78.5)
(7, 82.9)
};
\addlegendentry{Однозадачная точность (EN)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 64.8)
(1, 68.8)
(2, 71.7)
(3, 74.2)
(4, 75.4)
(5, 75.9)
(6, 77.4)
(7, 82.1)
};
\addlegendentry{Многозадачная точность (EN)}
\end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация эмоций,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={0.8k, 1.2k, 2k, 2.7k, 3.6k, 3.9k, 5.9k, 39.5k},
ymin=45,ymax=80,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]

\addplot[color=orange,dotted, mark=*] coordinates {
(0, 48.7)
(1, 60.6)
(2, 62.5)
(3, 63.3)
(4, 64.6)
(5, 64.6)
(6, 65.8)
(7, 70.3)
};
\addlegendentry{Однозадачная точность (EN)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 57.6)
(1, 58.6)
(2, 60.5)
(3, 61.1)
(4, 62.1)
(5, 62.6)
(6, 64.0)
(7, 67.7)};
\addlegendentry{Многозадачная точность (EN)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}

\medskip

\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация тональности,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={2.6k, 3.8k, 6.4k, 8.9k, 11.5k, 12.7k, 19.1k, 127.7k},
ymin=35,ymax=80,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 39.6)
(1, 65.2)
(2, 66.9)
(3, 67.9)
(4, 68.2)
(5, 68.3)
(6, 69.3)
(7, 74.7)
};
\addlegendentry{Однозадачная точность (EN)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 61.4)
(1, 62.5)
(2, 64.4)
(3, 65.8)
(4, 66.5)
(5, 66.6)
(6, 68.3)
(7, 75.2)};
\addlegendentry{Многозадачная точность (EN)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация токсичности,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={1.6k, 2.4k, 4.0k, 5.6k, 7.2k, 8k, 12k, 80k},
ymin=85,ymax=95,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 91.8)
(1, 91.8)
(2, 91.8)
(3, 91.8)
(4, 91.8)
(5, 92.2)
(6, 92.2)
(7, 91.5)
};
\addlegendentry{Однозадачная точность (EN)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 90.8)
(1, 91.0)
(2, 90.8)
(3, 91.0)
(4, 91.4)
(5, 91.5)
(6, 91.6)
(7, 90.6)};
\addlegendentry{Многозадачная точность (EN)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}

\medskip

\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация интентов,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={1,2,3,4,5,6,7},
xticklabels={0.3k, 0.6k, 1.2k, 1.7k, 2.3k, 2.9k, 5.8k, 11.5k},
ymin=25,ymax=85,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
%(0, 2.6)
(1, 26.5)
(2, 42.7)
(3, 61.4)
(4, 74.4)
(5, 75.5)
(6, 78.7)
(7, 87.4)
};
\addlegendentry{Однозадачная точность (EN)}
\addplot[color=red,solid,mark=*] coordinates {
%(0, 44.2)
(1, 55.5)
(2, 62.4)
(3, 70.0)
(4, 72.4)
(5, 74.3)
(6, 76.9)
(7, 86.3)};
\addlegendentry{Многозадачная точность (EN)}
\end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Тематическая классификация,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={0.3k, 0.6k, 1.2k, 1.7k, 2.3k, 2.9k, 5.8k, 11.5k},
ymin=35,ymax=90,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 41.4)
(1, 54.0)
(2, 81.6)
(3, 83.3)
(4, 84.2)
(5, 84.8)
(6, 86.3)
(7, 91.0)
};
\addlegendentry{Однозадачная точность (EN)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 69.9)
(1, 76.4)
(2, 80.2)
(3, 83.1)
(4, 84.4)
(5, 84.6)
(6, 86.4)
(7, 90.8)
};
\addlegendentry{Многозадачная точность (EN)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}


\caption{Однозадачная и многозадачная точность для каждой задачи. Английский язык.}
\label{fig:tr-ag:en_dialog_part_n_samples}

\end{figure}
%todo in plot consistently denominate numbers



Другим интересным направлением исследований является исследование переноса знаний между английским и русским языками в многозадачных моделях. Для исследования данного переноса автор диссертационной работы использовал мультиязыковые базовые модели, предобучавшиеся на большом числе языков. 


\subsection{Многоязычные многозадачные модели -- эффект кросс-языкового обучения}

На этой стадии экспериментов, использовались только многоязычные модели. В качестве многоязычных базовых моделей использовались \textit{distilbert-base-multilingual-cased} и \textit{bert-base-multilingual-cased}. На этом этапе решались следующие задачи:

 \begin{itemize}
\item Сравнить качество многозадачных и однозадачных моделей для русского языка при использовании многоязычных базовых моделей. 
\item Проверить, как меняются результаты у однозадачных и у многозадачных моделей, если добавлять при их обучении к русскоязычным данным англоязычные данные, объединяя данные по задаче (то есть для каждой задачи, учить модель на английских и русских данных, но валидировать только на русских).
\item Проверить, дает ли для описанного в предыдущем пункте какое-то улучшение, если считать англоязычные задачи отдельными задачами (валидируясь все так же только на русскоязычные данных), и соответственно, при обучении на русскоязычных задачах использовать только русскоязычные данные, а при англоязычных -- только англоязычные. 
\end{itemize} 

Заметим, что так как англоязычных открытых данных для большинства задач гораздо больше, чем русскоязычных, именно изучение переноса знаний с английского языка на русский представляет бОльший практический интерес, чем изучение переноса знаний с русского языка на английский. Хотя в разделе~\ref{ch:rutopics} изучается и такой перенос знаний тоже. 
%TODO. Формат представления Accuracy /f1 -- должен быть единообразным по диссеру? 
%TODO. Выделять режимы экспериментов в таблицах и перед ними через Italic? 
\begin{table*}
\caption{Точность/f1 macro на русскоязычных данных для многоязычных моделей. Режим S означает однозадачные модели, режим M -- многозадачные модели. RU означает русскоязычные данные, EN означает англоязычные данные. Объединенные означает, что русскоязычные и англоязычные данные объединены по задаче, Отдельные означает, что русскоязычные и англоязычными задачи считаются отдельными задачами. \textit{distilbert-mult} обозначает модель \textit{distilbert-base-multilingual-cased}, \textit{bert-mult} - модель \textit{bert-base-multilingual-cased}. Усреднено по трем запускам. }
\label{mult_results}
%\begin{tabular}{|c|c|c||c|c|c|c|c|c|} \hline
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c||c|c|c|c|c|c||c|} \hline
Модель & \begin{tabular}[c]{@{}l@{}}Тренировочные\\данные\end{tabular} & Режим & Среднее & \begin{tabular}[c]{@{}l@{}}Эмоции\end{tabular} & \begin{tabular}[c]{@{}l@{}}Тональность\end{tabular} & \begin{tabular}[c]{@{}l@{}}Токсичность\end{tabular} & \begin{tabular}[c]{@{}l@{}}Интенты\end{tabular} & \begin{tabular}[c]{@{}l@{}}Темы\end{tabular} &\begin{tabular}[c]{@{}l@{}}Число\\батчей\end{tabular} \\
\hline \hline
\textit{distilbert-mult} & RU & S & 84.7/81.0 & 77.4/69.1 & 77.7/77.9 & 96.7/94.8 & 83.5/76.6 & 88.1/86.9 & 10058 \\ %\hline
\textit{distilbert-mult} & RU & M & 84.3/80.2 & 78.1/70.5 & 76.8/76.7 & 96.5/94.4 & 81.9/72.3 & 88.2/87.1 & 9821 \\ \hline
\textit{distilbert-mult} & \begin{tabular}[c]{@{}l@{}}RU+EN,\\объединенные\end{tabular} & S & 85.2/81.8 & 78.9/70.2 & 77.4/77.3 & 96.8/94.9 & 84.7/79.1 & 88.4/87.4 & 31843 \\ %\hline
\textit{distilbert-mult} & \begin{tabular}[c]{@{}l@{}}RU+EN,\\объединенные\end{tabular} & M & 84.5/81.1 & 77.9/70.7 & 76.6/76.7 & 96.5/94.5 & 82.9/76.5 & 88.4/87.2 & 17790 \\ \hline
\textit{distilbert-mult} & \begin{tabular}[c]{@{}l@{}}RU+EN,\\отдельные\end{tabular} & M & 84.4/80.6 & 77.6/70.0 & 76.8/77.1 & 96.5/94.5 & 82.4/73.9 & 88.3/87.2 & 23688 \\ \hline
\textit{bert-mult} & RU & S & 84.7/80.2 & 76.6/64.2 & 77.8/78.2 & 96.9/95.1 & 83.9/76.3 & 88.4/87.0 & 10884 \\ %\hline
\textit{bert-mult} & RU & M & 84.8/81.4 & 78.4/71.4 & 76.3/76.3 & 96.8/94.8 & 83.7/76.6 & 89.0/87.8 & 12810 \\ \hline
\textit{bert-mult} & \begin{tabular}[c]{@{}l@{}}RU+EN,\\объединенные\end{tabular} & S & 85.6/82.3 & 78.9/70.1 & 77.6/77.8 & 96.9/94.9 & 85.0/80.4 & 89.4/88.5 & 23752 \\ %\hline
\textit{bert-mult} & \begin{tabular}[c]{@{}l@{}}RU+EN,\\объединенные\end{tabular} & M & 85.2/82.3 & 79.2/72.7 & 76.4/76.6 & 96.7/94.8 & 84.3/79.3 & 89.4/88.3 & 20755 \\ \hline
\textit{bert-mult} & \begin{tabular}[c]{@{}l@{}}RU+EN,\\отдельные\end{tabular} & M & 85.0/81.6 & 78.3/71.4 & 77.1/77.0 & 96.7/94.7 & 84.0/76.7 & 89.1/88.0 & 22701 \\ \hline
\end{tabular}
}
\end{table*}

Как можно видеть, результаты для каждого из экспериментов в этой серии довольно похожи друг на друга: добавление английских данных к русским выводит нас на плато, лишь с небольшими улучшениями по сравнению с использованием только русскоязычных данных.  

При этом выделение англоязычных данных в отдельные задачи не приводит к дополнительному улучшению и даже приводит к небольшому ухудшению. Это показывает, что перенос знаний лучше работает в рамках одной задачи, чем в рамках разных задач. Это можно  объяснить тем, что в первом случае перенос знаний происходит и для тела модели, и для ее задаче-специфичных слоев, а во втором -- только для тела модели. Тем не менее, этот эффект выражен слабо и нуждается в дополнительной проверке в будущих исследованиях.

Более точное исследование того, насколько сильно помогает добавление англоязычных данных в обучающую выборку, когда русскоязычных данных у нас мало, требует дополнительных экспериментов. Еще раз отмечаю, что эти эксперименты имеют прикладное значение, так как для большинства задач англоязычных данных в открытом доступе гораздо больше, чем русскоязычных. Эти эксперименты описаны в следующем разделе.

\subsection{Насколько помогает добавление англоязычных данных? }

В этой серии экспериментов изучалось поведение многозадачных и однозадачных моделей при объединении русскоязычных и англоязычных данных.  Автор работы изучал, насколько изменятся показатели модели \textit{distilbert-base-multilingual-cased} (в многозадачном или однозадачном режиме), обученной на некой доле русскоязычных данных, если добавить к этим данным полные англоязычные тренировочные данные.

В частности, эксперименты проводились для следующих долей русскоязычных тренировочных данных: 0\%, 3\%, 5\%, 15\%, 20\%, 25\%, 50\% и 100\%. Для каждого из этих экспериментов результаты усреднялись по трем запускам, кроме экспериментов с 3\% и 5\% русскоязычных тренировочных данных и без англоязычных данных, когда в связи с высокой дисперсией результатов они усреднялись по пять запускам. 
Валидация в данной серии экспериментов проводилась на англоязычных валидационных данных. В случае проведения валидации на русскоязычных валидационных данных вместо англоязычных валидационных данных, значимого влияния на результаты зафиксированно не было,поэтому цифры для этого режима приводятся только для экспериментов с 0\% и 100\% русскоязычных тренировочных данных. ) 
 Полные результаты данного эксперимента представлены в Таблице~\ref{tab:mult_smalldata_results}. 
%TODO все графики чтобы отображались. И лучше в pgfplots

В графической форме усредненные по задачам результаты данного эксперимента представлены на графике~\ref{fig:tr-ag:ru_dialog_part}, а результаты для каждой задачи -- на графике~\ref{fig:tr-ag:ru_dialog_part_n_samples}. 
%TODO -- дописать, что все метрики они для теста если явно не указано иное. И ссылки на свои статьи по аналогии с pseudolabel. 

%\begin{figure}[ht]
%  \includegraphics[width=\textwidth]{ru_dialog_part.jpg}
%  \caption{Точность \textit{distilbert-multilingual-base-cased} на русскоязычных данных в однозадачном и многозадачном режиме, при использовании некой доли русскоязычных обучающих данных или добавление к ним полного англоязычного набора данных.}\label{fig:tr-ag:ru_dialog_part}
%\end{figure}

\label{fig:thresholds_acc_ru}
\begin{figure}[!htbp]
\begin{minipage}{0.55\textwidth}
\begin{tikzpicture}[baseline={(0,2.1)}]%[scale=2]
\begin{axis}[xlabel = RU доля,
ylabel = Средняя точность,
legend pos= south east,
width=0.9\textwidth,
xtick={0,1,2,3,4,5,6,7,8},
xticklabels={2,3,5,10,15,20,25,50,100},
ymin=50,ymax=90,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(1, 57.02)
(2, 58.379999999999995)
(3, 75.66666666666667)
(4, 77.7)
(5, 78.36666666666667)
(6, 79.53333333333333)
(7, 82.5)
(8, 84.39999999999999)
};
\addlegendentry{S точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(1, 65.88)
(2, 70.3)
(3, 75.23333333333333)
(4, 77.23333333333333)
(5, 79.0)
(6, 79.60000000000001)
(7, 82.3)
(8, 84.33333333333333)
};
\addlegendentry{M точность (RU)}
\addplot[color=cyan,dashed, mark=*] coordinates {
(1, 70.73333333333333)
(2, 74.23333333333333)
(3, 77.39999999999999)
(4, 78.89999999999999)
(5, 80.13333333333334)
(6, 80.93333333333332)
(7, 82.83333333333333)
(8, 84.36666666666667)
};
\addlegendentry{S точность (RU+EN)}
\addplot[color=blue,dashed,mark=*] coordinates {
(1, 71.8)
(2, 74.96666666666667)
(3, 77.93333333333334)
(4, 79.66666666666667)
(5, 80.56666666666666)
(6, 81.36666666666666)
(7, 83.23333333333333)
(8, 85.16666666666667)
};
\addlegendentry{M точность (RU+EN)}
\end{axis}%
\end{tikzpicture}
% \hspace{3mm}
% \captionof{figure}
% \caption{Av}
\end{minipage}
\begin{minipage}{0.45\textwidth}
{
\scalebox{0.8}{
\begin{tabular}[baseline={(0,2.1)}]{|l||c|c|c|c|}
\hline
RU & S & M & S & M \\
доля & RU & RU & RU+EN & RU+EN \\ % Sizes are different for RU and RU+EN, so I don't give them here
\hline
3 & 57.0 & \textbf{65.9} & \textbf{71.8} & 70.7 \\ 
% \hline
5 & 58.4 & \textbf{70.3} & \textbf{75.0} & 74.2\\ 
% \hline
10 & \textbf{75.7} & 75.2 & \textbf{77.9} & 77.4\\ 
% \hline
15 & \textbf{77.7} & 77.2 & \textbf{79.7} & 78.9\\ 
% \hline
20 & 78.4 & \textbf{79.0} & \textbf{80.6} & 80.1 \\ 
% \hline
25 & 79.5 & \textbf{79.6} & \textbf{81.4} & 80.9 \\ 
% \hline
50 & \textbf{82.5} & 82.3 & \textbf{83.2} & 82.8 \\ 
% \hline
100 & \textbf{84.4} & 84.3 & \textbf{85.2} & 84.4 \\ \hline
\end{tabular}}
}
\end{minipage}
\caption{Средняя точность на русскоязычных данных для \textit{distilbert-base-multilingual-cased}. S означает однозадачный режим, M означает многозадачный режим, RU доля означает долю русскоязычных обучающих данных, использованных при обучении, RU означает только обучение на этой доле русскоязычных данных, RU+EN означает обучение на этой доле русскоязычных обучающих данных плюс на 100 процентах англоязычных обучающих данных. В Таблице~\ref{tab:mult_smalldata_results} приведены более подробные детали.}
\label{fig:tr-ag:ru_dialog_part}
\end{figure}
%\input{Dissertation/largeplot1.tex}
%\begin{figure}[ht]
%  \includegraphics[width=\textwidth]{ru_dialog_part_n_samples.jpg}
%  \caption{Точность \textit{distilbert-multilingual-base-cased} на русскоязычных данных в однозадачном и многозадачном режиме, при использовании некой доли русскоязычных обучающих данных, в зависимости от числа примеров. Для каждой задачи приводится точность, средняя точность также приводится для более удобного сравнения.}\label{fig:tr-ag:ru_dialog_part_n_samples}
%\end{figure}
\pgfplotsset{every tick label/.append style={font=\tiny}}

\begin{figure}[!ht]
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число тренировочных примеров,
ylabel = Точность,
title=Средняя точность,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={6k,10k,21k,31k,41k,51k,103k,205k},
ymin=50,ymax=90,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 57.02)
(1, 58.379999999999995)
(2, 75.66666666666667)
(3, 77.7)
(4, 78.36666666666667)
(5, 79.53333333333333)
(6, 82.5)
(7, 84.39999999999999)
};
\addlegendentry{Однозадачная точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 65.88)
(1, 70.3)
(2, 75.23333333333333)
(3, 77.23333333333333)
(4, 79.0)
(5, 79.60000000000001)
(6, 82.3)
(7, 84.33333333333333)};
\addlegendentry{Многозадачная точность (RU)}
\end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация эмоций,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={196, 327, 655, 983, 1311, 1639, 3278, 6557},
ymin=45,ymax=80,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 49.14)
(1, 48.260000000000005)
(2, 64.5)
(3, 66.10000000000001)
(4, 64.26666666666667)
(5, 66.96666666666665)
(6, 73.96666666666667)
(7, 76.46666666666667)
};
\addlegendentry{Однозадачная точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 62.61999999999999)
(1, 64.82000000000001)
(2, 68.73333333333333)
(3, 70.73333333333333)
(4, 71.36666666666667)
(5, 72.3)
(6, 75.0)
(7, 78.13333333333334)};
\addlegendentry{Многозадачная точность (RU)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}

\medskip

\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация тональности,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={2k, 4k, 8k, 12k, 17k, 21k, 41k, 83k},
ymin=65,ymax=80,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 69.46000000000001)
(1, 71.02000000000001)
(2, 73.3)
(3, 73.96666666666665)
(4, 74.36666666666666)
(5, 75.13333333333334)
(6, 76.36666666666667)
(7, 77.16666666666667)
};
\addlegendentry{Однозадачная точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 68.99999999999999)
(1, 70.14)
(2, 71.46666666666665)
(3, 71.7)
(4, 72.96666666666667)
(5, 72.66666666666667)
(6, 74.56666666666666)
(7, 76.23333333333333)};
\addlegendentry{Многозадачная точность (RU)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}[scale=1]
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация токсичности,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={3k, 5k, 9k, 14k, 19k, 23k, 47k, 93k},
ymin=90,ymax=100,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 91.50000000000001)
(1, 92.70000000000002)
(2, 93.93333333333334)
(3, 94.80000000000001)
(4, 95.06666666666666)
(5, 95.36666666666667)
(6, 96.13333333333333)
(7, 96.7)
};
\addlegendentry{Однозадачная точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 91.24000000000001)
(1, 92.6)
(2, 93.96666666666665)
(3, 94.60000000000001)
(4, 95.0)
(5, 95.33333333333333)
(6, 96.0)
(7, 96.5)};
\addlegendentry{Многозадачная точность (RU)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}

\medskip

\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Классификация интентов,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={0.3k, 0.6k, 1.2k, 1.7k, 2.3k, 2.9k, 5.8k, 11.5k},
ymin=25,ymax=85,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 38.9)
(1, 29.920000000000005)
(2, 67.7)
(3, 72.16666666666667)
(4, 75.33333333333333)
(5, 76.60000000000001)
(6, 79.96666666666668)
(7, 83.46666666666665)
};
\addlegendentry{Однозадачная точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 42.64)
(1, 52.98)
(2, 64.03333333333335)
(3, 68.6)
(4, 73.5)
(5, 73.83333333333333)
(6, 79.5)
(7, 82.36666666666667)};
\addlegendentry{Многозадачная точность (RU)}
\end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
\begin{tikzpicture}
\begin{axis}[xlabel = Число обучающих примеров,
ylabel = Точность,
title=Тематическая классификация,
legend pos= south east,
width=\textwidth,
% width=10cm,
% height=10cm,
% xmin=2,
% xmax=100,
xtick={0,1,2,3,4,5,6,7},
xticklabels={0.3k, 0.6k, 1.2k, 1.7k, 2.3k, 2.9k, 5.8k, 11.5k},
ymin=35,ymax=90,
legend cell align={left},
legend style={nodes={scale=0.5, transform shape}}
]
\addplot[color=orange,dotted, mark=*] coordinates {
(0, 36.16)
(1, 50.06)
(2, 78.80000000000001)
(3, 81.56666666666666)
(4, 82.86666666666666)
(5, 83.60000000000001)
(6, 86.13333333333334)
(7, 88.2)
};
\addlegendentry{Однозадачная точность (RU)}
\addplot[color=red,solid,mark=*] coordinates {
(0, 42.64)
(1, 52.98)
(2, 64.03333333333335)
(3, 68.6)
(4, 73.5)
(5, 73.83333333333333)
(6, 79.5)
(7, 82.36666666666667)};
\addlegendentry{Многозадачная точность (RU)}
\end{axis}%
\end{tikzpicture}
\end{subfigure}


\caption{Однозадачная и многозадачная точность для каждой задачи. Русский язык.}
\label{fig:tr-ag:ru_dialog_part_n_samples}
\end{figure}



 \begin{table*}
\caption{ Влияние добавления англоязычных данных. Точность/ f1-макро на русскоязычных данных для энкодер-агностичного \textit{distilbert-base-multilingual-cased}. Число батчей означает число батчей, которые видела модель в процессе своего обучения, режим S означает однозадачное обучение, режим M -- многозадачное обучение. RU доля -- доля тренировочных примеров, взятых из каждого русскоязычного тренировочного набора данных, и EN  доля -- доля примеров, взятых из каждого англоязычного тренировочного набора данных. Усреднено по 3 запускам, кроме указанных выше экспериментов, для которых усреднение проводилось по 5 запускам.}
\label{tab:mult_smalldata_results}
\resizebox{\textwidth}{!}{\begin{tabular}{|c|c|c|c||c|c|c|c|c|c||c|} \hline
Режим & \begin{tabular}[c]{@{}l@{}}RU\\доля\end{tabular} & \begin{tabular}[c]{@{}l@{}}EN\\доля\end{tabular} &\begin{tabular}[c]{@{}l@{}}Валидация\\на\end{tabular} & Среднее & \begin{tabular}[c]{@{}l@{}}Эмоции\end{tabular} & \begin{tabular}[c]{@{}l@{}}Тональность\end{tabular} & \begin{tabular}[c]{@{}l@{}}Токсичность\end{tabular} & \begin{tabular}[c]{@{}l@{}}Интенты\end{tabular} & \begin{tabular}[c]{@{}l@{}}Темы\end{tabular} & \begin{tabular}[c]{@{}l@{}}Число\\ батчей\end{tabular} \\\hline \hline
S & 100\% & 100\% & EN & 85.2/82.1 & 79.0/70.8 & 77.2/77.4 & 96.5/94.5 & 84.5/80.6 & 88.4/87.4 & 15946 \\
M & 100\% & 100\% & EN & 84.4/80.9 & 77.2/70.5 & 75.8/75.8 & 96.4/94.4 & 83.5/76.3 & 88.9/87.8 & 20737 \\ \hline
S & 50\% & 100\% & EN & 83.2/79.5 & 75.6/65.8 & 75.6/75.7 & 96.1/93.9 & 82.2/76.5 & 86.8/85.5 & 16672 \\
M & 50\% & 100\% & EN & 82.8/78.1 & 76.2/64.5 & 74.0/73.4 & 95.9/93.5 & 80.9/72.7 & 87.2/86.1 & 19336 \\ \hline
S & 25\% & 100\% & EN & 81.4/76.7 & 73.7/61.4 & 73.7/73.9 & 95.5/92.7 & 78.8/71.9 & 85.1/83.6 & 16589 \\
M & 25\% & 100\% & EN & 80.9/76.4 & 73.1/63.9 & 73.7/73.7 & 95.1/92.2 & 77.5/68.1 & 85.3/83.9 & 16665 \\ \hline
S & 20\% & 100\% & EN & 80.6/76.0 & 71.8/60.3 & 74.0/74.0 & 95.1/92.1 & 78.0/71.1 & 83.9/82.4 & 12951 \\
M & 20\% & 100\% & EN & 80.1/75.0 & 71.9/61.2 & 73.5/73.5 & 94.9/91.9 & 76.1/65.5 & 84.2/82.8 & 17429 \\ \hline
S & 15\% & 100\% & EN & 79.7/74.7 & 70.8/57.8 & 72.6/72.7 & 94.6/91.3 & 77.3/70.1 & 83.1/81.6 & 13037 \\
M & 15\% & 100\% & EN & 78.9/73.5 & 70.0/58.4 & 71.9/71.5 & 94.5/91.2 & 74.7/65.0 & 83.5/81.8 & 15599 \\ \hline
S & 10\% & 100\% & EN & 77.9/72.0 & 68.3/52.1 & 72.3/72.7 & 93.9/90.0 & 73.9/65.8 & 81.2/79.4 & 13545 \\
M & 10\% & 100\% & EN & 77.4/70.9 & 67.9/51.2 & 71.7/71.7 & 93.7/90.1 & 72.3/61.5 & 81.6/79.9 & 14471 \\ \hline
S & 5\% & 100\% & EN & 75.0/67.9 & 64.1/45.0 & 70.2/70.4 & 92.7/87.8 & 69.9/60.5 & 77.9/75.8 & 12567 \\
M & 5\% & 100\% & EN & 74.2/66.3 & 63.4/41.2 & 70.1/70.2 & 92.3/87.6 & 67.6/56.6 & 77.7/75.9 & 12779 \\ \hline
S & 3\% & 100\% & EN & 71.8/64.6 & 59.1/38.8 & 68.4/68.6 & 91.0/85.6 & 65.9/57.4 & 74.6/72.6 & 12065 \\
M & 3\% & 100\% & EN & 70.7/64.2 & 58.5/44.8 & 67.8/67.7 & 90.9/85.5 & 62.4/51.3 & 74.0/71.6 & 14896 \\ \hline
S & 0\% & 100\% & EN & 52.4/42.0 & 48.3/26.6 & 43.8/43.1 & 80.0/58.6 & 37.5/31.5 & 52.3/50.4 & 15469 \\
M & 0\% & 100\% & EN & 51.0/41.5 & 42.6/23.8 & 45.4/42.8 & 78.6/61.6 & 38.0/30.6 & 50.0/48.4 & 14000 \\ \hline
S & 100\% & 0\% & RU & 84.4/80.4 & 76.5/66.5 & 77.2/77.3 & 96.7/94.7 & 83.5/76.4 & 88.2/87.0 & 11199 \\
M & 100\% & 0\% & RU & 84.3/80.4 & 77.9/70.4 & 76.4/76.5 & 96.5/94.4 & 82.3/73.3 & 88.4/87.4 & 11956 \\ \hline
S & 50\% & 0\% & RU & 82.5/78.0 & 74.0/63.2 & 76.4/76.4 & 96.1/93.8 & 80.0/71.9 & 86.1/84.8 & 5878 \\
M & 50\% & 0\% & RU & 82.3/78.0 & 75.0/66.5 & 74.6/74.7 & 96.0/93.7 & 79.5/69.8 & 86.4/85.2 & 8090 \\ \hline
S & 25\% & 0\% & RU & 79.5/72.5 & 67.0/45.0 & 75.1/75.4 & 95.4/92.5 & 76.6/68.1 & 83.6/81.5 & 3496 \\
M & 25\% & 0\% & RU & 79.6/74.3 & 72.3/62.1 & 72.7/72.8 & 95.3/92.6 & 73.8/61.5 & 83.7/82.1 & 5830 \\ \hline
S & 20\% & 0\% & RU & 78.4/70.3 & 64.3/36.2 & 74.4/74.7 & 95.1/92.0 & 75.3/67.5 & 82.9/81.0 & 2796 \\
M & 20\% & 0\% & RU & 79.0/74.2 & 71.4/61.4 & 73.0/73.2 & 95.0/91.9 & 73.5/63.8 & 82.3/80.8 & 5773 \\ \hline
S & 15\% & 0\% & RU & 77.7/70.1 & 66.1/44.5 & 74.0/74.0 & 94.8/91.5 & 72.2/61.2 & 81.6/79.5 & 1997 \\
M & 15\% & 0\% & RU & 77.2/71.3 & 70.7/59.6 & 71.7/72.0 & 94.6/91.4 & 68.6/54.9 & 80.6/78.7 & 5320 \\ \hline
S & 10\% & 0\% & RU & 75.7/67.1 & 64.5/41.1 & 73.3/73.5 & 93.9/90.0 & 67.7/54.7 & 78.8/76.2 & 1469 \\
M & 10\% & 0\% & RU & 75.2/68.2 & 68.7/55.3 & 71.5/71.7 & 94.0/90.2 & 64.0/48.4 & 77.8/75.5 & 2836 \\ \hline
S & 5\% & 0\% & RU & 58.4/47.9 & 48.3/20.3 & 71.0/71.1 & 92.7/87.9 & 29.9/18.2 & 50.1/41.8 & 739 \\
M & 5\% & 0\% & RU & 70.3/61.6 & 64.8/48.3 & 70.1/70.3 & 92.6/88.0 & 53.0/35.0 & 71.2/66.3 & 2095 \\ \hline
S & 3\% & 0\% & RU & 57.0/45.2 & 49.1/20.5 & 69.5/69.6 & 91.5/85.8 & 38.9/24.7 & 36.2/25.6 & 521 \\
M & 3\% & 0\% & RU & 65.9/55.1 & 62.6/41.3 & 69.0/69.2 & 91.2/85.6 & 42.6/24.2 & 63.9/55.1 & 1132 \\ \hline
\end{tabular}
}
\end{table*}
%TODO. Формат таблиц единообразно

 \begin{table*} \caption{Сравнение валидации на русскоязычных и англоязычных данных. Точность/ f1-макро на русскоязычных данных для энкодер-агностичного \textit{distilbert-base-multilingual-cased}. Число батчей означает число батчей, которые видела модель в процессе своего обучения, режим S означает однозадачное обучение, режим M -- многозадачное обучение. RU доля -- доля тренировочных примеров, взятых из каждого русскоязычного тренировочного набора данных, и EN  доля -- доля примеров, взятых из каждого англоязычного тренировочного набора данных. Усреднено по 3 запускам, кроме указанных выше экспериментов, для которых усреднение проводилось по 5 запускам.}
\label{mult_smalldata_results2} 
\resizebox{\textwidth}{!}{ 
 \begin{tabular}{|c|c|c|c||c|c|c|c|c|c||c|} \hline 
Режим & \begin{tabular}[c]{@{}l@{}}RU\\доля\end{tabular} & \begin{tabular}[c]{@{}l@{}}EN\\доля\end{tabular} &\begin{tabular}[c]{@{}l@{}}Валидация\\на\end{tabular} & Среднее & \begin{tabular}[c]{@{}l@{}}Эмоции\end{tabular} & \begin{tabular}[c]{@{}l@{}}Тональность\end{tabular} & \begin{tabular}[c]{@{}l@{}}Токсичность\end{tabular} & \begin{tabular}[c]{@{}l@{}}Интенты\end{tabular} & \begin{tabular}[c]{@{}l@{}}Темы\end{tabular} & \begin{tabular}[c]{@{}l@{}}Число\\ батчей\end{tabular} \\ \hline \hline
 S & 100\% & 100\% & EN & 85.2/82.1 & 79.0/70.8 & 77.2/77.4 & 96.5/94.5 & 84.5/80.6 & 88.4/87.4 & 15946 \\
 S & 100\% & 100\% & RU & 85.3/81.9 & 79.2/71.4 & 77.2/77.3 & 96.7/94.7 & 84.6/78.2 & 88.6/87.7 & 29204 \\
M & 100\% & 100\% & EN & 84.4/80.9 & 77.2/70.5 & 75.8/75.8 & 96.4/94.4 & 83.5/76.3 & 88.9/87.8 & 20737 \\
M & 100\% & 100\% & RU & 84.4/80.7 & 77.6/69.8 & 76.8/76.9 & 96.6/94.6 & 82.4/74.5 & 88.8/87.8 & 21726 \\ \hline
 S & 50\% & 100\% & EN & 83.2/79.5 & 75.6/65.8 & 75.6/75.7 & 96.1/93.9 & 82.2/76.5 & 86.8/85.5 & 16672 \\
 S & 50\% & 100\% & RU & 83.5/79.6 & 76.7/67.6 & 76.1/76.2 & 96.2/93.9 & 81.7/74.9 & 86.7/85.4 & 17882 \\
 M & 50\% & 100\% & EN & 82.8/78.1 & 76.2/64.5 & 74.0/73.4 & 95.9/93.5 & 80.9/72.7 & 87.2/86.1 & 19336 \\
M & 50\% & 100\% & RU & 82.7/78.6 & 75.5/66.3 & 74.5/74.7 & 96.0/93.6 & 80.7/72.8 & 86.8/85.8 & 23203 \\ \hline 
S & 25\% & 100\% & EN & 81.4/76.7 & 73.7/61.4 & 73.7/73.9 & 95.5/92.7 & 78.8/71.9 & 85.1/83.6 & 16589 \\
S & 25\% & 100\% & RU & 81.8/77.3 & 74.5/63.4 & 74.6/74.9 & 95.4/92.6 & 79.1/71.7 & 85.1/83.7 & 15304 \\
M & 25\% & 100\% & EN & 80.9/76.4 & 73.1/63.9 & 73.7/73.7 & 95.1/92.2 & 77.5/68.1 & 85.3/83.9 & 16665 \\
M & 25\% & 100\% & RU & 81.0/76.6 & 73.3/63.8 & 73.5/73.8 & 95.0/92.2 & 78.1/69.5 & 85.1/83.9 & 19329 \\ \hline 
S & 20\% & 100\% & EN & 80.6/76.0 & 71.8/60.3 & 74.0/74.0 & 95.1/92.1 & 78.0/71.1 & 83.9/82.4 & 12951 \\
S & 20\% & 100\% & RU & 81.0/76.3 & 73.2/62.3 & 74.5/74.6 & 95.2/92.2 & 77.6/69.6 & 84.4/83.0 & 15798 \\
 M & 20\% & 100\% & EN & 80.1/75.0 & 71.9/61.2 & 73.5/73.5 & 94.9/91.9 & 76.1/65.5 & 84.2/82.8 & 17429 \\
M & 20\% & 100\% & RU & 80.3/75.3 & 72.3/61.5 & 73.9/74.1 & 94.9/92.0 & 76.1/66.1 & 84.5/83.1 & 14847 \\ \hline
 S & 15\% & 100\% & EN & 79.7/74.7 & 70.8/57.8 & 72.6/72.7 & 94.6/91.3 & 77.3/70.1 & 83.1/81.6 & 13037 \\
S & 15\% & 100\% & RU & 80.0/75.4 & 71.5/60.5 & 73.7/73.9 & 94.8/91.6 & 76.6/69.2 & 83.3/81.7 & 18014 \\
 M & 15\% & 100\% & EN & 78.9/73.5 & 70.0/58.4 & 71.9/71.5 & 94.5/91.2 & 74.7/65.0 & 83.5/81.8 & 15599 \\
M & 15\% & 100\% & RU & 79.0/73.1 & 69.8/54.1 & 71.7/71.5 & 94.5/91.3 & 75.5/66.6 & 83.5/82.1 & 17471 \\ \hline
 S & 10\% & 100\% & EN & 77.9/72.0 & 68.3/52.1 & 72.3/72.7 & 93.9/90.0 & 73.9/65.8 & 81.2/79.4 & 13545 \\
 S & 10\% & 100\% & RU & 78.2/72.0 & 69.4/50.5 & 72.1/72.4 & 94.3/90.6 & 74.4/66.8 & 81.0/79.5 & 17812 \\
M & 10\% & 100\% & EN & 77.4/70.9 & 67.9/51.2 & 71.7/71.7 & 93.7/90.1 & 72.3/61.5 & 81.6/79.9 & 14471 \\
M & 10\% & 100\% & RU & 77.3/71.2 & 67.8/54.3 & 72.0/72.1 & 93.4/89.7 & 71.4/59.7 & 81.7/79.9 & 13267 \\ \hline
 S & 5\% & 100\% & EN & 75.0/67.9 & 64.1/45.0 & 70.2/70.4 & 92.7/87.8 & 69.9/60.5 & 77.9/75.8 & 12567 \\
S & 5\% & 100\% & RU & 75.2/68.7 & 64.8/47.9 & 70.5/70.7 & 93.0/88.4 & 69.5/59.9 & 78.1/76.4 & 16024 \\
M & 5\% & 100\% & EN & 74.2/66.3 & 63.4/41.2 & 70.1/70.2 & 92.3/87.6 & 67.6/56.6 & 77.7/75.9 & 12779 \\
M & 5\% & 100\% & RU & 73.6/66.3 & 61.3/44.7 & 70.1/70.1 & 92.4/87.6 & 66.1/52.8 & 78.0/76.1 & 11618 \\ \hline
 S & 3\% & 100\% & EN & 71.8/64.6 & 59.1/38.8 & 68.4/68.6 & 91.0/85.6 & 65.9/57.4 & 74.6/72.6 & 12065 \\
 S & 3\% & 100\% & RU & 72.1/64.8 & 59.9/40.1 & 68.7/69.0 & 91.8/86.5 & 65.5/55.9 & 74.6/72.5 & 12298 \\
 M & 3\% & 100\% & EN & 70.7/64.2 & 58.5/44.8 & 67.8/67.7 & 90.9/85.5 & 62.4/51.3 & 74.0/71.6 & 14896 \\
M & 3\% & 100\% & RU & 70.7/63.0 & 58.7/39.5 & 67.8/67.2 & 90.6/85.2 & 62.1/50.8 & 74.2/72.1 & 14323 \\ \hline \end{tabular} } \end{table*} 


\section{Выводы и анализ результатов}\label{ch:tr-ag:discussion_conclusion}
Многозадачные энкодер-агностичные модели практически соответствуют однозадачным моделям по своим метрикам на диалоговых задачах. Для моделей, предобученных только на одном языке, разрыв в средней точности составляет около 0.8-0.9\% для английского языка и около 0.3-0.6\% для русского языка. Для многоязычных моделей, разрыв остается в тех же пределах, кроме одного эксперимента (\textit{bert-base-multilingual-cased}, обученный только на русскоязычных данных), для которого разрыв полностью исчезает.
%TODO. Тело модели --- базовая модель. Терминология.

Для набора задач GLUE, многозадачные англоязычные модели даже превосходят однозадачные модели по своей средней точности. Это происходит за счет задач с недостаточно большими тренировочными наборами данных (AX, STS-B и особенно RTE), метрики на которых улучшаются за счет переноса знаний с задач, для которых тренировочных данных на порядки больше (MNLI, QQP).
При этом обучение многозадачных нейронных сетей с тем же самым критерием остановки обучения требовало больше обучающих шагов, чем обучение соответствующих однозадачных моделей.

Причиной этого является то, что обучение многозадачных моделей не прекращалось до тех пор, пока метрики на задачах, для которых данных мало, не прекращали улучшаться.
Следовательно, примеры из достаточно крупных по размеру обучающей выборки задач, метрики для которых уже достигли своих точек насыщения,многозадачные модель видела чаще, чем видели соответствующие им однозадачные модели. При обучении на долях тренировочной обучающей выборки, этот эффект выражен сильнее -- вероятно, в связи с тем, что разрыв между точками насыщения для задач с меньшим объёмом обучающей выборки и задач с большим объемом обучающей выборки растет.

Для обучения на части тренировочных данных, можно видеть, что если обучать \textit{distilbert-base-multilingual-cased} на небольших долях тренировочных данных (порядка 2-5\%), многозадачные модели превосходят однозадачные по средней точности,как показано в Таблице~\ref{tab:mult_smalldata_results}. Как можно видеть из Таблицы~\ref{tab:tr-ag:en_dialog_part}, данный вывод справедлив и для \textit{distilbert-base-cased}, учившегося только на англоязычных данных -- в районе 9-10\% тренировочных данных для каждой из этих двух моделей это превосходство исчезает. По графикам~\ref{fig:tr-ag:ru_dialog_part_n_samples} и~\ref{fig:tr-ag:en_dialog_part_n_samples} можно видеть, что превосходство в точности для каждой из задач сильно зависит от размера набора данных -- чем меньше урезанный набор данных, тем выше преимущество многозадачных моделей. Исключением из этого правила является русскоязычная задача классификации эмоций -- вероятно, тут роль играет эффект переноса знаний с задачи классификации тональности.

%~\ref{tab:mult_smalldata_results2} --- Нет ссылки, она просто показывает, что нет разницы на чем валидировать

Гипотеза о том, что перенос знаний в многозадачных моделях зависит от размера набора данных, дополнительно подтверждается тем, что в экспериментах с добавлением английских данных, многозадачные модели не показывали явного преимущества над многозадачными. Вероятно, это означает, что, после добавления к каждой задаче 100\% англоязычных тренировочных данных, наборы данных уже стали слишком большими для достижения такого превосходства.

Кроме этого, стоит отметить, что добавление англоязычных тренировочных данных к русскоязычным улучшает метрики на русскоязычных тестовых данных. Чем меньше размер имеющихся русскоязычных тренировочных данных, тем сильнее повышается точность моделей от добавления англоязычных данных -- и выигрыш в точности может достигать нескольких процентов, если объем русскоязычных тренировочных данных достаточно маленький (3-10\% в Таблице~\ref{tab:mult_smalldata_results}.) Этот вывод справедлив как для однозадачных, так и для многозадачных моделей, и язык валидационных данных (английских или русских) не влиял на результаты экспериментов.

Главный \textbf{вывод} из этой главы -- \textbf{для достаточно малых данных многозадачные энкодер-агностичные модели превосходят по своей средней точности однозадачные, в особенности -- за счет задач с наименьшим объемом данных. При этом для таких многоязычных моделей наблюдается также перенос знаний с английского языка на русский в рамках одной задачи, и чем меньше русскоязычных данных, тем сильнее выражен перенос. Эта закономерность справедлива и для однозадачных моделей.}

Помимо этого, практический результат описанной в данной главе работы заключается в том, что \textbf{программный код для реализации многозадачной энкодер-агностичной нейросетевой модели встроен в библиотеку DeepPavlov, имевшую более 500000 скачиваний на момент встраивания кода. Данные модели позволяют решить большое число задач без дополнительных вычислительных затрат, не считая затрат на использование задаче-специфичных линейных слоёв (всего $\sim$0.1\% дополнительных параметров для решения сразу пяти задач вместо одной).}
