\chapter*{Словарь терминов}             % Заголовок
%TOREMOVE SENTIMENT TOXICITY RETRIEVAL SKILL - РАНЖИРУЮЩИЙ CONVERSATION SKILL - РАЗГОВОРНЫЙ TF-IDF RETRIEVAL embedding skill selector response selector
dropout batch size learning rate loss function transfer learning
pretraining finetuning pre-training fine-tuning датасет
выборка или разбиение процедура обучения модели или же тренировки 
\addcontentsline{toc}{chapter}{Словарь терминов}  % Добавляем его в оглавление
\textbf{Open-source} : Находящийся в открытом доступе. 
\textbf{Бенчмарк} : Набор задач, используемый для оценки качества программного решения. 
\textbf{Предобучение} : Процесс предварительного обучения модели, который
применяется перед обучением модели на целевом наборе данных (или задаче). 
\textbf{Многоязычная модель} : Модель, предобучение которой производилось на достаточно большом количестве языков. 
\textbf{Дообучение} : Обучение модели на новом наборе данных (возможно, на другой задаче), после того, как она прошла процесс предобучения.
\textbf{Конкатенация} : Операция объединения двух векто
ров (последовательностей) в один, в результате которой элементы одного из векторов добавляются в конец другого. Происходит от английского слова concatenate. 
\textbf{Корреляция} : Статистическая взаимосвязь двух или более величин, которые можно с некой степенью точности считать случайной, такая, что изменениям одной(одних) из величин сопутствуют изменения другой(других) величин. 
\textbf{Тональность} : Эмоциональная окраска текста. Обычно выделяют позитивную, негативную или нейтральную.
\textbf{Токсичность} : Вид негативной характеристики текста, обычно означает наличие в тексте нецензурных выражений, оскорблений, непристойностей, личностной ненависти и пр.
\textbf{Токен} : Текстовая единица, представляющая из себя слово целиком или N-грамму символов.
\textbf{Токенизация} : Процесс разбиения текста на токены. Например, разбиение текста по пробелам и символам пунктуации. 
\textbf{Языковая модель} : Нейросетевая модель, обученная для решения задачи моделирования языка, то есть предсказания следующего слова/токена в тексте.
\textbf{Векторные представления слов/текстов} : Представление слов/текстов в виде векторов фиксированной длины с вещественными
значениями.  
\textbf{Векторизация слов/текстов} : Получение их векторных представлений. 
\textbf{Аннотаторы} : Модели для обработки естественного языка, которые получает на вход текст реплики(возможно, с состоянием диалога), и возвращают некие автоматическим образом полученные характеристики для этой реплики (т.е их аннотации). 
\textbf{Выборщик навыков} : Компонента диалоговой платформы, формирующая список навыков, которые будут вызваны для генерации реплик-кандидатов.
\textbf{Выборщик ответа} : Компонента диалоговой платформы, использующая состояние диалога, реплики-кандидаты и их аннотации для выбора финального ответа, возвращаемого пользователю.
\textbf{Многозадачное обучение} : Обучение модели для решения различных задач одновременно (без модификации архитектуры/весов под каждую конкретную задачу на этапе предсказания}. 
\textbf{Сэмплирование примеров} : Выбор примеров для показа при многозадачном обучения. Примеры могут выбираться из той или иной задачи с определенной вероятностью. Существуют и более сложные способы сэмплирования, но в рамках данной работы они не рассматривались. 
\textbf{Навык} : Элемент диалоговой платформы, который может выдавать вариант следующей реплики для выбора в рамках этой платформы. 
 \textbf{Разговорный навык} : Модель, производящая по
заданном контексту реплику-гипотезу, которая может являться продолжением диалога.
\textbf{Ранжирующий навык} : Модель, извлекающая реплику гипотезу по заданному контексту из заданного набора возможных реплик методом ранжирования.
\textbf{Ранжирующий навык TF-IDF} - Ранжирующий навык, использующий меток ранжирования, основанный на алгоритме TF-IDF~\cite{tfidf}. 
\textbf{Трансформер-агностичная модель} : Модель, куда можно подставить различные типы Трансформеров, не  изменяя при этом ее архитектуру. 
\textbf{Набор данных} : Данные для обучения и/или тестирования модели. Обычно делятся на тренировочную, валидационную и тестовую выборку. 
\textbf{Тренировочная выборка (разбиение)} : Данные, которые показываются модели при прохождении процедуры обучения модели. Для каждого из таких примеров модель обновляет свои параметры с целью приближения своих предсказаний к значениям этих примеров. 
\textbf{Валидационная выборка (разбиение)} : Данные, на которых проверяется качество модели после завершения каждой обучающей эпохи (т.е после того, как модель прошла процедуру обучения для определённого числа примеров, обычно соответствующего размеру тренировочной выборки). Исходя из качества на валидационной выборке, принимается решение о продолжении либо же прекращении обучения модели. 
\textbf{Тестовая выборка (разбиение)} : Данные, на которых проверяется качество модели после завершения ее обучения. 
\textbf{Перенос знаний} : Использование знаний, полученных во время обучения на одной задаче (и/или языке) для обучения модели на другой задаче (и/или языке). Это более общее понятие, чем дообучение и предобучение.
\textbf{Функция потерь} : Функция, оптимизация которой осуществляется на этапе обучения нейронной сети. Цель оптимизации - приближенте предсказаний модели к обучающей выборке. 
\textbf{Скорость обучения} : Гиперпараметр, определяющий масштаб корректировки весов нейронной сети на каждой тренировочной итерации с учётом функции потерь. 
\textbf{Размер батча} : Количество обучающих примеров за одну итерацию.
\textbf{Дропаут} : Метод регуляризации, позволяющий уменьшить переобучение модели за счет предупреждения коадаптаций нейронов на тренировочных данных в процессе обучения. В рамках данного метода на каждой обучающей итерации определенный случайно выбранный процент нейронов не задействуется (т.е их веса считаются нулевыми), что способствует лучшей работе оставшегося процента нейронов. 
\textbf{Интент} : Намерение, выражаемые одной из сторон диалога. 
 
