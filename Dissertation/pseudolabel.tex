\chapter{Использование псевдоразметки данных в многозадачных моделях для решения задач GLUE}\label{ch:pseudolabel}
% https://www.overleaf.com/7535984655svjbkdpsdgpc И ЦИТАТЫ И ВИД ТАБЛИЦ

Простейшим способом трансформер-инвариантной модели для решения большого количества задач является использование модели с одним “трансформером” в качестве тела(например, BERT-base-uncased) и одним линейным слоем на все задачи. Данный вид модели максимально экономичен по потребляемой памяти, как и по технической реализации. Тем не менее, при обучении его на нескольких датасетах возникает проблема, так как у каждого датасета есть метки только для классов “своей” задачи. У некоторых датасетов классы могут быть схожими, у других - кардинально различаться. В работе \cite{Karpov_Burtsev_2021} автором диссертации была подробно исследована данная проблема. Эксперименты, проделанные в данной работе, подробно описаны ниже.




\section{Описание экспериментов}\label{sec:ch3/sect1}
В каждом из экспериментов архитектура модели оставалась той же самой, изменялись лишь метки классов, подаваемые на вход модели. Модель тренировалась предсказывать вероятность от 0 до 1 для каждого класса, в multilabel режиме.
Модель оценивалась на следующих классификационных задачах - Multi-Genre Natural Language Inference(далее - MNLI), Quora Question Pairs(далее - QQP), Stanford Sentiment Treebank - 2(далее - SST-2) и Recognizing Textual Entailment(далее - RTE) из набора данных GLUE \cite{wang_2018}. Первые 3 задачи были выбраны, так как их наборы данных были достаточно велики ( более 50000 примеров для каждой из задач). Четвертая задача была выбрана, чтобы получить возможность исследовать объединение классов при псевдоразметке. Также для каждой из этих задач были воспроизведены результаты из вышеупомянутой статьи(заметим, что оригинальная модель не была multilabel). Примеры из всех задач были перемешаны и выбирались случайным образом. В связи с вычислительными ограничениями, все эксперименты проводились при модели-теле BERT-Base-Uncased \cite{devlin_2018}, аналогичной оригинальной статье, с ней же шло и сравнение всех остальных экспериментов.

\section{Условные обозначения}\label{subsec:ch3/sect2}
    Для формул ниже будут использоваться следующие условные обозначения:
    \begin{itemize}
    \item[*] $\color {black} +$ и $\color {black}-$ означают положительный(\textit{positive}) и отрицательный(\textit{negative}) классы в наборе данных SST-2 
    
    \item[*] $\color {black} d$ и $\color {black}!d$означают класс "дубликат" (\textit{duplicate}) и "не дубликат" \textit{not duplicate}  в наборе данных QQP;
    
    \item[*] $\color {black} e, c, n$: метки "логическое следствие"(\textit{entailment}), "логическое противоречие"(\textit{contradiction}) и "нейтральный"(\textit{neutral}) из набора данных MNLI; 
    
    \item[*] $\color {black}\varepsilon, !\varepsilon $: метки "логическое следствие"(\textit{entailment}) и "логическое противоречие"(\textit{not entailment}) из набора данных RTE;

    
    \item[*]  $\color{black}\mathit{MNLIpred}, \mathit{RTEpred}, \mathit{QQPpred}, \mathit{SSTpred}$ - предсказания модели, обученной на соответствующей задаче (MNLI, RTE, QQP, SST) для метки из нижнего индекса формулы. 
    
    \item[*]  $\color{black} I$ означает округление предсказанной оригинальной моделью вероятностного вектора: самый большой элемент считается равным 1, остальные зануляются.  
    
    \item[*] $\mathit{MNLIpred}^{!e}_{n}$,$\mathit{MNLIpred}^{!e}_{c}$ - вероятности, предсказанные для классов “нейтральный” и “логическое противоречие” модели MNLI при условии, что вероятность класса “логическое следствие” задается равной нулю. После этого вероятности этих классов вычисляются так, как если бы классов было не 3, а всего 2
    
        
    
    \item[*]  $\color{black} prob^{label}_{task}$ вектор с вероятностями от 0 до 1 ( 1 класс - 1 вероятность), которые нам необходимо присвоить примеру из набора данных $\color{black}{task}$,
    имеющему в этом наборе данных метку $\color{black}{label}$;
    
    \item[*]  $\color{black} P_{label}$ вероятность P метки $\color{black} label$, где P от 0 до 1.
    
    \end{itemize}    

    Это значит, что, например:
    \begin{itemize}
    
    \item[*] $\color{black} \mathit{MNLIpred}_e$ - вероятность метки \textit{entailment}, предсказанной моделью, обученной на MNLI;
    
    \item[*] $\color{black} I(\mathit{MNLIpred})_e$ равняется 1, если \textit{entailment} самый вероятный предсказанный класс для MNLI, и 0 в других случаях. 
     \end{itemize}
   
         \begin{equation}
    \color{black} \mathit{MNLIpred}^{!e}_{n} = \mathit{MNLIpred}^n/(\mathit{MNLIpred}^n + \mathit{MNLIpred}^c) \label{eq:ps0:0}
    \end{equation}
             \begin{equation}
    \color{black} \mathit{MNLIpred}^{!e}_{c} = \mathit{MNLIpred}^c/(\mathit{MNLIpred}^n + \mathit{MNLIpred}^c) \label{eq:ps0:1}
    \end{equation}

    Вероятностные вектора обозначаются квадратными скобками.

\section{Способы обучения многозадачной модели}\label{subsec:ch3/sect3}

Автором были рассмотрены разные способы обучения многозадачных моделей. Эти способы представлены ниже.

    \subsection{Независимые метки}\label{subsec:ch3/sect3/sub1}

В данном подходе, модель обучается на данных из всех задач - RTE, MNLI, QQP и SST-2. При этом массивы меток для каждой из задач независимы: для каждого примера вероятность всех классов, кроме изначально заданного в одном из этих датасетов, считается равной нулю.  Всего при данном подходе 9 классов - 3 для задачи MNLI и по 2 для каждой из остальных 3 задач.   
Вероятности, подаваемые на вход модели, для данного метода можно представить следующими формулами:

 \begin{equation}
		\color{black} prob^{\varepsilon}_{RTE}  = [1_{\varepsilon}, 0_{!\varepsilon},0_{e},0_{c},0_{n},0_{d}, 0_{!d},0_{+},0_{-}]  \label{eq:ps1:0}
\end{equation}
\begin{equation}
		\color{black} prob^{!\varepsilon}_{RTE} = [0_{\varepsilon}, 1_{!\varepsilon},0_{e},0_{c},0_{n},0_{d}, 0_{!d},0_{+},0_{-}] \label{eq:ps1:1}
\end{equation}
\begin{equation}
\color{black} prob^{e}_{MNLI} = [0_{\varepsilon}, 0_{!\varepsilon},1_{e},0_{c},0_{n},0_{d}, 0_{!d},0_{+},0_{-}] \label{eq:ps1:2}
\end{equation}
\begin{equation}
\color{black} prob^{c}_{MNLI} = [0_{\varepsilon}, 0_{!\varepsilon},0_{e},1_{c},0_{n},0_{d}, 0_{!d},0_{+},0_{-}] \label{eq:ps1:3}
\end{equation}
\begin{equation}
\color{black} prob^{n}_{MNLI} = [0_{\varepsilon}, 0_{!\varepsilon},0_{e},0_{c},1_{n},0_{d}, 0_{!d},0_{+},0_{-}] \label{eq:ps1:4}
\end{equation}
\begin{equation}
\color{black} prob^{d}_{QQP} = [0_{\varepsilon}, 0_{!\varepsilon},0_{e},0_{c},0_{n},1_{d}, 0_{!d},0_{+},0_{-}] \label{eq:ps1:5}
\end{equation}
\begin{equation}
\color{black} prob^{!d}_{QQP} = [0_{\varepsilon}, 0_{!\varepsilon},0_{e},0_{c},0_{n},0_{d}, 1_{!d},0_{+},0_{-}] \label{eq:ps1:6}
\end{equation}
\begin{equation}
\color{black} prob^{+}_{SST} = [0_{\varepsilon}, 0_{!\varepsilon},0_{e},0_{c},0_{n},0_{d}, 0_{!d},1_{+},0_{-}] \label{eq:ps1:7}
\end{equation}
\begin{equation}
\color{black} prob^{-}_{SST} = [0_{\varepsilon}, 0_{!\varepsilon},0_{e},0_{c},0_{n},0_{d}, 0_{!d},0_{+},1_{-}] \label{eq:ps1:8}
\end{equation}

\subsection{Мягкие независимые метки}\label{subsec:ch3/sect3/sub2}



Данный подход аналогичен подходу \textbf{Независимые метки} с одним отличием - для каждого примера, обнуляется не вероятность абсолютно всех классов кроме того, что изначально задан, а только вероятность других классов той же самой задачи. Вероятности других классов других задач считаются одинаковыми, с суммой вероятностей равной 1 для каждой из задач.
Вероятности, подаваемые на вход модели, для данного метода можно представить следующими формулами:
    
\begin{equation}
\color{black} prob^{\varepsilon}_{RTE}  = [1_{\varepsilon}, 0_{!\varepsilon},1/3_{e},1/3_{c},1/3_{n},1/2_{d}, 1/2_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:0}
\end{equation}
\begin{equation}
\color{black} prob^{!\varepsilon}_{RTE} = [0_{\varepsilon}, 1_{!\varepsilon},1/3_{e},1/3_{c},1/3_{n},1/2_{d}, 1/2_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:1}
\end{equation}
\begin{equation}
\color{black} prob^{e}_{MNLI} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},1_{e},0_{c},0_{n},1/2_{d}, 1/2_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:2}
\end{equation}
\begin{equation}
\color{black} prob^{c}_{MNLI} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},0_{e},1_{c},0_{n},1/2_{d}, 1/2_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:3}
\end{equation}
\begin{equation}
\color{black} prob^{n}_{MNLI} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},0_{e},0_{c},1_{n},1/2_{d}, 1/2_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:4}
\end{equation}
\begin{equation}
\color{black} prob^{d}_{QQP} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},1/3_{e},1/3_{c},1/3_{n},1_{d}, 0_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:5}
\end{equation}
\begin{equation}
\color{black} prob^{!d}_{QQP} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},1/3_{e},1/3_{c},1/3_{n},0_{d}, 1_{!d},1/2_{+},1/2_{-}]
\label{eq:ps2:6}
\end{equation}
\begin{equation}
\color{black} prob^{+}_{SST} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},1/3_{e},1/3_{c},1/3_{n},1/2_{d}, 1/2_{!d},1_{+},0_{-}]
\label{eq:ps2:7}
\end{equation}
\begin{equation}
\color{black} prob^{-}_{SST} = [1/2_{\varepsilon}, 1/2_{!\varepsilon},1/3_{e},1/3_{c},1/3_{n},1/2_{d}, 1/2_{!d},0_{+},1_{-}]
\label{eq:ps2:8}
\end{equation}

\subsection{Дополненные независимые метки}\label{subsec:ch3/sect3/sub3}

Данный подход аналогичен подходам \textbf{Независимые метки} и \textbf{Мягкие независимые метки}, кроме одного отличия. Для каждого примера, вероятности всех классов из “не своего” датасета не считаются одинаковыми, а определяются в соответствии с предсказаниями модели, обученной на этом “не своем” датасете в рамках воспроизведения оригинальной статьи.
Вероятности, подаваемые на вход модели, для данного метода можно описать следующими формулами:

\begin{align}
\color{black} prob^{\varepsilon}_{RTE}  = [1_{\varepsilon}, 0_{!\varepsilon},{\mathit{MNLIpred}}_{e},\mathit{MNLIpred}_{c},\mathit{MNLIpred}_{n},\mathit{QQPpred}_{d}, \nonumber\\
\color{black} \mathit{QQPpred}_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:0}
\end{align}
\begin{align}
\color{black} prob^{!\varepsilon}_{RTE} = [0_{\varepsilon}, 1_{!\varepsilon},{\mathit{MNLIpred}}_{e},\mathit{MNLIpred}_{c},\mathit{MNLIpred}_{n},\mathit{QQPpred}_{d},\nonumber\\ \color{black} \mathit{QQPpred}_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:1}
\end{align}
\begin{align}
\color{black} prob^{e}_{MNLI} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},1_{e},0_{c},0_{n},\mathit{QQPpred}_{d},\nonumber\\ \color{black} \mathit{QQPpred}_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:2}
\end{align}
\begin{align}
\color{black} prob^{c}_{MNLI} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},0_{e},1_{c},0_{n},\mathit{QQPpred}_{d},\nonumber\\ \color{black} \mathit{QQPpred}_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:3}
\end{align}
\begin{align}
\color{black} prob^{n}_{MNLI} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},0_{e},0_{c},1_{n},\mathit{QQPpred}_{d},\nonumber\\ \color{black} \mathit{QQPpred}_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:4}
\end{align}
\begin{align}
\color{black} prob^{d}_{QQP} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},\mathit{MNLIpred}_{e},\nonumber\\ \color{black} \mathit{MNLIpred}_{c},\mathit{MNLIpred}_{n},1_{d},0_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:5}
\end{align}
\begin{align}
\color{black} prob^{!d}_{QQP} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},\mathit{MNLIpred}_{e},\mathit{MNLIpred}_{c},\nonumber\\ \color{black} \mathit{MNLIpred}_{n},0_{d},1_{!d},\mathit{SSTpred}_{+},\mathit{SSTpred}_{-}]
\label{eq:ps3:6}
\end{align}
\begin{align}
\color{black} prob^{+}_{SST} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},\mathit{MNLIpred}_{e},\mathit{MNLIpred}_{c},\nonumber\\ \color{black} \mathit{MNLIpred}_{n},\mathit{QQPpred}_{d},\mathit{QQPpred}_{!d},1_{+},0_{-}]
\label{eq:ps3:7}
\end{align}
\begin{align}
\color{black} prob^{-}_{SST} = [\mathit{RTEpred}_{\varepsilon}, \mathit{RTEpred}_{!\varepsilon},\mathit{MNLIpred}_{e},\mathit{MNLIpred}_{c},\nonumber\\ \color{black} \mathit{MNLIpred}_{n},\mathit{QQPpred}_{d},\mathit{QQPpred}_{!d},0_{+},1_{-}]
\label{eq:ps3:8}
\end{align}

\subsection{Мягкое вероятностное предположение}\label{subsec:ch3/sect3/sub4}

В данном эксперименте, как и в экспериментах \textbf{Независимые метки}, \textbf{Мягкие независимые метки} и \textbf{Дополненные независимые метки}, модель была обучена на данных из всех четырех задач - RTE, MNLI, QQP и SST-2. Но при этом метки для этих задач считались зависимыми. А именно, количество классов для модели было сокращено до 5: положительный(positive), негативный(negative), логическое следствие(entailment), логическое противоречие(contradiction), нейтральный(neutral). Набор классов из этих датасетов был переведен в вероятности этих 5 классов в соответствие со следующими правилами:
\begin{itemize}
\item[*] Метки из всех датасетов, кроме SST, считаются на 50\% положительных и на 50\% отрицательными.
\item[*] Метки из датасета SST считаются имеющими классы “логическое следствие”, “логическое противоречие” и “нейтральный” с вероятностью $\frac{1}{3}$ каждый. Им назначаются вероятности классов “положительный” и “отрицательный” в соответствии с оригинальным набором данных.
\item[*] Меткам из датасета MNLI назначаются вероятности классов “логическое следствие”, “логическое противоречие” и “нейтральный” в соответствии с оригинальным набором данных.
\item[*] Меткам из датасеты QQP, если у них класс “дубликат”, назначается вероятность класса “логическое следствие” 1 и вероятности классов “логическое противоречие” и “нейтральный” 0. Иначе вероятность класса “логическое следствие” считается равной 0, а вероятности классов “логическое противоречие” и “нейтральный” считаются равными по 0.5.
\item[*] Меткам из датасета RTE, если у них класс “логическое следствие”, тоже назначается вероятность класса “логическое следствие” 1 и вероятности классов “логическое противоречие” и “нейтральный” 0. Иначе вероятность класса “логическое следствие” считается равной 0, а вероятности классов “логическое противоречие” и “нейтральный” считаются равными по 0.5.
\end{itemize}

Вероятности, подаваемые на вход модели, для данного метода можно представить следующими формулами:

\begin{equation}
\color{black} prob^{\varepsilon}_{RTE}  = [{1}_{e}, {0}_{c},{0}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:0}
\end{equation}
\begin{equation}
\color{black} prob^{!\varepsilon}_{RTE}  = [{0}_{e}, {1/2}_{c},{1/2}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:1}
\end{equation}
\begin{equation}
\color{black} prob^{e}_{MNLI}  = [{1}_{e}, {0}_{c},{0}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:2}
\end{equation}
\begin{equation}
\color{black} prob^{c}_{MNLI}  = [{0}_{e}, {1}_{c},{0}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:3}
\end{equation}
\begin{equation}
\color{black} prob^{n}_{MNLI}  = [{0}_{e}, {0}_{c},{1}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:4}
\end{equation}
\begin{equation}
\color{black} prob^{d}_{QQP}  = [{1}_{e}, {0}_{c},{0}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:5}
\end{equation}
\begin{equation}
\color{black} prob^{!d}_{QQP}  = [{0}_{e}, {1/2}_{c},{1/2}_{n},{1/2}_{+},{1/2}_{-}]
\label{eq:ps4:6}
\end{equation}
\begin{equation}
\color{black} prob^{SST}_{+} = [{1/3}_{e}, {1/3}_{c},{1/3}_{n},{1}_{+},{0}_{-}]
\label{eq:ps4:7}
\end{equation}
\begin{equation}
\color{black} prob^{SST}_{-} = [{1/3}_{e}, {1/3}_{c},{1/3}_{n},{0}_{+},{1}_{-}]
\label{eq:ps4:8}
\end{equation}

\subsection{Мягкие предсказанные метки}\label{subsec:ch3/sect3/sub5}

Данный подход аналогичен подходу \textbf{Мягкое вероятностное предположение} с одним отличием. Все недостающие вероятности для каждой из задач не считаются равновероятными, а определяются дополнительной разметкой от модели для каждой задачи, а именно:
\begin{itemize}
\item[*] Если пример не из датасета SST-2, вероятность положительного и отрицательного классов определяется по предсказаниям модели, обученной на датасете SST-2. Иначе, как и в предыдущем подходе, эти вероятности берутся из оригинального датасета.
\item[*] Меткам из датасета MNLI, как и в предыдущем подходе, назначаются вероятности классов “логическое следствие”, “логическое противоречие” и “нейтральный” в соответствии с оригинальным набором данных.
\item[*] Меткам из датасеты QQP, если у них класс “дубликат”, как и в предыдущем подходе, назначается вероятность класса “логическое следствие” 1 и вероятности классов “логическое противоречие” и “нейтральный” 0. Иначе вероятность класса “логическое следствие” считается равной 0, а вероятности классов “логическое противоречие” и “нейтральный” определяются по предсказаниям модели, обученной на наборе данных MNLI, нормализованных на сумму предсказанных вероятностей этих 2 классов.
\item[*] Меткам из датасета RTE, если у них класс “логическое следствие”, как и в предыдущем подходе, назначается вероятность класса “логическое следствие” 1 и вероятности классов “логическое противоречие” и “нейтральный” 0.  Иначе вероятность класса “логическое следствие” считается равной 0, а вероятности классов “логическое противоречие” и “нейтральный” определяются по предсказаниям модели, обученной на наборе данных MNLI, нормализованных на сумму предсказанных вероятностей этих 2 классов.
\end{itemize}


Вероятности, подаваемые на вход модели, для данного метода можно описать следующими формулами:



\begin{equation}
\color{black} prob^{\varepsilon}_{RTE}  = [{1}_{e}, {0}_{c},{0}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:0}
\end{equation}
\begin{equation}
\color{black} prob^{!\varepsilon}_{RTE}  = [{0}_{e}, \mathit{MNLIpred}^{!e}_{c},\mathit{MNLIpred}^{!e}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:1}
\end{equation}
\begin{equation}
\color{black} prob^{e}_{MNLI}  = [{1}_{e}, {0}_{c},{0}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:2}
\end{equation}
\begin{equation}
\color{black} prob^{c}_{MNLI}  = [{0}_{e}, {1}_{c},{0}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:3}
\end{equation}
\begin{equation}
\color{black} prob^{n}_{MNLI}  = [{0}_{e}, {0}_{c},{1}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:4}
\end{equation}
\begin{equation}
\color{black} prob^{d}_{QQP}  = [{1}_{e}, {0}_{c},{0}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:5}
\end{equation}
\begin{equation}
\color{black} prob^{!d}_{QQP}  = [{0}_{e}, \mathit{MNLIpred}^{!e}_{c},\mathit{MNLIpred}^{!e}_{n},{\mathit{SSTpred}}_{+},{\mathit{SSTpred}}_{-}]
\label{eq:ps5:6}
\end{equation}
\begin{equation}
\color{black} prob^{SST}_{+} = [\mathit{MNLIpred}_{e}, \mathit{MNLIpred}_{c},\mathit{MNLIpred}_{n},{1}_{+},{0}_{-}]
\label{eq:ps5:7}
\end{equation}
\begin{equation}
\color{black} prob^{SST}_{-} = [\mathit{MNLIpred}_{e}, \mathit{MNLIpred}_{c},\mathit{MNLIpred}_{n},{0}_{+},{1}_{-}]
\label{eq:ps5:8}
\end{equation}

\subsection{Жесткие предсказанные метки}\label{subsec:ch3/sect3/sub6}

Данный подход аналогичен подходу \textbf{Мягкие предсказанные метки} с одним изменением. Для меток, полученных из предсказаний оригинальной модели, максимальная вероятность для каждой задачи округляется до 1, а все остальные вероятности до 0.
Вероятности, подаваемые на вход модели, для данного метода можно описать следующими формулами:
\begin{equation}
\color{black} prob^{\varepsilon}_{RTE}  = [{1}_{e}, {0}_{c},{0}_{n},
\color{black}I({\mathit{SSTpred}}_{+}),{I(\mathit{SSTpred}}_{-})]
\label{eq:ps6:0}
\end{equation}
\begin{equation}
\color{black} prob^{!\varepsilon}_{RTE}  = [{0}_{e}, \mathit{MNLIpred}^{!e}_{c},\mathit{MNLIpred}^{!e}_{n},\nonumber\\\color{black}I({\mathit{SSTpred}}_{+}),{Id(\mathit{SSTpred}}_{-})]
\label{eq:ps6:1}
\end{equation}
\begin{equation}
\color{black} prob^{e}_{MNLI}  = [{1}_{e}, {0}_{c},{0}_{n},I({\mathit{SSTpred}}_{+}),{I\mathit{SSTpred}}_{-})]
\label{eq:ps6:2}
\end{equation}
\begin{equation}
\color{black} prob^{c}_{MNLI}  = [{0}_{e}, {1}_{c},{0}_{n},I({\mathit{SSTpred}}_{+}),{I(\mathit{SSTpred}}_{-})]
\label{eq:ps6:3}
\end{equation}
\begin{equation}
\color{black} prob^{n}_{MNLI}  = [{0}_{e}, {0}_{c},{1}_{n},I({\mathit{SSTpred}}_{+}),{I(\mathit{SSTpred}}_{-})]
\label{eq:ps6:4}
\end{equation}
\begin{equation}
\color{black} prob^{d}_{QQP}  = [{1}_{e}, {0}_{c},{0}_{n},I(\mathit{SSTpred}_{+}),I(\mathit{SSTpred}_{-})]
\label{eq:ps6:5}
\end{equation}
\begin{equation}
\color{black} prob^{!d}_{QQP}  = [{0}_{e}, I(\mathit{MNLIpred}^{!e}_{c}),I(\mathit{MNLIpred}^{!e}_{n}),\nonumber\\
\color{black} I(\mathit{SSTpred}_{+}),I(\mathit{SSTpred}_{-})]
\label{eq:ps6:6}
\end{equation}
\begin{equation}
\
\color{black} prob^{SST}_{+} = [I(\mathit{MNLIpred}_{e}), I(\mathit{MNLIpred}_{c}),\nonumber\\
\color{black} I(\mathit{MNLIpred}_{n}),{1}_{+},{0}_{-}]
\label{eq:ps6:7}
\end{equation}
\begin{equation}
\color{black} prob^{SST}_{-} = [I(\mathit{MNLIpred}_{e}), I\mathit{MNLIpred}_{c}),\nonumber\\
\color{black} I(\mathit{MNLIpred}_{n}),{0}_{+},{1}_{-}]
\label{eq:ps6:8}
\end{equation}


\subsection{Независимые метки, замороженная голова}\label{subsec:ch3/sect3/sub7}

Данный подход аналогичен подходу \textbf{Независимые метки}, с тем исключением, что линейный классификационный слой не обучается, а обучается только тело модели. Все формулы для данного подхода аналогичны формулам для подхода \textbf{Независимые метки}.

\subsection{Мягкие независимые метки, замороженная голова}\label{subsec:ch3/sect3/sub8}

Данный подход аналогичен подходу \textbf{Мягкие независимые метки}, с тем исключением, что линейный классификационный слой не обучается, а обучается только тело модели. Все формулы для данного подхода аналогичны формулам для подхода \textbf{Мягкие независимые метки}.
\section{Настройки и результаты экспериментов}\label{sec:ch3/sect4}

Для каждого из вышеописанных подходов, включая воспроизведение результатов оригинальной статьи, было сделано 4 попытки воспроизведения. Как и в оригинальной статье, эти 4 попытки отличались только скоростями обучения. По образцу этой статьи скорость обучения была 2e-5, 3e-5, 4e-5 и 5e-5 для первой, второй третьей и четвертой попытки соответственно. В качестве финальной была выбрана скорость обучения, для которой точность на валидационном сете была максимальной. Длительность обучения была ограничена 3 эпохами. Полные валидационные данные для всех экспериментов можно увидеть в оригинальной статье.
Результаты на валидационных и тестовых данных приведены в таблицах ~\ref{tab:ps1} и ~\ref{tab:ps2} соответственно. Стоит особо отметить, что данные результаты были достигнуты с числом параметров, на 10-13\% меньшим, чем в \cite{stickland_2019}, и без изменений в базовой архитектуре нейросетевой модели.

\begin{table}[htbp]
\centering
\caption {Лучшая точность на валидационных данных (при лучшей скорости обучения из выбираемых, среднее по 3 запускам)}
\label{tab:ps1}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c||c|c|c|c|c|}
\hline
Название эксперимента & Среднее& \({RTE}\)& \({QQP}\)&\({MNLI}\)&\({SST}\)\\
\hline
\hline
Базовый(воспроизведенный) & 81.3\% & 64.6\% & 90.8\% & 77.3\% & 92.7\%   \\
\hline
Независимые метки      & 82.8\%  & \textbf{78.3\%} & 90.6\% & 75.8\% & 92.0\%  \\
\hline
Мягкие независимые метки        & 82.2\% & 69.7\% & 89.5\% & 75.9\% & \textbf{92.6\%} \\
\hline
Дополненные независимые метки   & 81.4\% & 68.1\% & 90.5\% & 75.6\% & 92.4\% \\
\hline
Мягкое вероятностное предположение  & \textbf{84.2\%} & 78.2\% & \textbf{90.7\%} & 76.2\% & 91.9\%   \\
\hline
Мягкие предсказанные метки  & 83.2\% & 76.3\% & 90.5\% & 76.0\% & 92.2\%  \\
\hline
Жесткие предсказанные метки & 82.9\% & 77.4\% & 90.6\% & 75.3\% & 90.7\% \\
\hline
Независимые метки, замороженная голова  & 82.5\% & 76.1\% & 90.5\% & 75.7\% & 91.4\%  \\
\hline
Мягкие независимые метки, замороженная голова & 82.6\% & 74.4\% & 90.4\% & \textbf{76.7\%} & 91.2\%  \\ 
\hline
\end{tabular}
}
\end{table}

\begin{table}[htbp]
\centering
\caption {Лучшая точность на тестовых данных (при лучшей скорости обучения из выбираемых, среднее по 3 запускам)}
\label{tab:ps2}% label всегда желательно идти после caption
\resizebox{\textwidth}{!}
{%
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
Название эксперимента &Среднее& \({RTE}\)& \({QQP}\)&\({MNLI-m}\)&\({MNLI-mm}\)&\({SST}\)\\
\hline
Базовый(из оригинальной статьи)& 78.8\% & 66.4\%  & 71.2\% & 84.6\% & 83.4\% & 93.5\% \\
\hline
Базовый(воспроизведенный)& 77.6\% & 62.7\% & 71.0\% & 83.1\% & 82.7\% & 93.5\% \\
\hline
Независимые метки &79.0\% & 71.5\% & 70.9\% & 82.7\% & 81.7\% & 91.3\% \\
\hline
Мягкие независимые метки  &78.9\% & 69.3\% & 71.3\% & 82.8\% & 82.1\% & 92.6\% \\
\hline
Дополненные независимые метки &77.6\% & 64.2\%&\textbf{ 71.8\%} & 81.2\% & 80.7\% & \textbf{93.2\%} \\
\hline
Мягкое вероятностное предположение  &\textbf{79.7\%} & \textbf{72.7\%} & 70.7\% &\textbf{ 83.4\%} &\textbf{82.3\%} & 92.5\% \\
\hline
Мягкие предсказанные метки  & 78.8\% & 70.3\% & 70.7\% & 81.7\% & 81.7\% & 92.5\% \\
\hline
Жесткие предсказанные метки & 79.1\% & 71.3\% &71.1\% & 81.7\% & 81.4\% & 92.6\% \\
\hline
\begin{tabular}[c]{@{}l@{}}Независимые метки,\\замороженная голова\end{tabular}   & 78.2\% & 66.9\%& \textbf{71.8\%} & 82.6\% & 81.8\% & 91.9\% \\
\hline
\begin{tabular}[c]{@{}l@{}}Мягкие независимые метки,\\замороженная голова\end{tabular}  &79.1\% & 70.0\% & 71.5\% & 83.0\% &\textbf{ 82.3\%} & 92.4\% \\
\hline
\end{tabular}
}
\end{table}


\section{Выводы и анализ результатов}\label{sec:ch3/sect5}

Как можно видеть, разные способы дают результаты, похожие на результаты оригинальной модели BERT. Или даже более высокие результаты, если мы описываем задачу RTE. Причина данного преимущества для задачи RTE -  его схожесть с остальными задачами из GLUE, для которых данных гораздо больше, чем для RTE.

 Отсутствие роста показателей для QQP при объединении меток показывает, что объединение меток для этой задачи было слишком грубым. Это показывает ограничения для предложенных способов объединения меток.
 
На задачах, которые больше всего похожи друг на друга - RTE и MNLI - лучше всего показывает себя метод \textbf{Мягкое вероятностное предположение}. Это доказывает оправданность объединения меток при решении похожих задач. Этот метод превосходит результаты для RTE из оригинальной статьи и отстает от результатов для других задач только на 0.5-1.2\%.

На задачах, не похожих на остальные, таких, как SST и QQP, лучше всего показывает себя метод \textbf{Дополненные независимые метки}, что объясняется эффектом переноса знаний. Этот метод должен работать лучше всех вышеописанных методов в условиях, когда задачи достаточно сильно отличаются друг от друга. Именно этот подход применялся при работе над многозадачными моделями в диалоговой системе DREAM, которая будет описана в следующем разделе.

\clearpage
