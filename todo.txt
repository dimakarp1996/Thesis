ЗАМЕЧАНИЯ

АРТЕМ СОРОКИН

1. Работе не хватает консистентности и ясности в оформлении таблиц.  В части таблиц жирным выделены лучше полученные на задаче результаты (таб. 3, 5, 22, 23). Часть таблиц с результатами не использует выделения (таб. 4, 8, 19). Часть таблиц игнорирует лучшие результаты в определенных строках, но выделяет их в других (таб. 1, 2). В части таблиц не представляется возможным понять правило, по которому одни значения выделяются жирным, а другие - нет (таб. 26). В сопутствующем тексте и описании таблиц не упоминается использование жирного шрифта для выделения чего-либо.  
1. В большинстве экспериментов в данной работе (например, таблицы 1-8, графики на рисунках 3.1, 3.2) приводится только выборочное среднее по некоторому числу независимых запусков модели.  При этом для этих экспериментов не посчитаны доверительные интервалы или хотя бы значение стандартного отклонения для выборки. Это затрудняет возможность делать выводы о том, как сравниваемые методы действительно соотносятся друг с другом. 
2. Автор работы постоянно обращает внимание на то, что рассматриваемые им многозадачные модели требуют меньше вычислительных ресурсов по сравнению с использованием нескольких однозадачных моделей (стр. 6, 9, 47, 86). Проблема заключается в том, что эти утверждения являются слишком общими и вводят в заблуждение. Например, значительная часть многозадачных моделей, предложенных автором, использует при обучении результаты работы специализированных однозадачных моделей (см. разделы 2.3.5 и 2.3.6). Таким образом, обучение многозадачной модели обязательно потребует больших вычислительных ресурсов, так-как уже включает в себя обучение всех однозадачных моделей. Только ближе к концу диссертации становится понятно, что автор имеет в виду экономию вычислительных ресурсов на стадии применения модели, игнорируя затраты на стадии её обучения. 

ВАЛЕНТИН МАЛЫХ

В качестве недостатков можно отметить следующие:
Работа посвящена только исследованию переноса знаний в моделях, основанных на использовании кодировщиков, например, архитектуре BERT. В работе не проводилось исследование переноса знаний в моделях, использующих декодировщик либо комбинацию кодировщика и декодировщика, например, LLaMA или ChatGPT.
В главе 2 исследование проведено исключительно на англоязычном наборе задач GLUE, в то время как в последующих главах использовались наборы данных на двух языках, русском и английском. 
Также в диссертации был исследован только перенос знаний с английского языка на русский, но, например, не в обратном направлении.
По тексту диссертации используется большое количество калькированных терминов, самый характерный из них - “энкодер-агностичный”. 
