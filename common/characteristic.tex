{\actuality} 
Актуальность темы обоснована стремительным развитием нейросетевых моделей. В последнее время нейросетевые модели на основе трансформеров, типа BERT, стали чаще применяться в различных областях, в том числе в диалоговых системах. Это связано с тем, что они показывают более высокие результаты, чем иные методы машинного обучения. В то же самое время, такие модели требуют вычислительных ресурсов, которые могут быть дорогостоящими. В связи с этим развитие получает идея многозадачного обучения - использование одной и той же модели для решения нескольких задач машинного обучения. Однако перенос данных в многозадачных нейросетевых моделях между задачами и языками, особенно для задач, применимых в диалоговых системах, всё еще не изучены до конца. Наборов данных в открытом доступе для задач диалоговых систем, таких, как тематическая классификация, также недостаточно.


{\aim} данной работы является определение закономерностей, влияющих на перенос знаний между языками и задачами в многозадачных нейросетевых моделях на различных архитектурах, а также влияющих на особенности прикладного применения этих моделей в диалоговых платформах.

Для достижения поставленной цели необходимо было решить следующие {\tasks}:
%https://www.frccsc.ru/sites/default/files/docs/ds/002-073-05/diss/34-usov/ds05-34-usov_Avtoref.pdf?593

\begin{enumerate}
  \item {Создать и разместить в открытом доступе диалоговую платформу, а также проверить её пригодность для изучения прикладного применения многозадачных моделей.}
  %\item {Проверить применимость технологий, использованных в диалоговой платформе DREAM, в иных прикладных задачах.}
  \item {Выбрать на основании экспериментов оптимальную схему псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем.}
  \item {Выбрать на основании экспериментов оптимальную архитектуру многозадачных нейросетевых моделей, а также тип сэмплирования при обучении таких моделей.}
  \item {Выявить на основании экспериментов закономерности переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. Провести оценку зависимости этого переноса от размера обучающей выборки.}
  \item {Выявить на основании экспериментов закономерности переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. Повести оценку зависимости этого переноса от размера обучающей выборки. Рассмотреть применимость этих выводов для однозадачных моделей.}
  \item {Определить степень пригодности  открытого набора русскоязычных тематических данных для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний на разговорных данных.}
  \item {Проверить зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков к языку дообучения.}
  \item {Интегрировать рассмотренные в диссертации многозадачные нейросетевые архитектуры в диалоговую платформу, оценить применимость данных архитектур и провести их сравнительный анализ на основе опыта практического применения. На основании этого анализа произвести интеграцию также в библиотеку для решения задач машинного обучения, находящуюся в открытом доступе.}
  \newline
  \newline
\end{enumerate}


{\novelty}
\begin{enumerate}
  \item {Создана и выложена в открытый доступ диалоговая платформа DREAM, пригодная для изучения прикладного применения многозадачных нейросетевых моделей.}
  %\item {Проверена применимость технологий, использованных в диалоговой платформе DREAM, на прикладной задаче по созданию сервиса для работы с текстами texter-ocr-cv-microservice.}
  \item {На основании экспериментов выбраны оптимальные псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем на примере задач из набора данных GLUE.}
  \item {Проведены эксперименты для сравнения различных вариантов выбора архитектуры многозадачных трансформер-агностичных нейросетевых моделей, сравнения их с аналогичными однозадачными моделями для разных тел, а также выбора сэмплирования для определенных типов таких моделей.}
  \item {На основании экспериментов проведен анализ закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, была произведена оценка зависимости этого переноса от размера обучающей выборки.}
  \item {На основании экспериментов проведен анализ закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, была проведена оценка зависимости этого переноса от размера обучающей выборки. Была рассмотрена также применимость этих выводов для однозадачных моделей.}
  \item {Проверена степень пригодности русскоязычного открытого набора тематических данных {YAQTopics} для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
  \item {Проверена зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков к языку дообучения.}
  \item {Рассмотренные в диссертации многозадачные нейросетевые архитектуры были интегрированы в диалоговую платформу DREAM, была оценена их применимость и был проведен их сравнительный анализ на основе опыта применения. На основании этого анализа была произведена также интеграция в библиотеку DeepPavlov, находящуюся в открытом доступе.} 
\end{enumerate}

{\appropriation}
Пункты 3, 4, 5, 6, 7 и 8 Научной новизны соответствуют Пункту 8 «Комплексные исследования научных и технических проблем с применением современной технологии математического моделирования и
вычислительного эксперимента.» специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ», так как предложенный набор данных может использовать для валидации различных моделей машинного обучения. Пункты 1, 2 и 9 Научной новизны соответствует пункту 6 «Разработка систем компьютерного и имитационного моделирования, алгоритмов и методов имитационного моделирования на основе анализа математических моделей» специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ».

{\defpositions}
\begin{enumerate}
  \item {Созданная при существенном вкладе автора платформа DREAM, находящаяся в открытом доступе, пригодна для изучения прикладного применения многозадачных нейросетевых моделей.}
  %\item {На примере прикладной задачи по созданию сервиса для работы с текстами texter-ocr-cv-microservice показана применимость технологий, использованных в диалоговой платформе DREAM, за пределами этой диалоговой платформы.}
  \item {Псевдоразметка данных при помощи однозадачных моделей улучшает метрики многозадачных моделей. При этом объединение классов оправдывает себя только для задач, достаточно сильно похожих друг на друга.}
  \item {Многозадачные трансформер-агностичные нейросетевые модели показывают себя не хуже ряда других, более сложных архитектур, а предложенный метод сэмплирования - не хуже ряда других методов сэмплирования. При этом многозадачные трансформер-агностичные модели по данным проведенных экспериментов дают среднюю просадку не более 1 процента по сравнению с однозадачными моделями. При достаточной степени похожести задач друг на друга модели за счет таких задач в среднем даже превосходят однозадачные модели.}
  \item {Для достаточно малых данных многозадачные трансформер-агностичных модели начинают превосходить по своей средней точности однозадачные, в особенности - за счет задач с наименьшим объемом данных.}
  \item {Если в основе многозадачной трансформер-агностичной модели лежит многоязычный BERT, то добавление английских данных к русским при соответствующей номенклатуре классов позволяет улучшить метрики на 1-5\%. Чем меньше изначально русскоязычных данных, тем улучшение сильнее. Этот же вывод справедлив и для однозадачных моделей.}
  \item {Русскоязычные модели, обученные на 6 классах из русскоязычного набора тематических данных YAQTopics, показывают точность около 85\% на наборе данных MASSIVE. Это оправдывает использование набора данных YAQTopics для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
  \item {Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к языку дообучения.}
  \item {Рассмотренные многозадачные нейросетевые архитектуры пригодны для практического применения в диалоговых платформах и в рамках open-source библиотек. При этом предложенные автором трансформер-агностичные нейросетевые модели выигрывают у моделей типа PAL-BERT за счет трансформер-агностичности, а у моделей с одним линейным слоем - за счёт большей гибкости, отсутствия необходимости в псевдоразметке и как следствие - меньшей склонности к переобучению.}
\end{enumerate}


\iffalse
Направления исследований 1.2.2:
1. Разработка новых математических методов моделирования объектов и
явлений (физико-математические науки).
2. Разработка, обоснование и тестирование эффективных вычислительных
методов с применением современных компьютерных технологий.
3. Реализация эффективных численных методов и алгоритмов в виде
комплексов проблемно-ориентированных программ для проведения
вычислительного эксперимента.
4. Разработка новых математических методов и алгоритмов интерпретации
натурного эксперимента на основе его математической модели.
5. Разработка новых математических методов и алгоритмов валидации
математических моделей объектов на основе данных натурного эксперимента
или на основе анализа математических моделей.
6. Разработка систем компьютерного и имитационного моделирования,
алгоритмов и методов имитационного моделирования на основе анализа
математических моделей (технические науки).
7. Качественные или аналитические методы исследования математических
моделей (технические науки).
8. Комплексные исследования научных и технических проблем с
применением современной технологии математического моделирования и
вычислительного эксперимента.
9. Постановка и проведение численных экспериментов, статистический
анализ их результатов, в том числе с применением современных
компьютерных технологий (технические науки).
\fi


{\influence}
%Практическая значимость заключается в следующем:
\begin{enumerate}
    \item Впервые в России была создана диалоговая платформа мирового уровня, вышедшая в полуфинал престижных мировых конкурсов Alexa Prize 3 и Alexa Prize 4 (в конкурсах было 10 и 9 участников соответственно, из более чем 300 кандидатов). Эта диалоговая платформа имеет полностью открытый код, что дает возможность легкого переиспользования любой части проделанной над ней работы. Были также разработаны сценарные навыки ля этой платформы.
    \item В данной диалоговой платформе были применены многозадачные нейросетевые модели: многозадачная нейросетевая модель с одним линейным слоем, многозадачная нейросетевая модель на основе архитектуры PAL-BERT и многозадачная трансформер-агностичная нейросетевая модель. 
    \item Программный код для реализации многозадачной трансформер-агностичной нейросетевой модели встроен в библиотеку DeepPavlov, имеющую более 500000 скачиваний на март 2023 года.
    \item По результатам этой работы оформлено также свидетельство о депонировании~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}. % Как написать подробнее
\end{enumerate}

{\methods}
Были
применены: % В данной работе были примененыЖ
\begin{enumerate}
\item[*] Метод численного эксперимента для исследования задач обработки естественного языка;
\item[*] Теория вероятностей и математическая статистика;
\item[*] Методы машинного обучения и теории глубокого обучения;
\item[*] Методы разработки на языках Python, Bash.
\end{enumerate}




{\reliability} полученных результатов обеспечивается экспериментами на наборах диалоговых данных и наборе данных GLUE, описанными в~\cite{pseudolabel,rumtl,enmtl,rutopics,dp_2023}, применением в различных соревнованиях по созданию диалоговых систем, описанным в ~\cite{dream1,dream2,dream1_trudy,Болотин_Карпов_Рашков_Шкурак_2019} и использованием результатов работы в диалоговой платформе DREAM и библиотеке DeepPavlov. Результаты находятся в соответствии с результатами, полученными другими авторами.

{\probation}
\begin{itemize}
    \item[*] En\&T 2018, доклад «Разработка диалоговой системы с интеграцией профиля личности», Даниил Болотин, Дмитрий Карпов, Григорий Рашков, Иван Шкурак, 15-16 ноября 2018 года, Москва;
    \item[*] Диалог-2021, доклад «Data pseudo-labeling while adapting BERT for multitask approaches», Dmitry Karpov, Mikhail Burtsev, 16-19 июня 2021 года, Москва;
    \item[*] AINL-2023, доклад «YAQTopics: Russian Conversational Topic Dataset», Dmitry Karpov, Mikhail Burtsev, Alexander Popov, 20-22 апреля 2023 года, Ереван, Армения;
\end{itemize}%, Computational Linguistics and Information Technologies~\cite{pseudolabel,rumtl},Proceedings of Alexa Prize 3~\cite{dream1},Proceedings of Alexa Prize 4~\cite{dream2}, Труды МФТИ~\cite{dream1_trudy},  Proceedings of InterSpeech 2023~\cite{enmtl}, Proceedings of ACL Systems Workshop~\cite{dp_topics}. Помимо этого, разработки, описанные в данной диссертации, были внедрены в находящуюся в открытом доступе диалоговую платформу DREAM, активно используемую в конкурсах Alexa Prize 3, Alexa Prize 4 и после них. Также на разработки, основанные на результатах работы, было получено свидетельство о регистрации ПО~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}.


{\contribution} В работе~\cite{Болотин_Карпов_Рашков_Шкурак_2019} автор отвечал за ряд важных компонент диалоговой системы, включающих в себя алгоритм для перефразировки реплик. Исследование, разработка и сравнительный анализ методов псевдоразметки данных, описанных в работе~\cite{pseudolabel}, были выполнены автором самостоятельно. В работах~\cite{dream1,dream1_trudy,dream2} автор отвечал за ряд важных компонент диалоговой системы - навыки обсуждения книг, эмоций, коронавируса, слухов, навык для обоснования диалога, классификаторы эмоций,интентов,момента остановки диалога,навык для выбора наиболее подходящего ответа с использованием алгоритма TF-IDF, генеративный навык и многозадачную нейросетевую модель. Технические решения для работы с естественным языком, использованные в \cite{dream1,dream1_trudy,dream2}, использовались также в~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}. В работах~\cite{rumtl,enmtl,rutopics} все исследования также были выполнены автором самостоятельно. В работе~\cite{dp_2023} автор отвечал за эксперименты с многозадачными трансформер-агностичными моделями для библиотеки DeepPavlov и их описание.

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} 

}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}%
        %
        {\publications} Основные результаты по теме диссертации изложены в~{9}~печатных изданиях,{1} из которых издано в журналах, рекомендованных ВАК, {2} в~периодических научных журналах, индексируемых Web of~Science и Scopus, {3} в~тезисах докладов.\footnote{Цифры будут уточнены после принятия всех статей.}

        \iffalse % This is a default template. And I do by hands
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi
        \fi
    \end{refsection}%
    \begin{refsection}[bl-author]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        \nocite{Болотин_Карпов_Рашков_Шкурак_2019}%vak
        \nocite{dream1}%vak
        \nocite{dream2}%vak
        \nocite{pseudolabel}
        \nocite{dream1_trudy}%vak
        \nocite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}%vak
        \nocite{rumtl}
        \nocite{rutopics}
        \nocite{enmtl}
        \nocite{dp_2023}
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
        %
        % Невидимый библиографический список для подсчёта количества внешних публикаций
        % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
        % цитирований внешних источников.
        % Замедляет компиляцию
    \ifsynopsis
    \ifnumequal{\value{draft}}{0}{
      \printbibliography[heading=nobibheading, section=0, env=countexternal,          keyword=biblioexternal]%
    }{}
    \fi
}
\iffalse
При использовании пакета \verb!biblatex! будут подсчитаны все работы, добавленные
в файл \verb!biblio/author.bib!. Для правильного подсчёта работ в~различных
системах цитирования требуется использовать поля:
\begin{itemize}
        \item {authorvak} если публикация индексирована ВАК,
        \item {authorscopus} если публикация индексирована Scopus,
        \item {authorwos} если публикация индексирована Web of Science,
        \item {authorconf} для докладов конференций,
        \item {authorother} для других публикаций.
\end{itemize}
Для подсчёта используются счётчики:
\begin{itemize}
        \item {citeauthorvak} для работ, индексируемых ВАК,
        \item {citeauthorscopus} для работ, индексируемых Scopus,
        \item {citeauthorwos} для работ, индексируемых Web of Science,
        \item {citeauthorvakscopuswos} для работ, индексируемых одной из трёх баз,
        \item {citeauthorscopuswos} для работ, индексируемых Scopus или Web of~Science,
        \item {citeauthorconf} для докладов на конференциях,
        \item {citeauthorother} для остальных работ,
        \item {citeauthor} для суммарного количества работ.
\end{itemize}
% Счётчик {citeexternal} используется для подсчёта процитированных публикаций.

Для добавления в список публикаций автора работ, которые не были процитированы в
автореферате требуется их~перечислить с использованием команды \verb!\nocite! в
\verb!Synopsis/content.tex!.
\fi
