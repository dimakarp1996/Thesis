
{\actuality} 
Актуальность темы обоснована стремительным развитием нейросетевых моделей. В последнее время нейросетевые модели на основе трансформеров, типа BERT, стали чаще применяться в различных областях, в том числе в диалоговых системах. Это связано с тем, что они показывают более высокие результаты, чем иные методы машинного обучения. В то же самое время, такие модели требуют вычислительных ресурсов, которые могут быть дорогостоящими. В связи с этим развитие получает идея многозадачного обучения - использование одной и той же модели для решения нескольких задач машинного обучения. Тем не менее, перенос данных в многозадачных нейросетевых моделях между задачами и языками, особенно для задач, применимых в диалоговых системах, всё еще не изучены до конца. Наборов данных в открытом доступе для задач диалоговых систем, таких, как тематическая классификация, также недостаточно.


{\aim} данной работы является определение закономерностей, влияющих на перенос знаний между языками и задачами в многозадачных нейросетевых моделях на различных архитектурах, а также на особенности прикладного применения этих моделей в диалоговой платформе.

Для достижения поставленной цели необходимо было решить следующие {\tasks}:

\begin{enumerate}
  \item {Создать и выложить в открытый доступ диалоговую платформу, на которой в дальнейшем могло бы изучаться прикладное применение многозадачных нейросетевых моделей. Проверить качество этой диалоговой платформы оценками пользователей.}
  \item {Проверить применимость технологий, использованных в диалоговой платформе DREAM, в иных прикладных задачах.}
  \item {Провести эксперименты для сравнения различных схем псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем.}
  \item {Провести эксперименты для сравнения различных вариантов выбора архитектуры многозадачных нейросетевых моделей, а также выбора сэмплирования для определенных типов таких моделей.}
  \item {Провести эксперименты для анализа закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, провести оценку зависимости этого переноса от размера обучающей выборки.}
  \item {Провести эксперименты для анализа закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, провести оценку зависимости этого переноса от размера обучающей выборки. Рассмотреть также применимость этих выводов для однозадачных моделей.}
  \item {Проверить пригодность русскоязычного открытого набора тематических данных для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний на разговорных данных.}
  \item {Проверить зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.}
  \item {Интегрировать рассмотренные в диссертации многозадачные нейросетевые архитектуры в диалоговую платформу, оценить применимость данных архитектур и провести их сравнительный анализ на основе опыта практического применения. На основании этого анализа произвести интеграцию также в open-source библиотеку.}
  \newline
  \newline
\end{enumerate}


{\novelty}
\begin{enumerate}
  \item {Создана и выложена в открытый доступ диалоговая платформа DREAM, на которй в дальнейшем может изучаться прикладное применение многозадачных нейросетевых моделей. Качество этой диалоговой платформы было проверено оценками пользователей в рамках конкурса "Alexa Prize Socialbot Grand Challenge", по результатам которых платформа DREAM вышла в полуфинал этого конкурса.}
  \item {Проверена применимость технологий, использованных в диалоговой платформе DREAM, на прикладной задаче по созданию сервиса для работы с текстами texter-ocr-cv-microservice.}
  \item {Проведены эксперименты для сравнения различных схем псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем на примере задач из набора данных GLUE.}
  \item {Проведены эксперименты для сравнения различных вариантов выбора архитектуры многозадачных трансформер-агностичных нейросетевых моделей, сравнения их с аналогичными однозадачными моделями для разных тел, а также выбора сэмплирования для определенных типов таких моделей.}
  \item {Проведены эксперименты для анализа закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, была произведена оценка зависимости этого переноса от размера обучающей выборки.}
  \item {Проведены эксперименты для анализа закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, была проведена оценка зависимости этого переноса от размера обучающей выборки. Была рассмотрена также применимость этих выводов для однозадачных моделей.}
  \item {Проверена пригодность хотя бы 1 русскоязычного открытого набора тематических данных \texttt{YAQTopics} для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
  \item {Проверена зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.}
  \item {Рассмотренные в диссертации многозадачные нейросетевые архитектуры были интегрированы в диалоговую платформу DREAM, была оценена применимость и был проведен их сравнительный анализ на основе опыта применения. На основании этого анализа была произведена также интеграция в open-source библиотеку DeepPavlov} 
\end{enumerate}

{\appropriation}
Пункты 3,4, 5, 6, 7 и 8 Научной новизны соответствуют Пункту 8 "Комплексные исследования научных и технических проблем с применением современной технологии математического моделирования и
вычислительного эксперимента." специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ», так как предложенный набор данных может использовать для валидации различных моделей машинного обучения. Пункты 1,2 и 9 Научной новизны соответствует пункту 6 "Разработка систем компьютерного и имитационного моделирования, алгоритмов и методов имитационного моделирования на основе анализа математических моделей" специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ».

{\defpositions}
\begin{enumerate}
  \item {Диалоговая платформа \texttt{DREAM} пригодна для изучения прикладного применения многозадачных нейросетевых моделей. Оценки пользователей в рамках международного конкурса "Alexa Prize Socialbot Grand Challenge", обеспечившие двукратный выход в полуфинал этой платформы, показывают высокое качество диалоговой платформы на момент её создания.}
  \item {На примере прикладной задачи по созданию сервиса для работы с текстами texter-ocr-cv-microservice показана применимость технологий, использованных в диалоговой платформе DREAM, за пределами этой диалоговой платформы.}
  \item {Псевдоразметка данных при помощи однозадачных моделей улучшает метрики многозадачных моделей. При этом объединение классов оправдывает себя только для задач, достаточно сильно похожих друг на друга.}
  \item {Было показано на различных наборах данных, что многозадачные трансформер-агностичные нейросетевые модели показывают себя не хуже ряда других, более сложных архитектур, а предложенный метод сэмплирования - не хуже ряда других методов сэмплирования. При этом многозадачные трансформер-агностичные модели по данным проведенным экспериментах дают среднюю просадку не более 1 процента по сравнению с однозадачными моделями. А если какие-то задачи достаточно похожи друг на друга, как например, в бенчмарке GLUE, многозадачные модели за счет таких задач в среднем даже превосходят однозадачные модели.}
  \item {Было показано, что для достаточно малых данных многозадачные трансформер-агностичных модели начинают превосходить по своей средней точности однозадачные, в особенности - за счет задач с наименьшим объемом данных.}
  \item {Было показано, что если в основе многозадачной трансформер-агностичной модели лежит многоязычный BERT, то добавление английских данных к русским при соответствующей номенклатуре классов позволяет улучшить метрики на 1-5\%. Чем меньше изначально русскоязычных данных, тем улучшение сильнее. Этот же вывод справедлив и для однозадачных моделей.}
  \item {Русскоязычный открытый набор тематических данных \texttt{YAQTopics} пригоден для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
  \item {Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к русскому.}
  \item {Рассмотренные многозадачные нейросетевые архитектуры пригодны для практического применения в диалоговых платформах и в рамках open-source библиотек. При этом предложенные автором трансформер-агностичные нейросетевые модели выигрывают у моделей типа PAL-BERT за счет трансформер-агностичности, а у моделей с одним линейным слоем - за счёт большей гибкости, отсутствия необходимости в псевдоразметке и как следствие - меньшей склонности к переобучению.}
\end{enumerate}


\iffalse
Направления исследований 1.2.2:
1. Разработка новых математических методов моделирования объектов и
явлений (физико-математические науки).
2. Разработка, обоснование и тестирование эффективных вычислительных
методов с применением современных компьютерных технологий.
3. Реализация эффективных численных методов и алгоритмов в виде
комплексов проблемно-ориентированных программ для проведения
вычислительного эксперимента.
4. Разработка новых математических методов и алгоритмов интерпретации
натурного эксперимента на основе его математической модели.
5. Разработка новых математических методов и алгоритмов валидации
математических моделей объектов на основе данных натурного эксперимента
или на основе анализа математических моделей.
6. Разработка систем компьютерного и имитационного моделирования,
алгоритмов и методов имитационного моделирования на основе анализа
математических моделей (технические науки).
7. Качественные или аналитические методы исследования математических
моделей (технические науки).
8. Комплексные исследования научных и технических проблем с
применением современной технологии математического моделирования и
вычислительного эксперимента.
9. Постановка и проведение численных экспериментов, статистический
анализ их результатов, в том числе с применением современных
компьютерных технологий (технические науки).
\fi


{\influence}
Практическая значимость заключается в следующем. Впервые в России была разработана диалоговая платформа мирового уровня, вышедшая в полуфинал престижных мировых конкурсов Alexa Prize 3 и Alexa Prize 4 (в конкурсах было 10 и 9 участников соответственно, из более чем 300 кандидатов). Эта диалоговая платформы имеет полностью открытый код, что дает возможность легкого переиспользования любой части проделанной над ней работы. 

В этой платформе, в числе всего прочего, применялись многозадачные нейросетевые модели, описанные автором в данном работе - многозадачная нейросетевая модель с одним линейным слоем, многозадачная нейросетевая модель на основе архитектуры PAL-BERT и многозадачная трансформер-агностичная нейросетевая модель. Был проведен ряд других прикладных работ для улучшения данной платформы, включающий в себя разработку сценарных навыков.

Помимо этого, программный код для реализации многозадачной трансформер-агностичной нейросетевой модели встроен в библиотеку DeepPavlov, имеющую более 500 000 скачиваний на март 2023 года.
Алгоритмы, использованные в данной работе, применены также в программе для ЭВМ [А6], на которую получено свидетельство о государственной регистрации.


{\methods}
В данной работе были
применены:
\begin{enumerate}
\item Метод численного эксперимента для исследования задач обработки естественного языка;
\item Основы теории вероятностей;
\item Методы машинного обучения и теории глубокого обучения;
\item Методы разработки на языках Python, Bash.
\end{enumerate}




{\reliability} полученных результатов обеспечивается экспериментами на наборах диалоговых данных и наборе данных GLUE, описанными в~\cite{pseudolabel}(индексируется в Scopus), ~\cite{Болотин_Карпов_Рашков_Шкурак_2019}, ~\cite{rumtl},~\cite{enmtl},~\cite{rutopics},~\cite{dp_2023}, применением в соревнованиях "Alexa Prize Challenge 3" и "Alexa Prize Challenge 4", описанным в ~\cite{dream1}, ~\cite{dream2}, ~\cite{dream1_trudy}(входит в список ВАК), а также использованием результатов работы в диалоговой платформе \texttt{DREAM} и библиотеке DeepPavlov. Результаты находятся в соответствии с результатами, полученными другими авторами.


{\probation}
Апробация работы. Результаты работы были представлены автором на конференции Диалог-2021~\cite{pseudolabel}, и опубликованы в журналах Proceedings of En\&T 2018~\cite{Болотин_Карпов_Рашков_Шкурак_2019}, Computational Linguistics and Information Technologies~\cite{pseudolabel,rumtl},Proceedings of Alexa Prize 3~\cite{dream1},Proceedings of Alexa Prize 4~\cite{dream2}, Труды МФТИ~\cite{dream1_trudy}, Proceedings of AINL 2023~\cite{rutopics}, Proceedings of InterSpeech 2023~\cite{enmtl}, Proceedings of ACL Systems Workshop~\cite{dp_topics}. Помимо этого, разработки, описанные в данной диссертации, были внедрены в находящуюся в открытом доступе диалоговую платформу \texttt{DREAM}, активно используемую в конкурсах Alexa Prize 3, Alexa Prize 4 и после них. Также на разработки, основанные на результатах работы, было получено свидетельство о регистрации ПО~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}.


{\contribution} В работе~\cite{Болотин_Карпов_Рашков_Шкурак_2019} автор отвечал за ряд важных компонент диалоговой системы, включающих в себя парафразер. Исследование, разработка и сравнительный анализ методов псевдоразметки данных, описанных в работе~\cite{pseudolabel}, были выполнены автором самостоятельно. В работах~\cite{dream1,dream1_trudy,dream2} автор отвечал за ряд важных компонент диалоговой системы - навыки обсуждения книг, эмоций, коронавируса, классификаторы эмоций,интентов,момента остановки диалога, TF-IDF Retrieval, Grounding Skill, Gossip Skill, генеративный навык и многозадачную нейросетевую модель. Технические решения для работы с естественным языком, использованные в \cite{dream1,dream1_trudy,dream2}, использовались также в~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}. В работах~\cite{rumtl,enmtl,rutopics} все исследования также были выполнены автором самостоятельно. В работе~\cite{dp_2023} автор отвечал за эксперименты с многозадачными трансформер-агностичными моделями для библиотеки DeepPavlov и их описание.

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} 

}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}%
        %
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi
    \end{refsection}%
    \begin{refsection}[bl-author]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        \nocite{Болотин_Карпов_Рашков_Шкурак_2019}%vak
        \nocite{dream1}%vak
        \nocite{dream2}%vak
        \nocite{pseudolabel}
        \nocite{dream1_trudy}%vak
        \nocite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}%vak
        \nocite{rumtl}
        \nocite{rutopics}
        \nocite{enmtl}
        \nocite{dp_2023}
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
        %
        % Невидимый библиографический список для подсчёта количества внешних публикаций
        % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
        % цитирований внешних источников.
        % Замедляет компиляцию
    \ifsynopsis
    \ifnumequal{\value{draft}}{0}{
      \printbibliography[heading=nobibheading, section=0, env=countexternal,          keyword=biblioexternal]%
    }{}
    \fi
}
\iffalse
При использовании пакета \verb!biblatex! будут подсчитаны все работы, добавленные
в файл \verb!biblio/author.bib!. Для правильного подсчёта работ в~различных
системах цитирования требуется использовать поля:
\begin{itemize}
        \item \texttt{authorvak} если публикация индексирована ВАК,
        \item \texttt{authorscopus} если публикация индексирована Scopus,
        \item \texttt{authorwos} если публикация индексирована Web of Science,
        \item \texttt{authorconf} для докладов конференций,
        \item \texttt{authorother} для других публикаций.
\end{itemize}
Для подсчёта используются счётчики:
\begin{itemize}
        \item \texttt{citeauthorvak} для работ, индексируемых ВАК,
        \item \texttt{citeauthorscopus} для работ, индексируемых Scopus,
        \item \texttt{citeauthorwos} для работ, индексируемых Web of Science,
        \item \texttt{citeauthorvakscopuswos} для работ, индексируемых одной из трёх баз,
        \item \texttt{citeauthorscopuswos} для работ, индексируемых Scopus или Web of~Science,
        \item \texttt{citeauthorconf} для докладов на конференциях,
        \item \texttt{citeauthorother} для остальных работ,
        \item \texttt{citeauthor} для суммарного количества работ.
\end{itemize}
% Счётчик \texttt{citeexternal} используется для подсчёта процитированных публикаций.

Для добавления в список публикаций автора работ, которые не были процитированы в
автореферате требуется их~перечислить с использованием команды \verb!\nocite! в
\verb!Synopsis/content.tex!.
\fi
