{\actuality} 
Актуальность темы обоснована стремительным развитием нейросетевых моделей, в частности, для обработки естественного текста.
В настоящее время нейросетевые модели на основе трансформеров, типа BERT, стали чаще применяться в различных областях, в том числе в диалоговых системах. Это связано с тем, что они показывают более высокие результаты, чем иные методы машинного обучения. 

В то же самое время, такие модели требуют вычислительных ресурсов, которые могут быть дорогостоящими. В зависимости от бюджета, может возникнуть потребность в экономии на вычислительных ресурсах без снижения качества работы моделей.

В связи с этим получает развитие идея многозадачного обучения - использование одной и той же модели для решения нескольких задач машинного обучения. Такие модели могут показывать результаты не хуже, чем однозадачные, тратя при этом меньше вычислительных ресурсов. В некоторых случаях эти модели могут показывать лучшие результаты, чем однозадачные модели, за счет переноса знаний.

Перенос знаний позволяет передавать знания между областями, задачами и языками. Перенос знаний можно часто встретить в реальном мире - к примеру, умение играть в шахматы помогает при освоении шашек. Однако особенности переноса знаний в многозадачных моделях между различными задачами изучены не до конца. Не полностью изучен и межъязыковой перенос знаний в многозадачных и однозадачных моделях. Исследование эффектов, связанных с переносом знаний, безусловно, является актуальным.

Также для изучения особенностей применения многозадачных моделей и переноса знаний в них существует потребность в технических решениях, которые находились бы в открытом доступе. Данная диссертационная работа призвана решить эти проблемы.


{\aim} данной работы является определение закономерностей, влияющих на перенос знаний между языками и задачами в многозадачных нейросетевых моделях на различных архитектурах и на особенности прикладного применения этих моделей в диалоговых платформах.

Для достижения поставленной цели необходимо решить следующие {\tasks}: % было
%https://www.frccsc.ru/sites/default/files/docs/ds/002-073-05/diss/34-usov/ds05-34-usov_Avtoref.pdf?593

\begin{enumerate}
  \item {Создать и разместить в открытом доступе диалоговую платформу, а также проверить её пригодность для изучения прикладного применения многозадачных моделей.} % TODO СПРОСИТЬ У ВАСИ
  \item {Предложить оптимальную схему псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем.}
  \item {Определить закономерности переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. Провести оценку зависимости этого переноса от размера обучающей выборки.}
  \item {Определить закономерности переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. Провести оценку зависимости этого переноса от размера обучающей выборки. Рассмотреть применимость этих выводов для однозадачных моделей.}
  \item {Проверить зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков к языку дообучения.}
  \item {Интегрировать рассмотренные в диссертации многозадачные нейросетевые архитектуры в диалоговую платформу, оценить применимость данных архитектур и провести их сравнительный анализ на основе опыта практического применения. На основании этого анализа произвести интеграцию данных архитектур также в open-source библиотеку для решения задач машинного обучения.}% todo программную библиотеку
  \newline
  \newline
\end{enumerate}


{\novelty}
\begin{enumerate}
  \item {Создана и выложена в открытый доступ диалоговая платформа DREAM, пригодная для изучения прикладного применения многозадачных нейросетевых моделей.}
  \item {Выбраны оптимальные схемы псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем на примере задач из набора данных GLUE.}
  \item {Выявлены закономерности переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами и языками. Была получена оценка зависимости этого переноса от размера обучающей выборки. Была проверена также справедливость выводов о межъязыковом переносе для однозадачных моделей.}
  \item {Получена оценка зависимости межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков к языку дообучения.}
  \item {Рассмотренные в диссертации многозадачные нейросетевые архитектуры были интегрированы в диалоговую платформу DREAM, была оценена их применимость и был проведен их сравнительный анализ на основе опыта применения. На основании этого анализа была произведена также интеграция в open-source библиотеку DeepPavlov.} 
\end{enumerate}

{\appropriation}
Пункты 2, 3, 4, 5, 6 и 7 Научной новизны соответствуют Пункту 8 «Комплексные исследования научных и технических проблем с применением современной технологии математического моделирования и вычислительного эксперимента.» специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ», так как предложенный набор данных может использовать для валидации различных моделей машинного обучения. Пункты 1 и 8 Научной новизны соответствует пункту 6 «Разработка систем компьютерного и имитационного моделирования, алгоритмов и методов имитационного моделирования на основе анализа математических моделей» специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». % TODO НУМЕРАЦИЯ ПУНКТОВ

{\defpositions}
\begin{enumerate}
  \item {Созданная при существенном вкладе автора платформа DREAM, находящаяся в открытом доступе, пригодна для изучения прикладного применения многозадачных нейросетевых моделей.}
  \item {Псевдоразметка данных при помощи однозадачных моделей улучшает метрики многозадачных моделей. При этом объединение классов оправдывает себя только для задач, достаточно сильно похожих друг на друга.}
  \item {Для достаточно малых данных многозадачные трансформер-агностичные модели начинают превосходить по своей средней точности однозадачные, в особенности - за счет задач с наименьшим объемом данных. При этом для таких многоязычных моделей наблюдается также перенос знаний с английского языка на русский в рамках одной задачи, и чем меньше русскоязычных данных, тем сильнее выражен перенос. Эта закономерность справедлива и для однозадачных моделей.}
  \item {Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к языку дообучения.}
  \item {Рассмотренные многозадачные нейросетевые архитектуры пригодны для практического применения в диалоговых платформах и в рамках open-source библиотек. При этом предложенные автором трансформер-агностичные нейросетевые модели выигрывают у модульных архитектур за счет трансформер-агностичности, а у моделей с одним линейным слоем - за счёт большей гибкости, отсутствия необходимости в псевдоразметке и как следствие - меньшей склонности к переобучению.}
\end{enumerate}


\iffalse
Направления исследований 1.2.2:
1. Разработка новых математических методов моделирования объектов и
явлений (физико-математические науки).
2. Разработка, обоснование и тестирование эффективных вычислительных
методов с применением современных компьютерных технологий.
3. Реализация эффективных численных методов и алгоритмов в виде
комплексов проблемно-ориентированных программ для проведения
вычислительного эксперимента.
4. Разработка новых математических методов и алгоритмов интерпретации
натурного эксперимента на основе его математической модели.
5. Разработка новых математических методов и алгоритмов валидации
математических моделей объектов на основе данных натурного эксперимента
или на основе анализа математических моделей.
6. Разработка систем компьютерного и имитационного моделирования,
алгоритмов и методов имитационного моделирования на основе анализа
математических моделей (технические науки).
7. Качественные или аналитические методы исследования математических
моделей (технические науки).
8. Комплексные исследования научных и технических проблем с
применением современной технологии математического моделирования и
вычислительного эксперимента.
9. Постановка и проведение численных экспериментов, статистический
анализ их результатов, в том числе с применением современных
компьютерных технологий (технические науки).
\fi


{\influence}
%Практическая значимость заключается в следующем:
\begin{enumerate}
   \item Впервые в России была создана диалоговая платформа мирового уровня, вышедшая в полуфинал престижных мировых конкурсов Alexa Prize 3 и Alexa Prize 4 (в конкурсах было 10 и 9 участников соответственно, из более чем 300 кандидатов). Эта диалоговая платформа имеет полностью открытый код, что дает возможность легкого переиспользования любой части проделанной над ней работы. Были также разработаны сценарные навыки для этой платформы.
   \item В данной диалоговой платформе были применены многозадачные нейросетевые модели: многозадачная нейросетевая модель с одним линейным слоем, многозадачная нейросетевая модель на основе архитектуры PAL-BERT и многозадачная трансформер-агностичная нейросетевая модель. 
   \item Программный код для реализации многозадачной трансформер-агностичной нейросетевой модели встроен в open-source библиотеку DeepPavlov, имеющую более 500000 скачиваний на март 2023 года.
\end{enumerate}

{\methods}
Были
применены: % В данной работе были примененыЖ
\begin{enumerate}
\item Метод численного эксперимента для исследования задач обработки естественного языка;
\item Теория вероятностей и математическая статистика;
\item Методы машинного обучения и теории глубокого обучения;
\item Методы разработки на языках Python, Bash.
\end{enumerate}

{\reliability} полученных результатов обеспечивается экспериментами на наборах диалоговых данных и наборе данных GLUE, описанными в~\cite{pseudolabel,rumtl,enmtl,rutopics,dp_2023}, применением в различных соревнованиях по созданию диалоговых систем, описанным в ~\cite{dream1,dream2,dream1_trudy,Болотин_Карпов_Рашков_Шкурак_2019} и использованием результатов работы в диалоговой платформе DREAM и библиотеке DeepPavlov. Результаты находятся в соответствии с результатами, полученными другими авторами.

{\probation}
\begin{itemize}
   \item En\&T 2018, доклад «Разработка диалоговой системы с интеграцией профиля личности», Даниил Болотин, Дмитрий Карпов, Григорий Рашков, Иван Шкурак, 15-16 ноября 2018 года, Москва;
   \item Диалог-2021, доклад «Data pseudo-labeling while adapting BERT for multitask approaches», Dmitry Karpov, Mikhail Burtsev, 16-19 июня 2021 года, Москва;
   \item AINL-2023, доклад «YAQTopics: Russian Conversational Topic Dataset», Dmitry Karpov, Vasily Konovalov, Mikhail Burtsev, 20-22 апреля 2023 года, Ереван, Армения;
\end{itemize}%, Computational Linguistics and Information Technologies~\cite{pseudolabel,rumtl},Proceedings of Alexa Prize 3~\cite{dream1},Proceedings of Alexa Prize 4~\cite{dream2}, Труды МФТИ~\cite{dream1_trudy},  Proceedings of InterSpeech 2023~\cite{enmtl}, Proceedings of ACL Systems Workshop~\cite{dp_topics}. Помимо этого, разработки, описанные в данной диссертации, были внедрены в находящуюся в открытом доступе диалоговую платформу DREAM, активно используемую в конкурсах Alexa Prize 3, Alexa Prize 4 и после них. Также на разработки, основанные на результатах работы, было получено свидетельство о регистрации ПО~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}.


{\contribution} В работе~\cite{Болотин_Карпов_Рашков_Шкурак_2019} автор отвечал за ряд основных компонент диалоговой системы, включающих в себя алгоритм для перефразировки реплик. Исследование, разработка и сравнительный анализ методов псевдоразметки данных, описанных в работе~\cite{pseudolabel}, были выполнены автором самостоятельно. В работах~\cite{dream1,dream1_trudy,dream2} автор отвечал за ряд важных компонент диалоговой системы - навыки обсуждения книг, эмоций, коронавируса, слухов, навык для обоснования диалога, ранжирующий навык TF-IDF, генеративный навык, классификаторы эмоций, интентов, момента остановки диалога и многозадачную нейросетевую модель. Технические решения для работы с естественным языком, использованные в \cite{dream1,dream1_trudy,dream2}, использовались также в~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}. В работах~\cite{rumtl,enmtl,rutopics} все исследования также были выполнены автором самостоятельно. В работе~\cite{dp_2023} автор отвечал за эксперименты с многозадачными трансформер-агностичными моделями для библиотеки DeepPavlov и их описание.

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
   {\publications} 

}%
{%%% Реализация пакетом biblatex через движок biber
   \begin{refsection}[bl-author]
      % Это refsection=1.
      % Процитированные здесь работы:
      %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
      %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
      %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
      %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
      %
      % Невидимый библиографический список для подсчёта количества публикаций:
      \printbibliography[heading=nobibheading, section=1, env=countauthorvak,        keyword=biblioauthorvak]%
      \printbibliography[heading=nobibheading, section=1, env=countauthorwos,        keyword=biblioauthorwos]%
      \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,      keyword=biblioauthorscopus]%
      \printbibliography[heading=nobibheading, section=1, env=countauthorconf,       keyword=biblioauthorconf]%
      \printbibliography[heading=nobibheading, section=1, env=countauthorother,      keyword=biblioauthorother]%
      \printbibliography[heading=nobibheading, section=1, env=countauthor,          keyword=biblioauthor]%
      \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
      \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,   filter=scopuswos]%
      %
      \nocite{*}%
      %
      {\publications} Основные результаты по теме диссертации изложены в~{9}~печатных изданиях,{1} из которых издано в журналах, рекомендованных ВАК, {2} в~периодических научных журналах, индексируемых Web of~Science и Scopus, {3} в~тезисах докладов.\footnote{Цифры будут уточнены после принятия всех статей.}

      \iffalse % This is a default template. And I do by hands
      {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
      \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
      \ifnum \value{citeauthorscopuswos}>0%
         , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
      \fi%
      \ifnum \value{citeauthorconf}>0%
         , \arabic{citeauthorconf} "--- в~тезисах докладов.
      \else%
         .
      \fi
      \fi
   \end{refsection}%
   \begin{refsection}[bl-author]
      % Это refsection=2.
      % Процитированные здесь работы:
      %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
      %  * ни на что не влияют в противном случае
      \nocite{Болотин_Карпов_Рашков_Шкурак_2019}%vak
      \nocite{dream1}%vak
      \nocite{dream2}%vak
      \nocite{pseudolabel}
      \nocite{dream1_trudy}%vak
      \nocite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}%vak
      \nocite{rumtl}
      \nocite{rutopics}
      \nocite{enmtl}
      \nocite{dp_2023}
   \end{refsection}%
      %
      % Всё, что вне этих двух refsection, это refsection=0,
      %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
      %  * для автореферата:
      %    * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
      %    * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
      %
      % Невидимый библиографический список для подсчёта количества внешних публикаций
      % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
      % цитирований внешних источников.
      % Замедляет компиляцию
   \ifsynopsis
   \ifnumequal{\value{draft}}{0}{
     \printbibliography[heading=nobibheading, section=0, env=countexternal,        keyword=biblioexternal]%
   }{}
   \fi
}
\iffalse
При использовании пакета \verb!biblatex! будут подсчитаны все работы, добавленные
в файл \verb!biblio/author.bib!. Для правильного подсчёта работ в~различных
системах цитирования требуется использовать поля:
\begin{itemize}
      \item {authorvak} если публикация индексирована ВАК,
      \item {authorscopus} если публикация индексирована Scopus,
      \item {authorwos} если публикация индексирована Web of Science,
      \item {authorconf} для докладов конференций,
      \item {authorother} для других публикаций.
\end{itemize}
Для подсчёта используются счётчики:
\begin{itemize}
      \item {citeauthorvak} для работ, индексируемых ВАК,
      \item {citeauthorscopus} для работ, индексируемых Scopus,
      \item {citeauthorwos} для работ, индексируемых Web of Science,
      \item {citeauthorvakscopuswos} для работ, индексируемых одной из трёх баз,
      \item {citeauthorscopuswos} для работ, индексируемых Scopus или Web of~Science,
      \item {citeauthorconf} для докладов на конференциях,
      \item {citeauthorother} для остальных работ,
      \item {citeauthor} для суммарного количества работ.
\end{itemize}
% Счётчик {citeexternal} используется для подсчёта процитированных публикаций.

Для добавления в список публикаций автора работ, которые не были процитированы в
автореферате требуется их~перечислить с использованием команды \verb!\nocite! в
\verb!Synopsis/content.tex!.
\fi
