
{\actuality} 
Актуальность темы обоснована стремительным развитием нейросетевых моделей. В последнее время нейросетевые модели на основе трансформеров, типа BERT, стали чаще применяться в различных областях, в том числе в диалоговых системах. Это связано с тем, что они показывают более высокие результаты, чем иные методы машинного обучения. В то же самое время, такие модели требуют вычислительных ресурсов, которые могут быть дорогостоящими. В связи с этим развитие получает идея многозадачного обучения - использование одной и той же модели для решения нескольких задач машинного обучения. Тем не менее, различные методы многозадачного обучения и их применение в диалоговых системах еще изучены не до конца.


{\aim} данной работы является эмпирический анализ использования различных нейросетевых архитектур для многозадачного машинного обучения при обработке естественного языка в диалоговых системах, а также эмпирический анализ различных методов подготовки и псевдоразметки данных для многозадачного машинного обучения. 

Для~достижения поставленной цели необходимо было решить следующие {\tasks}:
\begin{enumerate}
  \item Обучить и опубликовать в открытом доступе однозадачные модели классификации, адаптированные для разговорных данных конкурса Alexa Prize.
  \item Предложить и разработать сценарные разговорные навыки для
диалоговой системы.
  \item Разработать и опубликовать многозадачные модели, объединяющие опубликованные ранее однозадачные модели.
  \item Исследовать эмпирическим путем влияние аугментации данных, изменения архитектуры и методов сэмплирования на многозадачные модели. 
  \item На основании этих эмпирических исследований - выбрать оптимальные комбинации архитектуры, методов сэмплирования и аугментации данных для дальнейшего применения. \newline
  \newline
  \newline
\end{enumerate}


{\novelty}
\begin{enumerate}
  \item Впервые было проведено комплексное исследование влияния выбора методов сэмплирования, архитектуры и псевдоразметки данных с использованием как англоязычных, так и русскоязычных данных. 
  \item Обучены и опубликованы оригинальные однозадачные нейросетевые модели, готовые к использованию в качестве компонентов диалоговой системы DREAM.
  \item Предложены и опубликованы оригинальные разговорные навыки для диалоговой системы DREAM,
в основе которых лежат сценарии. 
\end{enumerate}

%{\appropriation}
Пункты 1 и 2 Научной новизны соответствуют пункту 5 "Комплексные исследования научных и технических проблем с применением современной технологии математического моделирования и
вычислительного эксперимента." специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». Пункт 3  Научной новизны соответствует пункту 8 «Разработка систем компьютерного и имитаци­онного моделирования» специальности 1.2.2 «Математическое моделирование,
численные методы и комплексы программ».


{\influence} \ldots
Практическая значимость заключается в следующем. Впервые в России были разработаны диалоговые системы мирового уровня, вышедшие в полуфинал престижных мировых конкурсов Alexa Prize 3 и Alexa Prize 4 (в конкурсах было 10 и 9 участников соответственно, из более чем 300 кандидатов). В этих системах, помимо основанных на правилах алгоритмах, применялись нейросетевые модели, в том числе и многозадачные описанные в диссертации модели. Помимо этого, программный код данных диалоговых систем был выложен в открытый доступ, что сделало результаты работы более доступными для мирового сообщества.
Помимо этого, программный код для реализации многозадачной трансформер-инвариантной нейросетевой модели (будет) встроен в библиотеку DeepPavlov, имеющую более.... скачиваний на март 2023 года.
Алгоритмы, использованные в данной работе, применены также в программе для ЭВМ [А6], на которую получено свидетельство о государственной регистрации.


{\methods} \ldots
В данной работе были
применены:
– метод численного эксперимента для исследования задач классифи­кации текстов;
– основы теории вероятностей;
– методы машинного обучения и теории глубокого обучения;
– методы разработки на языках Python, Bash, включая разработку программного кода для библиотек с открытым исходным кодом
DeepPavlov и DeepPavlov Agent
\ldots

{\defpositions}
\begin{enumerate}
\item Предложенные многозадачные модели демонстрируют более высокую степень экономии памяти, чем однозадачные модели
\item Предложенные многозадачные модели демонстрируют уровень качества, приближающийся к качеству однозадачных моделей
\item Предложенные многозадачные трансформер-инвариантные модели демонстрируют большую степень экономии памяти, чем модели типа PAL-BERT, при большей степени гибкости и удобства для встройки
\item Предложенные схемы псевдоразметки данных повышают качество многозадачных моделей.
\end{enumerate}


{\reliability} полученных результатов обеспечивается экспериментами на наборах диалоговых данных, а также применением в соревнованиях "Alexa Prize Challenge 3" и "Alexa Prize Challenge 4". 
 \ Результаты находятся в соответствии с результатами, полученными другими авторами.


{\probation}
Апробация работы. Результаты работы были представлены автором на конференции Диалог-2021 [А4], и опубликованы в журналах Proceedings of En\&T 2018[А1], Computational Linguistics and Information Technologies[А4], Proceedings of Alexa Prize 3[А2],Proceedings of Alexa Prize 4[А3], Труды МФТИ [А5]. Помимо этого, разработки, описанные в данной диссертации, были внедрены в диалоговые системы Dream и Dream 2, используемые в конкурсе Alexa Prize 3, Alexa Prize 4 и после него. Также на разработки, основанные на результатах работы, было получено свидетельство о регистрации ПО [A6].


{\contribution} В работе [А1] автор отвечал за ряд важных компонент диалоговой системы, включающих в себя парафразер. Исследование, разработка и сравнительный анализ методов псевдоразметки данных, описанных в [A4], были выполнены автором самостоятельно. В работах [A2],  [A5] автор отвечал за ряд важных компонент диалоговой системы - навыки обсуждения книг, эмоций, коронавируса, классификатор эмоций, и также за не ставший частью системы генеративный навык. В работе [A3] автор, помимо вышеупомянутых навыков, отвечал также за встройку многозадачного классификатора, основанного на модели PAL-BERT. В дальнейшем автор отвечал за встройку многозадачных моделей в диалоговую систему DREAM. Алгоритмы для обработки естественного языка, использованные в [A2], [A3], [A5], использовались также в [A6]. 

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} 

}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}%
        %
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi
    \end{refsection}%
    \begin{refsection}[bl-author]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        \nocite{Болотин_Карпов_Рашков_Шкурак_2019}%vak
        \nocite{dream1}%vak
        \nocite{dream2}%vak
        \nocite{pseudolabel}
        \nocite{dream1_trudy}%vak
        \nocite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}%vak
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
        %
        % Невидимый библиографический список для подсчёта количества внешних публикаций
        % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
        % цитирований внешних источников.
        % Замедляет компиляцию
    \ifsynopsis
    \ifnumequal{\value{draft}}{0}{
      \printbibliography[heading=nobibheading, section=0, env=countexternal,          keyword=biblioexternal]%
    }{}
    \fi
}

При использовании пакета \verb!biblatex! будут подсчитаны все работы, добавленные
в файл \verb!biblio/author.bib!. Для правильного подсчёта работ в~различных
системах цитирования требуется использовать поля:
\begin{itemize}
        \item \texttt{authorvak} если публикация индексирована ВАК,
        \item \texttt{authorscopus} если публикация индексирована Scopus,
        \item \texttt{authorwos} если публикация индексирована Web of Science,
        \item \texttt{authorconf} для докладов конференций,
        \item \texttt{authorother} для других публикаций.
\end{itemize}
Для подсчёта используются счётчики:
\begin{itemize}
        \item \texttt{citeauthorvak} для работ, индексируемых ВАК,
        \item \texttt{citeauthorscopus} для работ, индексируемых Scopus,
        \item \texttt{citeauthorwos} для работ, индексируемых Web of Science,
        \item \texttt{citeauthorvakscopuswos} для работ, индексируемых одной из трёх баз,
        \item \texttt{citeauthorscopuswos} для работ, индексируемых Scopus или Web of~Science,
        \item \texttt{citeauthorconf} для докладов на конференциях,
        \item \texttt{citeauthorother} для остальных работ,
        \item \texttt{citeauthor} для суммарного количества работ.
\end{itemize}
% Счётчик \texttt{citeexternal} используется для подсчёта процитированных публикаций.

Для добавления в список публикаций автора работ, которые не были процитированы в
автореферате требуется их~перечислить с использованием команды \verb!\nocite! в
\verb!Synopsis/content.tex!.

\iffalse
Пример автореферата
Общая характеристика работы
Актуальность темы. Создание диалоговой системы, способной
быстро, связно и осмысленно вести диалог на общие темы является одной
из фундаментальных проблем в области искусственного интеллекта (ИИ).
Развитие разговорного ИИ началось с диалоговых систем, основанных
на правилах и шаблонах [1]. Последние достижения в области обработки
естественного языка, например, предварительное обучение языковых мо
делей [2—5], архитектуры на основе памяти, и новые наборы диалоговых
данных [6—10], расширили возможности для решения многих сложных
проблем, возникающих при понимании человека машиной. В результате
современные диалоговые системы, такие как чат-боты XiaoIce [11] или
боты-участники конкурса «Alexa Prize Socialbot Grand Challenge»1, ком
бинируют в себе модели машинного и глубокого обучения с вручную
написанными сценариями на основе шаблонов [12].
Большинство современных диалоговых систем и голосовых помощни
ков имеют модульную архитектуру, включающую в себя модуль понимания
естественного языка, набор разговорных навыков и диалоговый мене
джер. Модуль понимания естественного языка обычно представляет из
себя набор нейросетевых моделей для классификации текста, разметки
(классификации элементов) последовательности и моделей извлечения ин
формации из баз знаний. Таким образом, классификация является одной
из важнейших задач, так как позволяет реализовать следующие функ
ции: определение текущей темы диалога, распознавание намерений, анализ
тональности, извлечение сущностей и определение их типов, выбор реко
мендаций. Однако, классификация текстов, как и любые другие задачи
понимания естественного языка, в контексте диалоговых систем имеет
особенности, связанные со специфичностью области использования. В част
ности, в данной работе рассматривается влияние стилистики разговорной
речи.
Отдельные разговорные навыки в современных диалоговых системах
представляют из себя сценарные, ранжирующие или генеративные модели.
Навыки на основе сценариев могут демонстрировать высокое качество диа
лога [13], однако такой подход имеет несколько важных недостатков, таких
как сложность интеграции знаний о пользователе, понимания контекста и
состояния диалога, ограниченность покрытия тем и ситуаций. Особенно
заметны эти проблемы становятся при общении с проактивными пользо
вателями, которые фактически берут на себя ведение диалога. Многие
системы также до сих пор плохо справляются с демонстрацией здравого
смысла в диалоге, что было показано в работах [14; 15]. В данном иссле
довании сделана попытка внедрить использование моделей предсказания
здравого смысла в диалог.
1https://developer.amazon.com/alexaprize/challenges/current-challenge/
3
Задачей диалогового менеджера является управление переключени
ем между навыками, в частности, шаблонными навыками узких предмет
ных областей и навыками диалога на общие темы. При этом ошибки
выбора навыков являются наиболее важной проблемой, так как они
часто приводят к изменению направления разговора в неподходящий
момент. Текущие подходы к отслеживанию состояния диалога и управ
лению диалогом в основном являются реактивными и полагаются на
результаты классификации намерений пользователя в последней реплике.
Таким образом, диалоговому менеджеру не хватает высокоуровневого по
нимания целей пользователя в диалоге и взаимопонимания с ним. Опыт
команд-участников конкурса «Alexa Prize Challenge» показывает, что даже
поверхностное моделирование понимания пользователя путем внедрения
шаблонных фраз, подтверждающих понимание реплики пользователя в от
ветах системы, значительно улучшает опыт пользователя [16; 17]. Поэтому
разработка стратегий управления диалогом, учитывающих цели пользова
телей, представляет из себя многообещающее направление.
У автора, как у члена команды DREAM – участника конкурса «Alexa
Prize Socialbot Grand Challenge» – была уникальная возможность прове
рить передовые исследовательские идеи в реальных условиях, в связи с
чем была сформулирована следующая цель диссертационной работы.
Целью данной работы является разработка и исследование ключе
вых нейросетевых моделей, навыков и алгоритмов для ведения диалога
на естественном языке и их интеграция в модульную диалоговую систему,
способную поддерживать разговор на широкий спектр тем.
Для достижения поставленной цели необходимо было решить следу
ющие задачи:
1. Исследовать влияние домена обучения векторных представлений
слов, включая векторные представления языковых моделей, на ка
чество решения задачи классификации текстов.
2. Обучить и опубликовать в открытом доступе модели оценки
тональности и токсичности, адаптированные для разговорных дан
ных.
3. Предложить и разработать сценарные разговорные навыки для
диалоговой системы.
4. Разработать и опубликовать разговорные навыки, использующие
нейросетевые модели предсказания здравого смысла.
5. Исследовать качество здравого смысла, демонстрируемого систе
мой в диалогах, и корреляцию здравого смысла и автоматических
метрик.
6. Предложить подход и разработать архитектуру диалогового мене
джера для диалоговой системы открытого домена.
4
7. Предложить подход и разработать метод выбора финального отве
та, позволяющий приоритизировать сценарные навыки и повысить
качество выбора финального ответа.
Научная новизна:
1. Впервые было проведено исследование влияния домена вектор
ных представлений языковых моделей на качество решения задачи
классификации текстов на русском языке.
2. Обучены и опубликованы оригинальные нейросетевые модели
оценки тональности и токсичности, адаптированные для разговор
ных данных на русском и английском языках.
3. Предложены и опубликованы оригинальные разговорные навыки,
в основе которых лежат сценарии.
4. Предложены и опубликованы оригинальные разговорные навыки,
интегрирующие модели предсказания здравого смысла.
5. Разработана новая схема разметки здравого смысла в диалоге.
6. Выполнено оригинальное исследование корреляции здравого смыс
ла и автоматических метрик.
7. Разработан и опубликован оригинальный алгоритм выбора фи
нального ответа, основанный на тегах и приоритизирующий сце
нарные разговорные навыки.
Соответствие диссертации паспорту научной специальности:
Пункты 1 и 2 Научной новизны соответствуют п. 5 «Комплексные ис
следования научных и технических проблем с применением современной
технологии математического моделирования и вычислительного экспери
мента» паспорта специальности 05.13.18 «Математическое моделирование,
численные методы и комплексы программ». Пункты 3, 4 и 7 Научной
новизны соответствуют п. 8 «Разработка систем компьютерного и имитаци
онного моделирования» паспорта специальности 05.13.18 «Математическое
моделирование, численные методы и комплексы программ». Пункты 5 и 6
Научной новизны соответствуют п. 6 «Разработка новых математических
методов и алгоритмов проверки адекватности математических моделей
объектов на основе данных натурного эксперимента» паспорта специ
альности 05.13.18 «Математическое моделирование, численные методы и
комплексы программ».
Практическая значимость заключается в следующем:
– Обученные в рамках работы векторные представления fastText
для различных языковых стилей позволяют улучшить качество ре
шения задач обработки естественного языка для соответствующего
домена.
– Предложенные нейросетевые методы и векторные представления
fastText были применены в конкурсе Kaggle «Toxic Comment
Classification Challenge»2 (18 место из 4539, золотая медаль).
2https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge
5
– Все разработанные и обученные модели векторных представле
ний и классификаторов, включая модели оценки тональности и
токсичности для диалогового домена, опубликованы в библиотеке
DeepPavlov3 и имеют тысячи скачиваний4.
– Предложенная методология использования предобученных век
торных представлений разговорного домена была применена к
обучению всех классификаторов диалоговой системы DREAM
в рамках конкурсов «Alexa Prize Challenge 3» и «Alexa Prize
Challenge 4».
– Предложенные сценарные разговорные навыки и навыки, интегри
рующие модели предсказания здравого смысла, а также алгоритмы
выбора набора навыков и выбора финального ответа были примене
ны в диалоговой системе DREAM в рамках конкурса «Alexa Prize
Challenge 3», «Alexa Prize Challenge 4» и выложены в открытый
доступ в рамках диалоговой системы DREAM5.
– По результатам данной работы оформлены свидетельства о го
сударственной регистрации программ для ЭВМ No 2021662460
«Программа выбора финального ответа из реплик-кандидатов»,
No 2021662601 «Программа разговорных навыков, интегрирую
щих модели предсказания аспектов здравого смысла в диалоге»,
No 2021664221 «Программа разговорного навыка для проведения
диалога о кино», No 2021664168 «Среда для создания сценарных
разговорных агентов».
Методология и методы исследования. В данной работе были
применены:
– метод численного эксперимента для исследования задач классифи
кации текстов;
– основы теории вероятностей;
– методы машинного обучения и теории глубокого обучения;
– методы разработки на языках Python, Bash, включая разработку
программного кода для библиотек с открытым исходным кодом
DeepPavlov и DeepPavlov Agent.
Основные положения, выносимые на защиту:
1. Векторные представления fastText и языковых моделей ELMo и
BERT соответствующего целевой задаче домена улучшают каче
ство решения задачи классификации текстов для английского и
русского языков.
3http://docs.deeppavlov.ai/en/master/features/models/classifiers.html, http://
docs.deeppavlov.ai/en/master/features/pretrained_vectors.html
4например, векторные представления fastText для разговорного домена скачаны
более 3 тысяч раз
5https://github.com/deepmipt/dream
6
2. Предложенные разговорные навыки, интегрирующие нейросете
вые модели предсказания здравого смысла в диалог, демонстриру
ют более высокий уровень наличия явного здравого смысла, чем
шаблонные навыки.
3. Для предложенной разметки уровней здравого смысла в диалоге,
проявление явного здравого смысла и отсутствие здравого смысла
могут быть оценены с помощью анализа тональности и токсично
сти реакции пользователя на реплики.
4. Предложенный алгоритм выбора финального ответа на основе те
гов, приоритизирующий сценарные навыки, повышает качество
выбора финальной реплики по сравнению с базовым алгоритмом,
основанном на уверенности навыков, для модульной диалоговой
системы открытого домена.
Достоверность полученных результатов обеспечивается экспери
ментами на наборах диалоговых данных, а также применением в сорев
нованиях Kaggle «Toxic Comment Classification Challenge», «Alexa Prize
Challenge 3» и «Alexa Prize Challenge 4». Результаты находятся в каче
ственном соответствии с результатами, полученными другими авторами.
Апробация работы. Результаты работы были представлены авто
ром на следующих научных конференциях и семинарах:
– XXV Международная научная конференция студентов, аспирантов
и молодых ученых «Ломоносов», доклад «Распознавание интентов
с помощью нейросетей», Баймурзина Диляра, 9 - 13 апреля 2018,
Москва;
– Конференция «Data Fest 5»6, 28 апреля 2018, Москва;
– The 56th Annual Meeting of the Association for Computational
Linguistics, Systems Demonstrations, демо-стенд «Deeppavlov:
Open-source library for dialogue systems», Burtsev Mikhail, et al.,
15 - 20 July 2018, Melbourne, Australia;
– XXV Международная конференция по компьютерной лингвисти
ке и интеллектуальным технологиям «Диалог», доклад «Language
model embeddings improve sentiment analysis», Baymurzina Dilyara,
Kuznetsov Denis, Burtsev Mikhail, 29 мая - 1 июня 2019, Москва;
– Конференция «AI Journey», постер «Conversational BERT for
English and Russian languages», Baymurzina Dilyara, Kuratov Yury,
Pugachev Leonid, 8 – 9 ноября 2019, Москва;
– XXII Международная конференция по компьютерной лингвистике
и интеллектуальным технологиям «Диалог», доклад «Evaluation of
Conversational Skills for Commonsense», Baymurzina Dilyara, et al.,
16 - 19 июня 2021, Москва.
6https://datafest.ru/5/
7
Личный вклад. Результаты, представленные на конференции «Ло
моносов» в докладе [A1], получены автором самостоятельно. В рабо
тах [A2] (индексируется Scopus), [A3], «Conversational BERT for English
and Russian languages» (постер на конференции «AI Journey») автором
реализованы и обучены модели классификации текстов. В работе [A4]
и [A5] (индексируется RSCI) автором была разработана часть аннота
торов, разговорных навыков, включая представленные в данной работе
сценарные навыки и навыки, интегрирующие здравый смысл в диалог.
В работе [A6] (индексируется Scopus) автором разработаны разговор
ные навыки, интегрирующие здравый смысл в диалог, предложена схема
разметки здравого смысла в диалоге, а также проведено исследование кор
реляции здравого смысла с автоматическими метриками. В работе [A7]
автором разработан алгоритм выбора финального ответа в диалоговой
системе, а также разработана часть аннотаторов и разговорных навы
ков. Программы ЭВМ [A8; A9] разработаны автором самостоятельно. В
программе ЭВМ [A10] автором разработана версия выборщика ответа на
основе тегов. В программе ЭВМ [A11] автор участвовала в доработке.
Публикации. Основные результаты по теме диссертации изложены
в 7 печатных изданиях, 1 из которых издано в журналах, индексируе
мых RSCI, 2 — в периодических научных журналах, индексируемых Web
of Science и Scopus, 2 — в тезисах докладов. Зарегистрированы 4 програм
мы для ЭВМ.
Содержание работы
Во введении обосновывается актуальность проводимых в рамках
данной диссертационной работы исследований, дается обзор научной ли
тературы по изучаемой проблеме, формулируется цель, ставятся задачи
работы, излагается научная новизна и практическая значимость представ
ляемой работы.
Первая глава посвящена обзору текущего состояния области диало
говых систем, в том числе основным видам, инструментам построения и
актуальным проблемам. Вводится терминология фреймворка DeepPavlov
Agent для описания архитектуры диалоговой системы (Рисунок 1).
Далее описываются основные виды разговорных навыков: ранжирую
щие, генеративные, шаблонные навыки. Алгоритм работы ранжирующих
моделей состоит в вычислении меры соответствия контекста и реплик из
базы возможных ответов и выбора наиболее подходящего ответа с опти
мальным значение меры. Для обучения генеративных моделей в базовом
варианте, когда на вход нейросети подается только векторное представле
ние контекста, а на выходе получается готовая реплика-кандидат, также
требуется только наличие набора диалоговых данных. На данный момент
наибольшую популярность среди генеративных моделей имеют языковые
8
Рис. 1 — Верхнеуровневая архитектура диалоговых систем во фреймворке
DeepPavlov Agent.
модели, предобученные на больших корпусах текстов для решения задачи
моделирования естественного языка. Одним из способов повысить кон
троль над генеративной моделью является использование дополнительной
информации, подаваемой на вход модели. Тогда модель учится генериро
вать реплику на основе контекста и обуславливаться на заданное знание,
что позволяет в некотором роде контролировать выход модели. Во мно
гих случаях требуется предсказуемость поведения диалоговой системы,
например, при использовании ее непосредственно на реальных пользовате
лях. В таких случаях самыми подходящими для использования являются
шаблонные навыки, которые используют различные условия, эвристики и
шаблоны для понимания контекста и генерации ответа.
Проблема недостатка контроля за развитием диалога может быть
решена за счет изначальной проработки сценария диалога на несколько
ходов. Что приводит к введению понятия сценарных навыков. Основное
достоинство сценарных навыков состоит в том, что они позволяют создать
впечатление связного диалога «в глубину» в течение сразу нескольких ша
гов диалога. Сценарии также позволяют в некотором роде интегрировать
персону бота в диалог – не только предпочтения, но и личные истории и
события. При этом не каждый шаблонный навык обязательно следует сце
нарию – шаблонные навыки вполне могут иметь одношаговые алгоритмы.
С другой стороны, в рамках сценарного навыка вполне можно использо
вать ранжирующие или генеративные модели для построения ответа на
некоторых шагах сценария.
В первой главе также описаны некоторые инструменты для построе
ния разговорных навыков, такие как AIML, DSL, STDM [18], DFF7. В конце
главы описаны проблемы диалоговых систем, которые будут изучаться
в диссертационной работе: доменная специфичность векторных представ
лений, особенности построения модульных диалоговых систем, создание
сценарных навыков, интеграция здравого смысла в диалог, а также диа
логовый менеджмент.
7https://github.com/deepmipt/dialog_flow_framework
9
Вторая глава посвящена исследованию влияния доменной специ
фичности, в частности языкового стиля, на решение задачи классификации
текстов. Исследования, описываемые в данной главе, проводились с 2017 го
да по 2019 год.
Первая часть исследований посвящена изучению базовых нейросе
тевых методов классификации текстов: широкой неглубокой свёрточной
SWCNN [19] сети и двунаправленной рекуррентной модели с долгой крат
косрочной памятью BiLSTM. Исследование проведено на наборе данных
SNIPS8, содержащем 2400 примеров для каждого из 7 заданных наме
рений. На наборе комментариев с веб-сайта Reddit9 с использованием
библиотеки fastText [20] обучена модель получения векторных представ
лений слов. Исследование было представлено в докладе [A1], архитектуры
и векторные представления использованы в статье [A2]. Результаты де
монстрируют преимущества неглубокой широкой свёрточной сети над
рекуррентной нейронной сетью с двунаправленной долгой краткосрочной
памятью.
Далее во второй главе представлено сравнение с векторами fastText
и исследование доменной специфичности векторных представлений языко
вых моделей (Embeddings from Language Models, ELMo) [21] – векторных
представлений, получаемых из BiLSTM модели, обученной для решения
задачи языкового моделирования на большом текстовом корпусе. Вектора
обладают важным свойством: представление каждого слова формирует
ся и левым, и правым контекстами этого слова. На момент публикации
оригинальной статьи [A3] автора, велись активные дискуссии о реальной
производительности ELMo, поэтому исследование было направлено на де
монстрацию успешного применения векторных представлений ELMo. В
рамках исследования соавтором были обучены языковые модели на рус
скоязычных текстовых данных трех языковых стилей: научного стиля –
на текстах с Wikipedia10, публицистического – на Russian WMT News11,
разговорного стиля – на наборе постов с веб-сайта Twitter12. Набор данных
RuSentiment был опубликован в 2018 году [22] вместе с базовыми резуль
татами, и был выбран в качестве целевого набора данных, так как его
содержание соответствует разговорному стилю, который часто не включал
ся в данные для языкового моделирования, в то время как использование
разговорных данных в 2019 году как раз стало набирать популярность в
связи с развитием диалоговых систем. В качестве нейросетевых архитектур
использовались SWCNN и двунаправленная управляемого рекуррентного
блока (BiGRU) [23; 24].
8https://github.com/snipsco/nlu-benchmark/tree/master/
2017-06-custom-intent-engines
9Набор «RC_2011-01» c http://files.pushshift.io/reddit/comments/
10https://ru.wikipedia.org/
11http://www.statmt.org/
12https://twitter.com/
10
\fi