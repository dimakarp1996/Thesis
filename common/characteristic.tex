
{\actuality} 
Актуальность темы обоснована стремительным развитием нейросетевых моделей. В последнее время нейросетевые модели на основе трансформеров, типа BERT, стали чаще применяться в различных областях, в том числе в диалоговых системах. Это связано с тем, что они показывают более высокие результаты, чем иные методы машинного обучения. В то же самое время, такие модели требуют вычислительных ресурсов, которые могут быть дорогостоящими. В связи с этим развитие получает идея многозадачного обучения - использование одной и той же модели для решения нескольких задач машинного обучения. Тем не менее, различные методы многозадачного обучения и их применение в диалоговых системах еще изучены не до конца.


{\aim} данной работы является эмпирический анализ использования различных нейросетевых архитектур для многозадачного машинного обучения при обработке естественного языка в диалоговых системах, а также эмпирический анализ различных методов подготовки и псевдоразметки данных для многозадачного машинного обучения. 

Для~достижения поставленной цели необходимо было решить следующие {\tasks}:
\begin{enumerate}
  \item Обучить и опубликовать в открытом доступе однозадачные модели классификации, адаптированные для разговорных данных конкурса Alexa Prize.
  \item Предложить и разработать сценарные разговорные навыки для
диалоговой системы.
  \item Разработать и опубликовать многозадачные модели, объединяющие опубликованные ранее однозадачные модели.
  \item Исследовать эмпирическим путем влияние аугментации данных, изменения архитектуры и методов сэмплирования на многозадачные модели. 
  \item На основании этих эмпирических исследований - выбрать оптимальные комбинации архитектуры, методов сэмплирования и аугментации данных для дальнейшего применения. \newline
  \newline
  \newline
\end{enumerate}


{\novelty}
\begin{enumerate}
  \item Впервые было проведено комплексное исследование влияния выбора методов сэмплирования, архитектуры и псевдоразметки данных с использованием как англоязычных, так и русскоязычных данных. 
  \item Обучены и опубликованы оригинальные однозадачные нейросетевые модели, готовые к использованию в качестве компонентов диалоговой системы DREAM.
  \item Предложены и опубликованы оригинальные разговорные навыки для диалоговой системы DREAM,
в основе которых лежат сценарии. 
\end{enumerate}

%{\appropriation}
Пункты 1 и 2 Научной новизны соответствуют пункту 5 "Комплексные исследования научных и технических проблем с применением современной технологии математического моделирования и
вычислительного эксперимента." специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». Пункт 3  Научной новизны соответствует пункту 8 «Разработка систем компьютерного и имитаци­онного моделирования» специальности 1.2.2 «Математическое моделирование,
численные методы и комплексы программ».


{\influence} \ldots
Практическая значимость заключается в следующем. Впервые в России были разработаны диалоговые системы мирового уровня, вышедшие в полуфинал престижных мировых конкурсов Alexa Prize 3 и Alexa Prize 4 (в конкурсах было 10 и 9 участников соответственно, из более чем 300 кандидатов). В этих системах, помимо основанных на правилах алгоритмах, применялись нейросетевые модели, в том числе и многозадачные описанные в диссертации модели. Помимо этого, программный код данных диалоговых систем был выложен в открытый доступ, что сделало результаты работы более доступными для мирового сообщества.
Помимо этого, программный код для реализации многозадачной трансформер-инвариантной нейросетевой модели (будет) встроен в библиотеку DeepPavlov, имеющую более.... скачиваний на март 2023 года.
Алгоритмы, использованные в данной работе, применены также в программе для ЭВМ [А6], на которую получено свидетельство о государственной регистрации.


{\methods} \ldots
В данной работе были
применены:
– метод численного эксперимента для исследования задач классифи­кации текстов;
– основы теории вероятностей;
– методы машинного обучения и теории глубокого обучения;
– методы разработки на языках Python, Bash, включая разработку программного кода для библиотек с открытым исходным кодом
DeepPavlov и DeepPavlov Agent
\ldots

{\defpositions}
\begin{enumerate}
\item Предложенные многозадачные модели демонстрируют более высокую степень экономии памяти, чем однозадачные модели
\item Предложенные многозадачные модели демонстрируют уровень качества, приближающийся к качеству однозадачных моделей
\item Предложенные многозадачные трансформер-инвариантные модели демонстрируют большую степень экономии памяти, чем модели типа PAL-BERT, при большей степени гибкости и удобства для встройки
\item Предложенные схемы псевдоразметки данных повышают качество многозадачных моделей.
\end{enumerate}


{\reliability} полученных результатов обеспечивается экспериментами на наборах диалоговых данных, а также применением в соревнованиях "Alexa Prize Challenge 3" и "Alexa Prize Challenge 4". 
 \ Результаты находятся в соответствии с результатами, полученными другими авторами.


{\probation}
Апробация работы. Результаты работы были представлены автором на конференции Диалог-2021 [А4], и опубликованы в журналах Proceedings of En\&T 2018[А1], Computational Linguistics and Information Technologies[А4], Proceedings of Alexa Prize 3[А2],Proceedings of Alexa Prize 4[А3], Труды МФТИ [А5]. Помимо этого, разработки, описанные в данной диссертации, были внедрены в диалоговые системы Dream и Dream 2, используемые в конкурсе Alexa Prize 3, Alexa Prize 4 и после него. Также на разработки, основанные на результатах работы, было получено свидетельство о регистрации ПО [A6].


{\contribution} В работе [А1] автор отвечал за ряд важных компонент диалоговой системы, включающих в себя парафразер. Исследование, разработка и сравнительный анализ методов псевдоразметки данных, описанных в [A4], были выполнены автором самостоятельно. В работах [A2],  [A5] автор отвечал за ряд важных компонент диалоговой системы - навыки обсуждения книг, эмоций, коронавируса, классификатор эмоций, и также за не ставший частью системы генеративный навык. В работе [A3] автор, помимо вышеупомянутых навыков, отвечал также за встройку многозадачного классификатора, основанного на модели PAL-BERT. В дальнейшем автор отвечал за встройку многозадачных моделей в диалоговую систему DREAM. Алгоритмы для обработки естественного языка, использованные в [A2], [A3], [A5], использовались также в [A6]. 

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} 

}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}%
        %
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi
    \end{refsection}%
    \begin{refsection}[bl-author]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        \nocite{Болотин_Карпов_Рашков_Шкурак_2019}%vak
        \nocite{dream1}%vak
        \nocite{dream2}%vak
        \nocite{pseudolabel}
        \nocite{dream1_trudy}%vak
        \nocite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}%vak
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
        %
        % Невидимый библиографический список для подсчёта количества внешних публикаций
        % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
        % цитирований внешних источников.
        % Замедляет компиляцию
    \ifsynopsis
    \ifnumequal{\value{draft}}{0}{
      \printbibliography[heading=nobibheading, section=0, env=countexternal,          keyword=biblioexternal]%
    }{}
    \fi
}

При использовании пакета \verb!biblatex! будут подсчитаны все работы, добавленные
в файл \verb!biblio/author.bib!. Для правильного подсчёта работ в~различных
системах цитирования требуется использовать поля:
\begin{itemize}
        \item \texttt{authorvak} если публикация индексирована ВАК,
        \item \texttt{authorscopus} если публикация индексирована Scopus,
        \item \texttt{authorwos} если публикация индексирована Web of Science,
        \item \texttt{authorconf} для докладов конференций,
        \item \texttt{authorother} для других публикаций.
\end{itemize}
Для подсчёта используются счётчики:
\begin{itemize}
        \item \texttt{citeauthorvak} для работ, индексируемых ВАК,
        \item \texttt{citeauthorscopus} для работ, индексируемых Scopus,
        \item \texttt{citeauthorwos} для работ, индексируемых Web of Science,
        \item \texttt{citeauthorvakscopuswos} для работ, индексируемых одной из трёх баз,
        \item \texttt{citeauthorscopuswos} для работ, индексируемых Scopus или Web of~Science,
        \item \texttt{citeauthorconf} для докладов на конференциях,
        \item \texttt{citeauthorother} для остальных работ,
        \item \texttt{citeauthor} для суммарного количества работ.
\end{itemize}
% Счётчик \texttt{citeexternal} используется для подсчёта процитированных публикаций.

Для добавления в список публикаций автора работ, которые не были процитированы в
автореферате требуется их~перечислить с использованием команды \verb!\nocite! в
\verb!Synopsis/content.tex!.
