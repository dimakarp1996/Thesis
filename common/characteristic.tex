
{\actuality} 
Актуальность темы обоснована стремительным развитием нейросетевых моделей. В последнее время нейросетевые модели на основе трансформеров, типа BERT, стали чаще применяться в различных областях, в том числе в диалоговых системах. Это связано с тем, что они показывают более высокие результаты, чем иные методы машинного обучения. В то же самое время, такие модели требуют вычислительных ресурсов, которые могут быть дорогостоящими. В связи с этим развитие получает идея многозадачного обучения - использование одной и той же модели для решения нескольких задач машинного обучения. Тем не менее, перенос данных в многозадачных нейросетевых моделях между задачами и языками, особенно для задач, применимых в диалоговых системах, всё еще не изучены до конца. Наборов данных в открытом доступе для задач диалоговых систем, таких, как тематическая классификация, также недостаточно.


{\aim} данной работы является исследование переноса знаний между языками и задачами в многозадачных нейросетевых моделях на различных архитектурах, а также изучение прикладного применения этих моделей на примере созданной диалоговой платформы DREAM.

Для достижения поставленной цели необходимо было решить следующие {\tasks}:
\begin{enumerate}
  \item Исследовать различные варианты выбора архитектуры многозадачных моделей на основе архитектуры Трансформер, а также выбора сэмплирования и выбора псевдоразметки данных для определенных типов таких моделей.
  \item Исследовать перенос знаний в многозадачных моделях на основе архитектуры Трансформер между английским и русским языком, а также между различными диалоговыми задачами. В частности, исследовать зависимость этого переноса от размера обучающей выборки.
  \item Предложить новый русскоязычный открытый набор тематических данных для прикладных задач диалоговой платформы DREAM и фундаментальных задач исследования переноса знаний.
  \item Исследовать зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.
  \item Разработать и опубликовать многозадачные трансформер-агностичные модели для диалоговой платформы DREAM и библиотеки DeepPavlov.
  \item Интегрировать многозадачные трансформер-агностичные модели в диалоговую платформу DREAM. Помимо этого, решить другие прикладные задачи, связанные с этой платформой( такие, как разработка сценарных навыков).
  \newline
  \newline
\end{enumerate}


{\novelty}
\begin{enumerate}
  \item Впервые было проведено комплексное исследование влияния выбора методов сэмплирования, архитектуры и псевдоразметки данных для многозадачных моделей на основе архитектуры Трансформер.
  \item Был исследован перенос знаний в многозадачных моделях на основе архитектуры Трансформер между английским и русским языком, а также между различными диалоговыми задачами. В частности, была исследована зависимость этого переноса от размера обучающей выборки.
  \item Был предложен новый русскоязычный открытый набор тематических данных \texttt{YAQTopics} для прикладных задач диалоговой платформы DREAM и фундаментальных задач исследования переноса знаний.
  \item Была исследована зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.
  \item Обучены и опубликованы оригинальные нейросетевые модели для использования в рамках диалоговой платформы DREAM и библиотеки DeepPavlov, в том числе трансформер-агностичные многозадачные модели с предложенной автором диссертационной работой архитектурой.
\end{enumerate}

{\appropriation}
Пункты 1, 2 и 4 Научной новизны соответствуют Пункту 8 "Комплексные исследования научных и технических проблем с применением современной технологии математического моделирования и
вычислительного эксперимента." специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ». Пункт 3 Научной новизны соответствует Пункту 5 "Разработка новых математических методов и алгоритмов валидации математических моделей объектов на основе данных натурного эксперимента или на основе анализа математических моделей." специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ», так как предложенный набор данных может использовать для валидации различных моделей машинного обучения. Пункт 5 Научной новизны соответствуте пункту 6 "Разработка систем компьютерного и имитационного моделирования, алгоритмов и методов имитационного моделирования на основе анализа математических моделей" специальности 1.2.2 «Математическое моделирование, численные методы и комплексы программ».

\iffalse
Направления исследований 1.2.1:
1. Естественно-научные основы и методы искусственного интеллекта.
2. Исследования в области оценки качества и эффективности
алгоритмических и программных решений для систем искусственного
интеллекта и машинного обучения. Методики сравнения и выбора
алгоритмических и программных решений при многих критериях.
3. Методы и алгоритмы моделирования мыслительных процессов:
рассуждений, аргументации, распознавания и классификации, формирования
понятий. Исследования в области нейроморфных методов анализа данных,
имитационное моделирование строения и функций мозга, в том числе – и с
использованием методов машинного обучения. Нейроинформатика и методы
моделирования биологических нервных систем.
4. Разработка методов, алгоритмов и создание систем искусственного
интеллекта и машинного обучения для обработки и анализа текстов на
естественном языке, для изображений, речи, биомедицины и других
специальных видов данных.
5. Методы и технологии поиска, приобретения и использования знаний и
закономерностей, в том числе – эмпирических, в системах искусственного
интеллекта. Исследования в области совместного применения методов
машинного обучения и классического математического моделирования.
Методы и средства использования экспертных знаний.
6. Формализация и постановка задач управления и (поддержки) принятия
решений на основе систем искусственного интеллекта и машинного обучения.
Разработка систем управления с использованием систем искусственного
интеллекта и методов машинного обучения в том числе – управления роботами,
автомобилями, БПЛА и т.п.
7. Разработка специализированного математического, алгоритмического и
программного обеспечения систем искусственного интеллекта и машинного
обучения. Методы и средства взаимодействия систем искусственного
интеллекта с другими системами и человеком-оператором.
8. Многоагентные системы и распределенный ИИ.
9. Методы и средства использования для решения задач искусственного
интеллекта и машинного обучения параллельных, квантовых вычислений и т.д.
10. Исследования в области этических проблем, связанных с созданием и
внедрением ИИ-систем, включая моделирование ожидаемых социальных и
экономических последствий.
11. Исследования в области «сильного ИИ», включая формирование
понятийной базы и элементов математического формализма, необходимых для
построения алгоритмического аппарата.
12. Исследования в области «доверенных» систем класса ИИ, включая
проблемы формирования тестовых выборок прецедентов, надежности,
устойчивости, переобучения и т.д.
13. Методы и средства формирования массивов данных и прецедентов,
включая «большие данные», необходимых для решения задач искусственного
интеллекта и машинного обучения. Проблемно-ориентированные коллекции
данных для важных прикладных областей.
14. Методы и средства формирования массивов условно-реальных данных и
прецедентов, необходимых для решения задач искусственного интеллекта и
машинного обучения.
15. Математические исследования в области статистики, логики, алгебры,
топологии, анализа функции и других областях, ориентированные на решение
задач искусственного интеллекта и машинного обучения.
16. Исследования в области специальных методов оптимизации, проблем
сложность и элиминации перебора, снижения размерности.
17. Исследования в области многослойных алгоритмических конструкций, в
том числе – многослойных нейросетей.

Направления исследований 1.2.2:
1. Разработка новых математических методов моделирования объектов и
явлений (физико-математические науки).
2. Разработка, обоснование и тестирование эффективных вычислительных
методов с применением современных компьютерных технологий.
3. Реализация эффективных численных методов и алгоритмов в виде
комплексов проблемно-ориентированных программ для проведения
вычислительного эксперимента.
4. Разработка новых математических методов и алгоритмов интерпретации
натурного эксперимента на основе его математической модели.
5. Разработка новых математических методов и алгоритмов валидации
математических моделей объектов на основе данных натурного эксперимента
или на основе анализа математических моделей.
6. Разработка систем компьютерного и имитационного моделирования,
алгоритмов и методов имитационного моделирования на основе анализа
математических моделей (технические науки).
7. Качественные или аналитические методы исследования математических
моделей (технические науки).
8. Комплексные исследования научных и технических проблем с
применением современной технологии математического моделирования и
вычислительного эксперимента.
9. Постановка и проведение численных экспериментов, статистический
анализ их результатов, в том числе с применением современных
компьютерных технологий (технические науки).
\fi


{\influence} \ldots
Практическая значимость заключается в следующем. Впервые в России была разработана диалоговая платформа мирового уровня, вышедшая в полуфинал престижных мировых конкурсов Alexa Prize 3 и Alexa Prize 4 (в конкурсах было 10 и 9 участников соответственно, из более чем 300 кандидатов). Эта диалоговая платформы имеет полностью открытый код, что дает возможность легкого переиспользования любой части проделанной над ней работы. 

В этой платформе, в числе всего прощего, применялись многозадачные нейросетевые модели, описанные автором в данном работе - многозадачная нейросетевая модель с одним линейным слоем, многозадачная нейросетевая модель на основе архитектуры PAL-BERT и многозадачная трансформер-агностичная нейросетевая модель. Был проведен ряд других прикладных работ для улучшения данной платформы, включающий в себя разработку сценарных навыков.

Помимо этого, программный код для реализации многозадачной трансформер-агностичной нейросетевой модели встроен в библиотеку DeepPavlov, имеющую более 500 000 скачиваний на март 2023 года.
Алгоритмы, использованные в данной работе, применены также в программе для ЭВМ [А6], на которую получено свидетельство о государственной регистрации.


{\methods} \ldots
В данной работе были
применены:
– метод численного эксперимента для исследования задач обработки естественного языка;
– основы теории вероятностей;
– методы машинного обучения и теории глубокого обучения;
– методы разработки на языках Python, Bash.
\ldots

{\defpositions}
\begin{enumerate}
\item Предложенные многозадачные трансформер-агностичные модели модели демонстрируют более высокую степень экономии памяти, чем однозадачные модели ( прирост числа параметров порядка 0.1\%), и при этом
\item Предложенные многозадачные модели демонстрируют уровень качества, приближающийся к качеству однозадачных моделей
\item Предложенные многозадачные трансформер-инвариантные модели демонстрируют большую степень экономии памяти, чем модели типа PAL-BERT, при большей степени гибкости и удобства для встройки
\item Предложенные схемы псевдоразметки данных повышают качество многозадачных моделей.
\end{enumerate}


{\reliability} полученных результатов обеспечивается экспериментами на наборах диалоговых данных и наборе данных GLUE, описанными в [A4](индексируется в Scopus), [A7], [A8], [A9], [A10], применением в соревнованиях "Alexa Prize Challenge 3" и "Alexa Prize Challenge 4", описанным в [A2], [A3], [A5](входит в список ВАК), а также использованием результатов работы в диалоговой платформе DREAM и библиотеке DeepPavlov. Результаты находятся в соответствии с результатами, полученными другими авторами.


{\probation}
Апробация работы. Результаты работы были представлены автором на конференции Диалог-2021 [А4], и опубликованы в журналах Proceedings of En\&T 2018 [А1], Computational Linguistics and Information Technologies [А4], Proceedings of Alexa Prize 3[А2],Proceedings of Alexa Prize 4 [А3], Труды МФТИ [А5], Proceedings of AINL 2023 [A7], [A8], Proceedings of InterSpeech 2023 [A9], Proceedings of ACL Systems Workshop [A10]. Помимо этого, разработки, описанные в данной диссертации, были внедрены в диалоговые системы Dream и Dream 2, используемые в конкурсе Alexa Prize 3, Alexa Prize 4 и после него. Также на разработки, основанные на результатах работы, было получено свидетельство о регистрации ПО [A6].


{\contribution} В работе [А1] автор отвечал за ряд важных компонент диалоговой системы, включающих в себя парафразер. Исследование, разработка и сравнительный анализ методов псевдоразметки данных, описанных в [A4], были выполнены автором самостоятельно. В работах [A2],  [A5] автор отвечал за ряд важных компонент диалоговой системы - навыки обсуждения книг, эмоций, коронавируса, классификатор эмоций, и также за не ставший частью системы генеративный навык. В работе [A3] автор, помимо вышеупомянутых навыков, отвечал также за встройку многозадачного классификатора, основанного на модели PAL-BERT. В дальнейшем автор отвечал за встройку многозадачных моделей в диалоговую систему DREAM. Алгоритмы для обработки естественного языка, использованные в [A2], [A3], [A5], использовались также в [A6]. В работах [A7], [A8], [A9] все исследования также были выполнены автором самостоятельно. В работе [A10] автор отвечал за эксперименты с многозадачными трансформер-агностичными моделями для библиотеки DeepPavlov и их описание.

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} 

}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нём должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчёта количества публикаций:
        \printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]%
        %
        \nocite{*}%
        %
        {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях,
        \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК\sloppy%
        \ifnum \value{citeauthorscopuswos}>0%
            , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus\sloppy%
        \fi%
        \ifnum \value{citeauthorconf}>0%
            , \arabic{citeauthorconf} "--- в~тезисах докладов.
        \else%
            .
        \fi
    \end{refsection}%
    \begin{refsection}[bl-author]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
        \nocite{Болотин_Карпов_Рашков_Шкурак_2019}%vak
        \nocite{dream1}%vak
        \nocite{dream2}%vak
        \nocite{pseudolabel}
        \nocite{dream1_trudy}%vak
        \nocite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}%vak
        \nocite{rumtl}
        \nocite{rutopics}
        \nocite{enmtl}
        \nocite{dp_2023}
    \end{refsection}%
        %
        % Всё, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
        %
        % Невидимый библиографический список для подсчёта количества внешних публикаций
        % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
        % цитирований внешних источников.
        % Замедляет компиляцию
    \ifsynopsis
    \ifnumequal{\value{draft}}{0}{
      \printbibliography[heading=nobibheading, section=0, env=countexternal,          keyword=biblioexternal]%
    }{}
    \fi
}
\iffalse
При использовании пакета \verb!biblatex! будут подсчитаны все работы, добавленные
в файл \verb!biblio/author.bib!. Для правильного подсчёта работ в~различных
системах цитирования требуется использовать поля:
\begin{itemize}
        \item \texttt{authorvak} если публикация индексирована ВАК,
        \item \texttt{authorscopus} если публикация индексирована Scopus,
        \item \texttt{authorwos} если публикация индексирована Web of Science,
        \item \texttt{authorconf} для докладов конференций,
        \item \texttt{authorother} для других публикаций.
\end{itemize}
Для подсчёта используются счётчики:
\begin{itemize}
        \item \texttt{citeauthorvak} для работ, индексируемых ВАК,
        \item \texttt{citeauthorscopus} для работ, индексируемых Scopus,
        \item \texttt{citeauthorwos} для работ, индексируемых Web of Science,
        \item \texttt{citeauthorvakscopuswos} для работ, индексируемых одной из трёх баз,
        \item \texttt{citeauthorscopuswos} для работ, индексируемых Scopus или Web of~Science,
        \item \texttt{citeauthorconf} для докладов на конференциях,
        \item \texttt{citeauthorother} для остальных работ,
        \item \texttt{citeauthor} для суммарного количества работ.
\end{itemize}
% Счётчик \texttt{citeexternal} используется для подсчёта процитированных публикаций.

Для добавления в список публикаций автора работ, которые не были процитированы в
автореферате требуется их~перечислить с использованием команды \verb!\nocite! в
\verb!Synopsis/content.tex!.
\fi
