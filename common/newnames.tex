
% Новые переменные, которые могут использоваться во всём проекте
% ГОСТ 7.0.11-2011
% 9.2 Оформление текста автореферата диссертации
% 9.2.1 Общая характеристика работы включает в себя следующие основные структурные
% элементы:
% актуальность темы исследования;
\newcommand{\actualityTXT}{Актуальность темы.}
% степень ее разработанности;
\newcommand{\progressTXT}{Степень разработанности темы.}
% цели и задачи;
\newcommand{\aimTXT}{Целью}
\newcommand{\tasksTXT}{задачи}
% научную новизну;
\newcommand{\noveltyTXT}{Научная новизна:}
% теоретическую и практическую значимость работы;
%\newcommand{\influenceTXT}{Теоретическая и практическая значимость}
\newcommand {\appropriationTXT}{Соответствие диссертации паспорту научной специальности}
% или чаще используют просто
\newcommand{\influenceTXT}{Практическая значимость}
% методологию и методы исследования;
\newcommand{\methodsTXT}{Методология и методы исследования.}
% положения, выносимые на защиту;
\newcommand{\defpositionsTXT}{Основные положения, выносимые на~защиту:}
% степень достоверности и апробацию результатов.
\newcommand{\reliabilityTXT}{Достоверность}
\newcommand{\probationTXT}{Апробация работы.}

\newcommand{\contributionTXT}{Личный вклад.}
\newcommand{\publicationsTXT}{Публикации.}


%%% Заголовки библиографии:

% для автореферата:
\newcommand{\bibtitleauthor}{Публикации автора по теме диссертации}

% для стиля библиографии `\insertbiblioauthorgrouped`
\newcommand{\bibtitleauthorvak}{В изданиях из списка ВАК РФ}
\newcommand{\bibtitleauthorscopus}{В изданиях, входящих в международную базу цитирования Scopus}
\newcommand{\bibtitleauthorwos}{В изданиях, входящих в международную базу цитирования Web of Science}
\newcommand{\bibtitleauthorother}{В прочих изданиях}
\newcommand{\bibtitleauthorconf}{В сборниках трудов конференций}
\newcommand{\bibtitleauthorpatent}{Зарегистрированные патенты}
\newcommand{\bibtitleauthorprogram}{Зарегистрированные программы для ЭВМ}

% для стиля библиографии `\insertbiblioauthorimportant`:
\newcommand{\bibtitleauthorimportant}{Наиболее значимые \protect\MakeLowercase\bibtitleauthor}

% для списка литературы в диссертации и списка чужих работ в автореферате:
\newcommand{\bibtitlefull}{Список литературы} % (ГОСТ Р 7.0.11-2011, 4)
\iffalse
\newcommand{\dreamTASK1}{Создать и выложить в открытый доступ диалоговую платформу DREAM, на которой в дальнейшем могло бы изучаться прикладное применение многозадачных нейросетевых моделей. Проверить качество этой диалоговой платформы международным конкурсом "Alexa Prize Socialbot Grand Challenge". }
\newcommand{\dreamNOVELTY1}{Была создана и выложена в открытый доступ диалоговая платформа DREAM, на которй в дальнейшем может изучаться прикладное применение многозадачных нейросетевых моделей. Качество этой диалоговой платформы было проверено международным конкурсом "Alexa Prize Socialbot Grand Challenge".}
\newcommand{\dreamDEFPOS1}{Диалоговая платформа DREAM пригодна для изучения прикладного применения многозадачных нейросетевых моделей. Двукратный выход в полуфинал международного конкурса "Alexa Prize Socialbot Grand Challenge" показывает высокое качество диалоговой платформы на момент её создания.}
\newcommand{\dreamTASK2}{Проверить применимость технологий, использованных в диалоговой платформе DREAM, в иных прикладных задачах.}
\newcommand{\dreamNOVELTY2}{Была проверена применимость технологий, использованных в диалоговой платформе DREAM, на прикладной задаче по созданию сервиса для работы с текстами texter-ocr-cv-microservice.}
\newcommand{\dreamDEFPOS2}{На примере прикладной задачи по созданию сервиса для работы с текстами texter-ocr-cv-microservice. эмпирически показана применимость технологий, использованных в диалоговой платформе DREAM, за пределами этой диалоговой платформы.}
\newcommand{\pseudolabelTASK1}{Провести эксперименты для сравнения различных схем псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем.}
\newcommand{\pseudolabelNOVELTY1}{Были проведены эксперименты для сравнения различных схем псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем на примере задач из набора данных GLUE.}
\newcommand{\pseudolabelDEFPOS1}{Псевдоразметка данных при помощи однозадачных моделей улучшает метрики многозадачных моделей. При этом объединение классов оправдывает себя только для задач, достаточно сильно похожих друг на друга.}
\newcommand{\tr-agTASK1}{Провести эксперименты для сравнения различных вариантов выбора архитектуры многозадачных нейросетевых моделей, а также выбора сэмплирования для определенных типов таких моделей.}
\newcommand{\tr-agNOVELTY1}{Были проведены эксперименты для сравнения различных вариантов выбора архитектуры многозадачных трансформер-агностичных нейросетевых моделей, сравнения их с аналогичными однозадачными моделями для разных тел, а также выбора сэмплирования для определенных типов таких моделей.}
\newcommand{\tr-agDEFPOS1}{Было показано на различных наборах данных, что многозадачные трансформер-агностичные нейросетевые модели показывают себя не хуже ряда других, более сложных архитектур, а предложенный метод сэмплирования - не хуже ряда других методов сэмплирования. При этом многозадачные трансформер-агностичные модели по данным проведенным экспериментах дают среднюю просадку не более 1 процента по сравнению с однозадачными моделями. А если какие-то задачи достаточно похожи друг на друга, как например, в бенчмарке GLUE, многозадачные модели за счет таких задач в среднем даже превосходят однозадачные модели.}
\newcommand{\tr-agTASK2}{Провести эмпирический анализ закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, провести оценку зависимости этого переноса от размера обучающей выборки.}
\newcommand{\tr-agNOVELTY2}{Был проведен эмпирический анализ закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, была произведена оценка зависимости этого переноса от размера обучающей выборки.}
\newcommand{\tr-agDEFPOS2}{Было показано, что для достаточно малых данных многозадачные трансформер-агностичных модели начинают превосходить по своей средней точности однозадачные, в особенности - за счет задач с наименьшим объемом данных.}
\newcommand{\tr-agTASK3} {Провести эмпирический анализ закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, провести оценку зависимости этого переноса от размера обучающей выборки. Рассмотреть также применимость этих выводов для однозадачных моделей.}
\newcommand{\tr-agNOVELTY3}{Был проведен эмпирический анализ закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, была проведена оценка зависимости этого переноса от размера обучающей выборки. Была рассмотрена также применимость этих выводов для однозадачных моделей.}
\newcommand{\tr-agDEFPOS3}{Было показано, что если в основе многозадачной трансформер-агностичной модели лежит многоязычный BERT, то добавление английских данных к русским при соответствующей номенклатуре классов позволяет улучшить метрики на 1-5\%. Чем меньше изначально русскоязычных данных, тем улучшение сильнее. Этот же вывод справедлив и для однозадачных моделей.}
\newcommand{\rutopicsTASK1}{Предложить новый русскоязычный открытый набор тематических данных для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний на разговорных данных.}
\newcommand{\rutopicsNOVELTY1}{Был предложен новый русскоязычный открытый набор тематических данных \texttt{YAQTopics} для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
\newcommand{\rutopicsDEFPOS1}{Предложенный автором новый русскоязычный открытый набор тематических данных \texttt{YAQTopics} подходит для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
\newcommand{\rutopicsTASK2}{Проверить зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.}
\newcommand{\rutopicsNOVELTY2}{Была проверена зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.}
\newcommand{\rutopicsDEFPOS2}{Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к русскому.}
\newcommand{\mtldreamTASK1}{Интегрировать рассмотренные в диссертации многозадачные нейросетевые архитектуры в диалоговую платформу DREAM, оценить применимость данных архитектур и провести их сравнительный анализ на основе опыта практического применения.}
\newcommand{\mtldreamNOVELTY1}{Рассмотренные в диссертации многозадачные нейросетевые архитектуры были интегрированы в диалоговую платформу, была оценена применимость и был проведен их сравнительные анализ на основе опыта применения.}
\newcommand{\mtldreamDEFPOS1}{Рассмотренные многозадачные нейросетевые архитектуры пригодны для практического применения в диалоговых платформах. При этом предложенные автором трансформер-агностичные нейросетевые модели выигрывают у моделей типа PAL-BERT за счет трансформер-агностичности, а у моделей с одним линейным слоем - за счёт большей гибкости, отсутствия необходимости в псевдоразметке и как следствие - меньшей склонности к переобучению.}
\fi