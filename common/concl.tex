%% Согласно ГОСТ Р 7.0.11-2011:
%% 5.3.3 В заключении диссертации излагают итоги выполненного исследования, рекомендации, перспективы дальнейшей разработки темы.
%% 9.2.3 В заключении автореферата диссертации излагают итоги данного исследования, рекомендации и перспективы дальнейшей разработки темы.
%ПРОСТО СКОПИРОВАЛ ПОЛОЖЕНИЯ ВЫНОСИМЫЕ ДЛЯ ЗАЩИТЫ
\begin{enumerate}
\item Предложенные многозадачные трансформер-агностичные модели модели демонстрируют более высокую степень экономии памяти, чем однозадачные модели ( прирост числа параметров порядка 0.1\%). Эти модели были применены в диалоговой платформе \texttt{DREAM} и библиотеке DeepPavlov.
\item Предложенные многозадачные трансформер-агностичные модели демонстрируют уровень качества, приближающийся к качеству однозадачных моделей. Просадка среднего качества на исследованных наборах данных не превышает один процент.
\item Предложенный тематический набор русскоязычных данных \texttt{YAQTopics} пригоден для решения задачи тематической классификации разговорных данных.
\item Для задач с относительно маленьким объемом данных по сравнению с другими задачами и при этом достаточно большой степенью похожести на какие-то задачи, имеющиеся бОльший объем данных, многозадачные модели показывают прирост метрик. Этот прирост усиливается для каждой задачи, если обучающая выборка достаточно мала.
\item Если номенклатура классов для английского и русского языка соответствует друг другу, то добавление англоязычных данных к русскоязычным для той же задачи помогает поднять качество многоязычной нейросетевой модели. Чем меньше русскоязычных данных, тем прирост качества выше, как для таких многозадачных моделях, так и для однозадачных.
\item В условиях предыдущего пункта перенос знаний для многозадачных моделей происходит эффективнее, если данные добавляются в рамках одной задачи, а не в рамках разных.
\item Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к русскому.
\item Трансформер-агностичность многозадачной нейросетевой модели повышает ее гибкость и удобство для стройки.
\item Предложенные схемы псевдоразметки данных повышают качество многозадачных моделей на тестовой выборке, но создает риск переобучения в случае возникновения дисбаланса классов.
  \item Исходный код всех упомянутых в предыдущих пунктах моделей и программ опубликован в открытом доступе, как набор данных YAQTopics, как часть библиотеки DeepPavlov и диалоговой платформы \texttt{DREAM} или же как дополнительные материалы к статьям.
\end{enumerate}
\iffalse
сследование зависимости качества решения задачи классификации
текстов от доменной специфичности, в частности языкового стиля, по
казало, что использование векторных представлений соответствующего
целевой задаче домена позволяет улучшить результаты для задач клас
сификации текстов (до 3.6 пунктов F-1 метрики на 5 разных задачах).
Предложенный подход был применен к построению классификаторов
для диалоговой системы DREAM.
2. Предложенный метод интеграции нейросетевых моделей предсказания
здравого смысла повышает количество высказываний бота, содер
жащих или дополняющих контекст диалога до здравого смысла.
Предложенные разговорные навыки, использующие данный метод,
были интегрированы в диалоговую систему \texttt{DREAM} испытаны и при
менены на реальных пользователях.
3. В соответствие с предложенной схемой разметки уровней здравого
смысла в диалогах, был размечен закрытый набор реальных диа
логовых данных, проведено исследование корреляции предложенной
разметки здравого смысла и нескольких автоматических метрик.
4. Исследование корреляции представленной разметки здравого смысла
и автоматических метрик показало, что тональность и токсичность ре
акции пользователя скоррелированы с явными проявления здравого
смысла и полным отсутствием здравого смысла.
5. Предложенные алгоритмы управления диалогом интегрированы в
компоненты Skill Selector и Response Selector диалоговой систе
мы \texttt{DREAM} в конкурсах «Alexa Prize Challenge 3» и «Alexa Prize
Challenge 4».
6. Предложенный алгоритм Response Selector на основе тегов позволил
улучшить выбор финального ответа. Доля реплик, соответствующих
контексту, возросла на 15.5% по сравнению с базовым эвристическим
алгоритмом и более, чем на 20% по сравнению с версией, не использу
ющей предложенные условия.
116

\fi