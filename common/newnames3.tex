
\newcommand{\dreamTASK1}{Создать и выложить в открытый доступ диалоговую платформу DREAM, на которой в дальнейшем могло бы изучаться прикладное применение многозадачных нейросетевых моделей. Проверить качество этой диалоговой платформы международным конкурсом "Alexa Prize Socialbot Grand Challenge". }
\iffalse
\newcommand{\dreamNOVELTY1}{Была создана и выложена в открытый доступ диалоговая платформа DREAM, на которй в дальнейшем может изучаться прикладное применение многозадачных нейросетевых моделей. Качество этой диалоговой платформы было проверено международным конкурсом "Alexa Prize Socialbot Grand Challenge".}
\newcommand{\dreamDEFPOS1}{Диалоговая платформа {DREAM} пригодна для изучения прикладного применения многозадачных нейросетевых моделей. Двукратный выход в полуфинал международного конкурса "Alexa Prize Socialbot Grand Challenge" показывает высокое качество диалоговой платформы на момент её создания.}
\newcommand{\dreamTASK2}{Проверить применимость технологий, использованных в диалоговой платформе DREAM, в иных прикладных задачах.}
\newcommand{\dreamNOVELTY2}{Была проверена применимость технологий, использованных в диалоговой платформе DREAM, на прикладной задаче по созданию сервиса для работы с текстами texter-ocr-cv-microservice.}
\newcommand{\dreamDEFPOS2}{На примере прикладной задачи по созданию сервиса для работы с текстами texter-ocr-cv-microservice. эмпирически показана применимость технологий, использованных в диалоговой платформе DREAM, за пределами этой диалоговой платформы.}
\newcommand{\pseudolabelTASK1}{Провести эксперименты для сравнения различных схем псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем.}
\newcommand{\pseudolabelNOVELTY1}{Были проведены эксперименты для сравнения различных схем псевдоразметки данных для многозадачных нейросетевых моделей с одним линейным слоем на примере задач из набора данных GLUE.}
\newcommand{\pseudolabelDEFPOS1}{Псевдоразметка данных при помощи однозадачных моделей улучшает метрики многозадачных моделей. При этом объединение классов оправдывает себя только для задач, достаточно сильно похожих друг на друга.}
\newcommand{\tr-agTASK1}{Провести эксперименты для сравнения различных вариантов выбора архитектуры многозадачных нейросетевых моделей, а также выбора сэмплирования для определенных типов таких моделей.}
\newcommand{\tr-agNOVELTY1}{Были проведены эксперименты для сравнения различных вариантов выбора архитектуры многозадачных трансформер-агностичных нейросетевых моделей, сравнения их с аналогичными однозадачными моделями для разных тел, а также выбора сэмплирования для определенных типов таких моделей.}
\newcommand{\tr-agDEFPOS1}{Было показано на различных наборах данных, что многозадачные трансформер-агностичные нейросетевые модели показывают себя не хуже ряда других, более сложных архитектур, а предложенный метод сэмплирования - не хуже ряда других методов сэмплирования. При этом многозадачные трансформер-агностичные модели по данным проведенным экспериментах дают среднюю просадку не более 1 процента по сравнению с однозадачными моделями. А если какие-то задачи достаточно похожи друг на друга, как например, в бенчмарке GLUE, многозадачные модели за счет таких задач в среднем даже превосходят однозадачные модели.}
\newcommand{\tr-agTASK2}{Провести эмпирический анализ закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, провести оценку зависимости этого переноса от размера обучающей выборки.}
\newcommand{\tr-agNOVELTY2}{Был проведен эмпирический анализ закономерностей переноса знаний в трансформер-агностичных многозадачных нейросетевых моделях между различными диалоговыми задачами. В частности, была произведена оценка зависимости этого переноса от размера обучающей выборки.}
\newcommand{\tr-agDEFPOS2}{Было показано, что для достаточно малых данных многозадачные трансформер-агностичных модели начинают превосходить по своей средней точности однозадачные, в особенности - за счет задач с наименьшим объемом данных.}
\newcommand{\tr-agTASK3} {Провести эмпирический анализ закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, провести оценку зависимости этого переноса от размера обучающей выборки. Рассмотреть также применимость этих выводов для однозадачных моделей.}
\newcommand{\tr-agNOVELTY3}{Был проведен эмпирический анализ закономерностей переноса знаний в многоязычных трансформер-агностичных многозадачных нейросетевых моделях между различными языками - с английского языка на русский. В частности, была проведена оценка зависимости этого переноса от размера обучающей выборки. Была рассмотрена также применимость этих выводов для однозадачных моделей.}
\newcommand{\tr-agDEFPOS3}{Было показано, что если в основе многозадачной трансформер-агностичной модели лежит многоязычный BERT, то добавление английских данных к русским при соответствующей номенклатуре классов позволяет улучшить метрики на 1-5\%. Чем меньше изначально русскоязычных данных, тем улучшение сильнее. Этот же вывод справедлив и для однозадачных моделей.}
\newcommand{\rutopicsTASK1}{Предложить новый русскоязычный открытый набор тематических данных для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний на разговорных данных.}
\newcommand{\rutopicsNOVELTY1}{Был предложен новый русскоязычный открытый набор тематических данных {YAQTopics} для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
\newcommand{\rutopicsDEFPOS1}{Предложенный автором новый русскоязычный открытый набор тематических данных {YAQTopics} подходит для решения задачи русскоязычной тематической классификации и фундаментальных задач исследования переноса знаний.}
\newcommand{\rutopicsTASK2}{Проверить зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.}
\newcommand{\rutopicsNOVELTY2}{Была проверена зависимость межъязыкового переноса знаний на разговорных данных в многоязычных нейросетевых моделях от размера предобучающей выборки и генеалогической близости языков.}
\newcommand{\rutopicsDEFPOS2}{Для многоязычных нейросетевых моделей качество переноса знаний на разные языки на тематических данных сильно коррелирует с размером предобучающей выборки для каждого языка, но при этом не коррелирует с генеалогической близостью этого языка к русскому.}
\newcommand{\mtldreamTASK1}{Интегрировать рассмотренные в диссертации многозадачные нейросетевые архитектуры в диалоговую платформу DREAM, оценить применимость данных архитектур и провести их сравнительный анализ на основе опыта практического применения.}
\newcommand{\mtldreamNOVELTY1}{Рассмотренные в диссертации многозадачные нейросетевые архитектуры были интегрированы в диалоговую платформу, была оценена применимость и был проведен их сравнительные анализ на основе опыта применения.}
\newcommand{\mtldreamDEFPOS1}{Рассмотренные многозадачные нейросетевые архитектуры пригодны для практического применения в диалоговых платформах. При этом предложенные автором трансформер-агностичные нейросетевые модели выигрывают у моделей типа PAL-BERT за счет трансформер-агностичности, а у моделей с одним линейным слоем - за счёт большей гибкости, отсутствия необходимости в псевдоразметке и как следствие - меньшей склонности к переобучению.}
\fi