\section*{Общая характеристика работы}

\newcommand{\actuality}{\underline{\textbf{\actualityTXT}}}
\newcommand{\progress}{\underline{\textbf{\progressTXT}}}
\newcommand{\aim}{\underline{{\textbf\aimTXT}}}
\newcommand{\tasks}{\underline{\textbf{\tasksTXT}}}
\newcommand{\novelty}{\underline{\textbf{\noveltyTXT}}}
\newcommand{\influence}{\underline{\textbf{\influenceTXT}}}
\newcommand{\methods}{\underline{\textbf{\methodsTXT}}}
\newcommand{\defpositions}{\underline{\textbf{\defpositionsTXT}}}
\newcommand{\reliability}{\underline{\textbf{\reliabilityTXT}}}
\newcommand{\probation}{\underline{\textbf{\probationTXT}}}
\newcommand{\contribution}{\underline{\textbf{\contributionTXT}}}
\newcommand{\publications}{\underline{\textbf{\publicationsTXT}}}

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

%Диссертационная работа была выполнена при поддержке грантов \dots

%\underline{\textbf{Объем и структура работы.}} Диссертация состоит из~введения,
%четырех глав, заключения и~приложения. Полный объем диссертации
%\textbf{ХХХ}~страниц текста с~\textbf{ХХ}~рисунками и~5~таблицами. Список
%литературы содержит \textbf{ХХX}~наименование.

\section*{Содержание работы}
Во \underline{\textbf{введении}} обосновывается актуальность
исследований, проводимых в~рамках данной диссертационной работы,
приводится обзор научной литературы по изучаемой проблеме,
формулируется цель, ставятся задачи работы, излагается научная новизна
и практическая значимость представляемой работы. 

Во \underline{\textbf{второй главе}} разбираются нейросетевые архитектуры, имеющие отношение к данной диссертационной работе. Это архитектура Трансформер~\cite{vaswani_2017}, и это нейросетевая модель \textbf{BERT}~\cite{devlin_2018}, основанная на данной архитектуре.

\underline{\textbf{Третья глава}} посвящена многозадачным нейросетевым моделям. В первом разделе третьей главы дается определение многозадачного обучения, и дается деление всех имеющихся многозадачных архитектур на четыре типа - параллельные, модульные, иерархические и генеративно-состязательные. В следующих двух разделах приводится подробный обзор двух архитектур, на которых основывались последующие разделы данной диссертационной работы. А именно, модель \textbf{MT-DNN}~\cite{mtdnn}, имеющая параллельную архитектуру, и модель \textbf{PAL-BERT}~\cite{stickland_2019}, имеющая модульную архитектуру. 

\underline{\textbf{Четвертая глава}} посвящена обзору диалоговой платформы DREAM. Именно потребности этой платформы стимулировали создание многозадачных нейросетевых моделей, описанных в данной диссертационной работе, в этой платформе они и получали свое прикладное применение. В главе подробно рассмотрена структура этой диалоговой платформы, ее эволюция в течение конкурсов "Alexa Prize Socialbot Grand Challenge 3" и "Alexa Prize Socialbot Grand Challenge 4". Отдельное внимание уделено личному вкладу автора данной диссертационной работы в каждую из версий диалоговой платформы DREAM. 

Вкладом в первую версию являются аннотаторы Emotion Classification и Dialog Termination, навыки открытого домена TF-IDF Retrieval и генеративный навык, а также навыки закрытого домена Book Skill, Coronavirus Skill и (в своей основной части) Emotion Skill, которые были разработаны автором данной диссертационной работы самостоятельно. Первая версия диалоговой платформы DREAM описана в работах~\cite{dream1,dream1_trudy}.

К вкладу автора во вторую версию относится в первую очередь обучение и интеграция многозадачной нейросетевой модели с одним линейным слоем. Эти работы подробно описаны в \textbf{восьмой главе}.  Также к вкладу автора относятся обучение модели классификации интентов на основе семантических классов из набора данных MIDAS~\cite{midas}, разработка сценарного навыка Grounding Skill, значительное участие в разработке навыка закрытого домена Gossip, значительное улучшение сценарных навыков Book Skill(на основе Wikidata), Emotion Skill и аннотатора Intent Catcher. Помимо этого, автор принимал активное участие в отладке других навыков и аннотаторов на основе ежедневного анализа диалогов системы DREAM и ее личного тестирования. 

Вторая версия диалоговой системы DREAM описана в работе~\cite{dream2}. Технические решения, применяемые при работе над второй версии диалоговой системы DREAM, использовались также в сторонней работе автора, на которую получено свидетельство о депонировании ~\cite{Дуплякин_Дмитрий_Ондар_Ушаков_2021}. 


\underline{\textbf{Пятая глава}} посвящена многозадачным нейросетевым моделям с одним линейным слоем - простейшему типу многозадачных моделей. Для четырех задач из бенчмарка GLUE~\cite{wang_2018}(MNLI, QQP, SST, RTE) сравниваются различные способы псевдоразметки данных при обучении многозадачной модели с одним линейным слоем. Делается вывод, что если задачи достаточно сильно отличаются друг от друга, то самый лучший способ обучения таких моделей - получение вероятностей для каждого примера, не имеющего метки для той или иной задачи, по предсказаниям модели, учившейся только для этой задачи. Именно этот метод подробнее описан в \textbf{восьмой главе}.

\underline{\textbf{Шестая глава}} посвящена трансформер-агностичным многозадачным моделям. В частности, в этой главе приводится архитектура трансформер-агностичной многозадачной модели. 

Была 

Глава 6. Трансформер-агностичные модели . . . . . . . . . . . . . 69
6.0.1 Архитектура трансформер-агностичной многозадачной
модели . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
6.0.2 Какие эксперименты не сработали . . . . . . . . . . . . . . 71
6.0.3 Преимущество трансформер-агностичной многозадачной
модели над многозадачной моделью с одним линейным
слоем . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

6.1 Наборы данных . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
6.1.1 Классификация эмоций . . . . . . . . . . . . . . . . . . . . 75
6.1.2 Классификация тональности . . . . . . . . . . . . . . . . . 76
6.1.3 Классификация токсичности . . . . . . . . . . . . . . . . . 77
6.1.4 Классификация интентов и тематическая классификация 78
6.2 Настройки экспериментов . . . . . . . . . . . . . . . . . . . . . . . 78
6.3 Многозадачные и однозадачные модели - эксперименты на
полном наборе данных . . . . . . . . . . . . . . . . . . . . . . . . . 79
6.3.1 Эффект уменьшения размера обучающей выборки
(англоязычные данные) . . . . . . . . . . . . . . . . . . . . 81
6.3.2 Многоязычные многозадачные модели - эффект
кросс-языкового обучения . . . . . . . . . . . . . . . . . . . 83
6.3.3 Насколько помогает добавление англоязычных данных? . 85
6.4 Выводы и анализ результатов . . . . . . . . . . . . . . . . . . . . 86
\underline{\textbf{Седьмая глава}} расширяет работу, проделанную в \textbf{шестой главе}. В данной главе предлагается новый тематический набор данных - \texttt{YAQTopics}.  Данный набор состоит из 76 тематических классов и имеет более 500 
Глава 7. Исследование переноса знаний в многоязычных
моделях на новом тематическом наборе данных . . . . . 7 МОЖЕТ ПОМЕНЯТЬСЯ
7.1 Введение . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
7.2 Набор данных YAQTopics . . . . . . . . . . . . . . . . . . . . . . . 8
7.3 Выбор представления набора данных YAQTopics . . . . . . . . . . 11
7.3.1 Обучение модели для сравнения . . . . . . . . . . . . . . . 11
7.4 Перенос знаний между языками . . . . . . . . . . . . . . . . . . . 15
7.5 Обсуждение и анализ результатов .

\fi

\underline{\textbf{Восьмая глава}}
Глава 8. Использование в диалоговой платформе DREAM
многозадачных моделей . . . . . . . . . . . . . . . . . . . . . 91
8.1 Использование многозадачных моделей с одним линейным слоем 91
8.1.1 Использование многозадачных моделей с одним
линейным слоем для объединения и замены
классификаторов реплик . . . . . . . . . . . . . . . . . . . 91
8.1.2 Использование многозадачных моделей с одним
линейным слоем для замены модели для оценки диалога . 94
8.2 Использование модели PAL-BERT в диалоговой платформе
DREAM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
8.3 Выводы . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
8.4 Использование многозадачной трансформер-агностичной
модели в диалоговой платформе DREAM . . . . . . . . . . . . . . 101
8.4.1 Экономия памяти GPU, CPU и быстродействия . . . . . . 1

Можно сослаться на свои работы в автореферате. Для этого в файле
\verb!Synopsis/setup.tex! необходимо присвоить положительное значение
счётчику \verb!\setcounter{usefootcite}{1}!. В таком случае ссылки на
работы других авторов будут подстрочными.
Изложенные в третьей главе результаты опубликованы в~\cite{vakbib1, vakbib2}.
Использование подстрочных ссылок внутри таблиц может вызывать проблемы.

В \underline{\textbf{четвертой главе}} приведено описание

В \underline{\textbf{заключении}} приведены основные результаты работы, которые заключаются в следующем:
\input{common/concl}

При использовании пакета \verb!biblatex! список публикаций автора по теме
диссертации формируется в разделе <<\publications>>\ файла
\verb!common/characteristic.tex!  при помощи команды \verb!\nocite!

\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=false}}{} % не рекомендуется применять пакет микротипографики к автоматически генерируемому списку литературы
\urlstyle{rm}                               % ссылки URL обычным шрифтом
\ifnumequal{\value{bibliosel}}{0}{% Встроенная реализация с загрузкой файла через движок bibtex8
  \renewcommand{\bibname}{\large \bibtitleauthor}
  \nocite{*}
  \insertbiblioauthor           % Подключаем Bib-базы
  %\insertbiblioexternal   % !!! bibtex не умеет работать с несколькими библиографиями !!!
}{% Реализация пакетом biblatex через движок biber
  % Цитирования.
  %  * Порядок перечисления определяет порядок в библиографии (только внутри подраздела, если `\insertbiblioauthorgrouped`).
  %  * Если не соблюдать порядок "как для \printbibliography", нумерация в `\insertbiblioauthor` будет кривой.
  %  * Если цитировать каждый источник отдельной командой --- найти некоторые ошибки будет проще.
  %
  %% authorvak
  \nocite{vakbib1}%
  \nocite{vakbib2}%
  %
  %% authorwos
  \nocite{wosbib1}%
  %
  %% authorscopus
  \nocite{scbib1}%
  %
  %% authorconf
  \nocite{confbib1}%
  \nocite{confbib2}%
  %
  %% authorother
  \nocite{bib1}%
  \nocite{bib2}%

  \ifnumgreater{\value{usefootcite}}{0}{
    \begin{refcontext}[labelprefix={}]
      \ifnum \value{bibgrouped}>0
        \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
      \else
        \insertbiblioauthor      % Вывод всех работ автора
      \fi
    \end{refcontext}
  }{
  \ifnum \value{citeexternal}>0
    \begin{refcontext}[labelprefix=A]
      \ifnum \value{bibgrouped}>0
        \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
      \else
        \insertbiblioauthor      % Вывод всех работ автора
      \fi
    \end{refcontext}
  \else
    \ifnum \value{bibgrouped}>0
      \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
    \else
      \insertbiblioauthor      % Вывод всех работ автора
    \fi
  \fi
  %  \insertbiblioauthorimportant  % Вывод наиболее значимых работ автора (определяется в файле characteristic во второй section)
  \begin{refcontext}[labelprefix={}]    \insertbiblioexternal            % Вывод списка литературы, на которую ссылались в тексте автореферата
  \end{refcontext}
  }
}
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=true}}{}
\urlstyle{tt}                               % возвращаем установки шрифта ссылок URL
